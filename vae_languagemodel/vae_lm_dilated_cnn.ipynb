{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of vae_lm_16.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "aE3aqguc1UK_"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "hZg-tBJhJ8Bz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Import library"
      ]
    },
    {
      "metadata": {
        "id": "YyBKEOB0J8B0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# !apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n",
        "# !add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
        "# !apt-get update -qq 2>&1 > /dev/null\n",
        "# !apt-get -y install -qq google-drive-ocamlfuse fuse\n",
        "# from google.colab import auth\n",
        "# auth.authenticate_user()\n",
        "# from oauth2client.client import GoogleCredentials\n",
        "# creds = GoogleCredentials.get_application_default()\n",
        "# import getpass\n",
        "# !google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n",
        "# vcode = getpass.getpass()\n",
        "# !echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KKjYVAahxqAX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# !mkdir -p drive\n",
        "# !google-drive-ocamlfuse drive"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oQv-8hdax6gp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "77552626-69c8-4d2b-dbcd-73adaa9698ae"
      },
      "cell_type": "code",
      "source": [
        "ls"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "adc.json  \u001b[0m\u001b[01;36mdatalab\u001b[0m@  \u001b[01;34mdrive\u001b[0m/  \u001b[01;34msample_data\u001b[0m/\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "krhD2fIQyC_X",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "84152b0f-1978-4e92-abf3-a3366aa54b37"
      },
      "cell_type": "code",
      "source": [
        "cd drive/ptb_vae_DCNN_lm"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/ptb_vae_DCNN_lm\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "1WbWrk2HJ8B2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import os\n",
        "import re\n",
        "import reader\n",
        "from tensorflow.contrib.seq2seq import sequence_loss\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "import collections\n",
        "\n",
        "!pip install -q mosestokenizer\n",
        "from mosestokenizer import *"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aE3aqguc1UK_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Data Pre-processing"
      ]
    },
    {
      "metadata": {
        "id": "jk41lQJA1hSG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# def _read_words(filename):\n",
        "#   with tf.gfile.GFile(filename, \"r\") as f: \n",
        "#     output = f.read().replace(\"\\n\", \" eos \").replace(\".\", \" .\")\n",
        "#     output = re.sub('[0-9]+', 'N', output)\n",
        "#     return output\n",
        "  \n",
        "# def train_vocab_en(n):  \n",
        "#     # get vocab in train which show more than n times\n",
        "    \n",
        "#     vocab = {'<PAD>': 0, '<OOV>': 1}\n",
        "    \n",
        "#     word_count = collections.defaultdict(float)\n",
        "    \n",
        "#     en_tokenize = MosesTokenizer('en')\n",
        "    \n",
        "#     for i in range(1):\n",
        "#       data = _read_words(\"../ptb_data/ptb.train.txt\")\n",
        "#       data = en_tokenize(data)\n",
        "    \n",
        "#       for token in data:\n",
        "#         word_count[token] += 1.0\n",
        "                          \n",
        "#     total_word = set(word_count)\n",
        "    \n",
        "#     for word in total_word:\n",
        "#         if word_count[word] > n:\n",
        "#             vocab[word] = len(vocab)  # word only show less than n times became oov\n",
        "            \n",
        "#     return vocab"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TFs1MjD61w-2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# en_word_to_id = train_vocab_en(5) \n",
        "# en_word_to_id['<beg>'] = len(en_word_to_id)\n",
        "# en_vocab_size = len(en_word_to_id)\n",
        "# print(en_vocab_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Zmwq93LwFQ1S",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# def _read_words(filename):\n",
        "#   with tf.gfile.GFile(filename, \"r\") as f: \n",
        "#     output = f.read().replace(\"\\n\", \" eos \").replace(\".\", \" .\")\n",
        "#     output = re.sub('[0-9]+', 'N', output)\n",
        "#     return output\n",
        "\n",
        "# def _file_to_word_ids(data, word_to_id):\n",
        "  \n",
        "#   id_list = []\n",
        "  \n",
        "#   for word in data:\n",
        "#     if word in word_to_id:\n",
        "#       id_list.append(word_to_id[word])\n",
        "#     else:\n",
        "#       id_list.append(1)\n",
        "          \n",
        "#   return id_list\n",
        "\n",
        "# def preprocess_train_data(pre_data, word_to_id, max_length):\n",
        "#     pre_data_array = np.asarray(pre_data)\n",
        "#     last_start = 0\n",
        "#     data = []\n",
        "#     each_sen_len = []\n",
        "    \n",
        "#     for i in range(len(pre_data_array)):\n",
        "#         if pre_data_array[i]==word_to_id['eos']:\n",
        "#             if max_length >= len(pre_data_array[last_start:(i+1)]):                \n",
        "#               data.append(pre_data_array[last_start:(i+1)])\n",
        "#               each_sen_len.append(i+1-last_start)\n",
        "              \n",
        "#             else:\n",
        "#               shorten_sentences = pre_data_array[last_start:(last_start+max_length-1)]\n",
        "#               shorten_sentences = np.concatenate((shorten_sentences, np.asarray([word_to_id['eos']])), axis=0)\n",
        "#               data.append(shorten_sentences)\n",
        "#               each_sen_len.append(max_length) \n",
        "            \n",
        "#             last_start = i+1\n",
        "            \n",
        "#     out_sentences = np.full([len(data), max_length], word_to_id['<PAD>'], dtype=np.int32)\n",
        "#     for i in range(len(data)):\n",
        "#         out_sentences[i,:len(data[i])] = data[i]    \n",
        "#     return out_sentences, np.asarray(each_sen_len)\n",
        "            \n",
        "#     return data, each_sen_len"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_U7GokZPFi67",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# def generate_input_en(en_file, en_word_to_id, max_length):\n",
        "  \n",
        "#     en_data = _read_words(en_file)\n",
        "\n",
        "#     en_tokenize = MosesTokenizer('en')\n",
        "\n",
        "#     en_data = en_tokenize(en_data)\n",
        "\n",
        "#     en_data_id = _file_to_word_ids(en_data, en_word_to_id)\n",
        "\n",
        "#     en_input, en_input_len = preprocess_train_data(en_data_id, en_word_to_id, max_length)\n",
        "    \n",
        "#     return en_input, en_input_len\n",
        "  \n",
        "  \n",
        "  \n",
        "# def generate_decode_input_en(en_file, en_word_to_id, max_length):\n",
        "    \n",
        "#     en_data = _read_words(en_file)\n",
        "\n",
        "#     en_tokenize = MosesTokenizer('en')\n",
        "\n",
        "#     en_data = en_tokenize(en_data)\n",
        "\n",
        "#     en_data_id = _file_to_word_ids(en_data, en_word_to_id)\n",
        "\n",
        "#     en_output, en_output_len = preprocess_train_data(en_data_id, en_word_to_id, max_length)\n",
        "\n",
        "#     out_beg_token = en_word_to_id['<beg>']*np.ones((en_output.shape[0], 1), dtype=np.int32)\n",
        "\n",
        "#     en_output = np.concatenate((out_beg_token, en_output), axis=1)\n",
        "\n",
        "#     return en_output,en_output_len"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "likRP73IFlSC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# def batch_producer(raw_data, raw_data_len, batch_size):    \n",
        "#     data_len = len(raw_data)    \n",
        "#     batch_len = data_len // batch_size    \n",
        "#     data = np.reshape(raw_data[0 : batch_size * batch_len, :], [batch_size, batch_len, -1])\n",
        "#     data = np.transpose(data, (1,0,2))\n",
        "    \n",
        "#     data_length = np.reshape(raw_data_len[0 : batch_size * batch_len], [batch_size, batch_len])\n",
        "#     data_length = np.transpose(data_length, (1,0))\n",
        "#     return data, data_length "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "O9vW-trZSFC_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# oov_id = en_word_to_id['<OOV>']\n",
        "\n",
        "# def dropout_func(decode_input, dropout_prob, oov_id=1):\n",
        "#   for i in range(decode_input.shape[0]):\n",
        "#     for j in range(decode_input.shape[1]):\n",
        "#         for k in range(1,decode_input.shape[2]):\n",
        "#             if np.random.uniform() > dropout_prob:\n",
        "#                 decode_input[i,j,k] = oov_id\n",
        "#   return decode_input"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Vva38F6OJ8B4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Data processing"
      ]
    },
    {
      "metadata": {
        "id": "LGzB7z-aRahf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# def preprocess_train_data(pre_data):\n",
        "#     pre_data_array = np.asarray(pre_data)\n",
        "#     last_start = 0\n",
        "#     max_length = 0\n",
        "#     data = []\n",
        "#     each_sen_len = []\n",
        "    \n",
        "#     for i in range(len(pre_data_array)):\n",
        "#         if pre_data_array[i]==2:\n",
        "#             data.append(pre_data_array[last_start:(i+1)])\n",
        "#             each_sen_len.append(i+1-last_start) \n",
        "#             if max_length < len(pre_data_array[last_start:(i+1)]):\n",
        "#                 max_length = len(pre_data_array[last_start:(i+1)])\n",
        "#             last_start = i+1\n",
        "            \n",
        "#     out_sentences = np.full([len(data), max_length], word_to_id['<pad>'], dtype=np.int32)\n",
        "#     for i in range(len(data)):\n",
        "#         out_sentences[i,:len(data[i])] = data[i]    \n",
        "#     return out_sentences, np.asarray(each_sen_len)\n",
        "  \n",
        "def preprocess_train_data(pre_data, word_to_id, max_length):\n",
        "    pre_data_array = np.asarray(pre_data)\n",
        "    last_start = 0\n",
        "    data = []\n",
        "    each_sen_len = []\n",
        "    \n",
        "    for i in range(len(pre_data_array)):\n",
        "        if pre_data_array[i]==word_to_id['<eos>']:\n",
        "            if max_length >= len(pre_data_array[last_start:(i+1)]):                \n",
        "              data.append(pre_data_array[last_start:(i+1)])\n",
        "              each_sen_len.append(i+1-last_start)\n",
        "              \n",
        "            else:\n",
        "              shorten_sentences = pre_data_array[last_start:(last_start+max_length-1)]\n",
        "              shorten_sentences = np.concatenate((shorten_sentences, np.asarray([word_to_id['<eos>']])), axis=0)\n",
        "              data.append(shorten_sentences)\n",
        "              each_sen_len.append(max_length) \n",
        "            \n",
        "            last_start = i+1\n",
        "            \n",
        "    out_sentences = np.full([len(data), max_length], word_to_id['<pad>'], dtype=np.int32)\n",
        "    for i in range(len(data)):\n",
        "        out_sentences[i,:len(data[i])] = data[i]    \n",
        "    return out_sentences, np.asarray(each_sen_len)\n",
        "            \n",
        "    return data, each_sen_len\n",
        "  \n",
        "  \n",
        "# def preprocess_test_data(pre_data, max_length):\n",
        "#     pre_data_array = np.asarray(pre_data)\n",
        "#     last_start = 0\n",
        "#     data = []\n",
        "#     each_sen_len = []\n",
        "    \n",
        "#     for i in range(len(pre_data_array)):\n",
        "#         if pre_data_array[i]==2:\n",
        "#             data.append(pre_data_array[last_start:(i+1)])\n",
        "#             each_sen_len.append(i+1-last_start)\n",
        "#             last_start = i+1\n",
        "            \n",
        "#     out_sentences = np.full([len(data), max_length], word_to_id['<pad>'], dtype=np.int32)\n",
        "#     for i in range(len(data)):\n",
        "#         out_sentences[i,:len(data[i])] = data[i]\n",
        "\n",
        "#     return out_sentences, np.asarray(each_sen_len)\n",
        "\n",
        "  \n",
        "  \n",
        "def ptb_producer(raw_data, raw_data_len, batch_size):    \n",
        "    data_len = len(raw_data)    \n",
        "    batch_len = data_len // batch_size    \n",
        "    data = np.reshape(raw_data[0 : batch_size * batch_len, :], [batch_size, batch_len, -1])\n",
        "    data = np.transpose(data, (1,0,2))\n",
        "    \n",
        "    data_length = np.reshape(raw_data_len[0 : batch_size * batch_len], [batch_size, batch_len])\n",
        "    data_length = np.transpose(data_length, (1,0))\n",
        "    return data, data_length "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HuTr7JFJo3Of",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def dropout_func(decode_input, dropout_prob, oov_id):\n",
        "  for i in range(decode_input.shape[0]):\n",
        "    for j in range(decode_input.shape[1]):\n",
        "        for k in range(1,decode_input.shape[2]):\n",
        "            if np.random.uniform() > dropout_prob:\n",
        "                decode_input[i,j,k] = oov_id\n",
        "  return decode_input"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "X8lcXNKLpYhT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f23449c8-26c2-48de-f417-d7294a0086f3"
      },
      "cell_type": "code",
      "source": [
        "train_data, valid_data, test_data, vocabulary, word_to_id = reader.ptb_raw_data(data_path=\"../ptb_data\")\n",
        "word_to_id['<pad>'] = 10000\n",
        "word_to_id['<beg>'] = 10001\n",
        "#word_to_id['<null>'] = 10002\n",
        "len(word_to_id) "
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10002"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "metadata": {
        "id": "oxQiy-1uJ8CF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Model"
      ]
    },
    {
      "metadata": {
        "id": "NSCJSRhXJ8CG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# set model parameter\n",
        "vocab_len = len(word_to_id)\n",
        "\n",
        "num_steps = 30\n",
        "max_length = num_steps\n",
        "batch_size = 50\n",
        "batch_size = 1\n",
        "\n",
        "embed_size = 300\n",
        "hidden_size = 500\n",
        "latent_size = 50\n",
        "\n",
        "dropout_prob = 0.7\n",
        "\n",
        "latent_num = 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Tymt8rizypNz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "###################### define placeholder ######################\n",
        "input_placeholder = tf.placeholder(tf.int32, [None, num_steps], 'input')                                # batch_size x num_steps\n",
        "decode_placeholder = tf.placeholder(tf.int32, [None, num_steps+1], 'decode_input')                        # batch_size x num_steps\n",
        "\n",
        "length_placeholder = tf.placeholder(tf.int32, [None, ], 'weight')                                       # batch_size x 1\n",
        "dropout_placeholder = tf.placeholder(tf.float32, name='dropout') \n",
        "\n",
        "discount_placeholder = tf.placeholder(tf.float32, name='discount') \n",
        "learnrate_placeholder = tf.placeholder(tf.float32, name='learnrate') \n",
        "\n",
        "if_gene_placeholder = tf.placeholder(tf.bool, name='if_gene')\n",
        "latent_var_placeholder = tf.placeholder(tf.float32, [batch_size, latent_size], 'la_var')       # batch_size x max_length x latent_size\n",
        "\n",
        "#### sequence weight of x\n",
        "squence_weight_x = tf.sequence_mask(length_placeholder, maxlen=max_length, dtype=tf.float32)                       # batch_size x max_length\n",
        "\n",
        "#########################################################\n",
        "xavier_initializer = tf.contrib.layers.xavier_initializer()\n",
        "\n",
        "\n",
        "##################### embedding look-up for input sentences ######################\n",
        "\n",
        "with tf.variable_scope('Embedding'):\n",
        "    embedding = tf.get_variable('embeding',[vocab_len, embed_size], dtype=tf.float32, initializer=xavier_initializer)\n",
        "    inputs = tf.nn.embedding_lookup(embedding, input_placeholder)                                       # batch_size x num_steps x embed_size\n",
        "    inputs = tf.transpose(inputs, (1,0,2))                                                              # num_steps x batch_size x embed_size\n",
        "    \n",
        "    decode_in = tf.nn.embedding_lookup(embedding, decode_placeholder)\n",
        "    #decode_in = tf.transpose(decode_in, (1,0,2))\n",
        "       \n",
        "    \n",
        "##################### encoder ######################\n",
        "    \n",
        "#### encoder lstm \n",
        "with tf.variable_scope('encode'):\n",
        "    basic_cell = tf.contrib.rnn.BasicLSTMCell(hidden_size, forget_bias=1.0, state_is_tuple=True)\n",
        "    init_state = basic_cell.zero_state(batch_size, tf.float32)\n",
        "    outputs, state = tf.nn.dynamic_rnn(basic_cell, inputs, sequence_length=length_placeholder, initial_state=init_state, dtype=tf.float32, time_major=True)\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nbZdZEYXy3vX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#### the fully-connected layer to obatin the mean and variance of q(z/x) \n",
        "with tf.variable_scope('latent'):\n",
        "    w_2_en = tf.get_variable('w2', [hidden_size, latent_size], dtype=tf.float32, initializer=xavier_initializer)\n",
        "    b_2_en = tf.get_variable('b2', [latent_size,], dtype=tf.float32, initializer=xavier_initializer)\n",
        "    w_3_en = tf.get_variable('w3', [hidden_size, latent_size], dtype=tf.float32, initializer=xavier_initializer)\n",
        "    b_3_en = tf.get_variable('b3', [latent_size,], dtype=tf.float32, initializer=xavier_initializer)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pcnP1uuzy61e",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#### generate sampled hidden code/latent variable \n",
        "final_hidden_state = state.h\n",
        "# outputs_tran = tf.transpose(outputs,(1,0,2))\n",
        "# final_hidden_state = tf.reshape(outputs_tran,(batch_size*num_steps, hidden_size))\n",
        "\n",
        "#### hidden mean\n",
        "mean_encode = tf.matmul(final_hidden_state,w_2_en) + b_2_en\n",
        "\n",
        "#### hidden variance\n",
        "log_var_encode = tf.matmul(final_hidden_state,w_3_en) + b_3_en\n",
        "var_encode = tf.exp(log_var_encode)\n",
        "std_encode = tf.sqrt(var_encode)\n",
        "\n",
        "#### sample the latent variable z by reparameterization trick\n",
        "eposida = tf.random_normal(tf.shape(std_encode), mean=0.0,stddev=1)\n",
        "hidden_code = mean_encode + std_encode*eposida                                                          # batch_size x latent_size\n",
        "      \n",
        "    \n",
        "#### KL Divergence loss  \n",
        "#### could be calculated in closed form since both q(z/x) and p(z) are assumed to be Gaussian distribution\n",
        "\n",
        "kl_div_loss = 1 + log_var_encode - tf.square(mean_encode) - var_encode     # batch_size*num_steps x latent_size\n",
        "kl_div_loss = -0.5 * tf.reduce_sum(kl_div_loss, axis=1)                    # batch_size*num_steps x 1\n",
        "#kl_div_loss = tf.reshape(kl_div_loss, (batch_size, num_steps))\n",
        "#kl_div_loss = tf.reduce_sum(kl_div_loss*squence_weight_x, axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_UtsMQXyl7or",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "hidden_code = latent_var_placeholder"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xiv6Gfo2cCBQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "##################### decoder ######################\n",
        "\n",
        "#### input for decoder lstm\n",
        "stacked_hidden_code = []\n",
        "for i in range(num_steps):\n",
        "    stacked_hidden_code.append(hidden_code)\n",
        "    \n",
        "stacked_hidden_code = tf.stack(stacked_hidden_code, axis=1)         # batch_size x num_steps x latent_size\n",
        "\n",
        "#stacked_hidden_code = tf.reshape(hidden_code, (batch_size, num_steps, latent_size))\n",
        "\n",
        "\n",
        "x_input_cnn = tf.concat([stacked_hidden_code, decode_in[:,:num_steps, :]], 2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "09lXYW41cZEU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "filter_num = 150\n",
        "\n",
        "with tf.variable_scope('x_con_dialted_1D'):\n",
        "  \n",
        "    f_x_1 = tf.get_variable(\"x_filter_1\", shape=[2, embed_size+latent_size, filter_num], dtype=tf.float32, initializer=xavier_initializer)\n",
        "    f_x_1_dia = tf.concat([f_x_1, \n",
        "                           tf.zeros(shape=[1, embed_size+latent_size, filter_num], dtype=tf.float32)],axis=0)                                      \n",
        "    # 3 x (embed_size+latent_size) x filter_num\n",
        "    \n",
        "    f_x_2 = tf.get_variable(\"x_filter_2\", shape=[3, filter_num, filter_num], dtype=tf.float32, initializer=xavier_initializer)\n",
        "    f_x_2_dia = tf.concat([tf.reshape(f_x_2[0],(1,filter_num,filter_num)), \n",
        "                           tf.zeros((1,filter_num,filter_num)), \n",
        "                           tf.reshape(f_x_2[1],(1,filter_num,filter_num)), \n",
        "                           tf.zeros((1,filter_num,filter_num)),\n",
        "                           tf.reshape(f_x_2[2],(1,filter_num,filter_num)),\n",
        "                           tf.zeros((4,filter_num,filter_num)),], axis=0)\n",
        "    # 9 x filter_num x filter_num\n",
        "    \n",
        "    f_x_3 = tf.get_variable(\"x_filter_3\", shape=[3, filter_num, filter_num], dtype=tf.float32, initializer=xavier_initializer)\n",
        "    f_x_3_dia = tf.concat([tf.reshape(f_x_3[0],(1,filter_num,filter_num)), \n",
        "                           tf.zeros((3,filter_num,filter_num)), \n",
        "                           tf.reshape(f_x_3[1],(1,filter_num,filter_num)), \n",
        "                           tf.zeros((3,filter_num,filter_num)),\n",
        "                           tf.reshape(f_x_3[2],(1,filter_num,filter_num)),\n",
        "                           tf.zeros((8,filter_num,filter_num))], axis=0)\n",
        "    # 13 x filter_num x filter_num\n",
        "    \n",
        "    f_x_4 = tf.get_variable(\"x_filter_4\", shape=[3, filter_num, filter_num], dtype=tf.float32, initializer=xavier_initializer)\n",
        "    f_x_4_dia = tf.concat([tf.reshape(f_x_4[0],(1,filter_num,filter_num)), \n",
        "                           tf.zeros((7,filter_num,filter_num)), \n",
        "                           tf.reshape(f_x_4[1],(1,filter_num,filter_num)), \n",
        "                           tf.zeros((7,filter_num,filter_num)),\n",
        "                           tf.reshape(f_x_4[2],(1,filter_num,filter_num)),\n",
        "                           tf.zeros((16,filter_num,filter_num))], axis=0)\n",
        "    # 21 x filter_num x filter_num\n",
        "    \n",
        "#     f_x_5 = tf.get_variable(\"x_filter_5\", shape=[2, filter_num, filter_num], dtype=tf.float32, initializer=xavier_initializer)\n",
        "#     f_x_5_dia = tf.concat([f_x_5, \n",
        "#                            tf.zeros(shape=[1, filter_num, filter_num], dtype=tf.float32)],axis=0)                                      \n",
        "#     # 3 x (embed_size+latent_size) x filter_num\n",
        "    \n",
        "    \n",
        "#     f_x_6 = tf.get_variable(\"x_filter_6\", shape=[3, filter_num, filter_num], dtype=tf.float32, initializer=xavier_initializer)\n",
        "#     f_x_6_dia = tf.concat([tf.reshape(f_x_6[0],(1,filter_num,filter_num)), \n",
        "#                            tf.zeros((1,filter_num,filter_num)), \n",
        "#                            tf.reshape(f_x_6[1],(1,filter_num,filter_num)), \n",
        "#                            tf.zeros((1,filter_num,filter_num)),\n",
        "#                            tf.reshape(f_x_6[2],(1,filter_num,filter_num)),\n",
        "#                            tf.zeros((4,filter_num,filter_num)),], axis=0)\n",
        "#     # 9 x filter_num x filter_num\n",
        "    \n",
        "#     f_x_7 = tf.get_variable(\"x_filter_7\", shape=[3, filter_num, filter_num], dtype=tf.float32, initializer=xavier_initializer)\n",
        "#     f_x_7_dia = tf.concat([tf.reshape(f_x_7[0],(1,filter_num,filter_num)), \n",
        "#                            tf.zeros((3,filter_num,filter_num)), \n",
        "#                            tf.reshape(f_x_7[1],(1,filter_num,filter_num)), \n",
        "#                            tf.zeros((3,filter_num,filter_num)),\n",
        "#                            tf.reshape(f_x_7[2],(1,filter_num,filter_num)),\n",
        "#                            tf.zeros((8,filter_num,filter_num))], axis=0)\n",
        "#     # 13 x filter_num x filter_num\n",
        "    \n",
        "#     f_x_8 = tf.get_variable(\"x_filter_8\", shape=[3, filter_num, filter_num], dtype=tf.float32, initializer=xavier_initializer)\n",
        "#     f_x_8_dia = tf.concat([tf.reshape(f_x_8[0],(1,filter_num,filter_num)), \n",
        "#                            tf.zeros((7,filter_num,filter_num)), \n",
        "#                            tf.reshape(f_x_8[1],(1,filter_num,filter_num)), \n",
        "#                            tf.zeros((7,filter_num,filter_num)),\n",
        "#                            tf.reshape(f_x_8[2],(1,filter_num,filter_num)),\n",
        "#                            tf.zeros((16,filter_num,filter_num))], axis=0)\n",
        "#     # 21 x filter_num x filter_num\n",
        "    \n",
        "    \n",
        "    \n",
        "#     f_x_5 = tf.get_variable(\"x_filter_5\", shape=[3, filter_num, filter_num], dtype=tf.float32, initializer=xavier_initializer)\n",
        "#     f_x_5_dia = tf.concat([tf.reshape(f_x_5[0],(1,filter_num,filter_num)), \n",
        "#                            tf.zeros((8,filter_num,filter_num)), \n",
        "#                            tf.reshape(f_x_5[1],(1,filter_num,filter_num)), \n",
        "#                            tf.zeros((8,filter_num,filter_num)),\n",
        "#                            tf.reshape(f_x_5[2],(1,filter_num,filter_num)),\n",
        "#                            tf.zeros((18,filter_num,filter_num))], axis=0)\n",
        "#     # 29 x filter_num x filter_num\n",
        "    \n",
        "# #### variablen of a FC layer to map the hidden state of the decoder-rnn in each time-step to the predicted next word\n",
        "# with tf.variable_scope('project'):\n",
        "#     U = tf.get_variable('rnn_output_w', [filter_num_half,embed_size], dtype=tf.float32, initializer=xavier_initializer)\n",
        "#     proj_b = tf.get_variable('rnn_output_b', [embed_size,], dtype=tf.float32, initializer=xavier_initializer)\n",
        "    \n",
        "#### variablen of a FC layer to map the hidden state of the decoder-rnn in each time-step to the predicted next word\n",
        "with tf.variable_scope('projection_x'):\n",
        "    proj_w_x = tf.get_variable('project_w_x', [filter_num,embed_size], dtype=tf.float32, initializer=xavier_initializer)\n",
        "    proj_b_x = tf.get_variable('project_b_x', [embed_size,], dtype=tf.float32, initializer=xavier_initializer)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "j2apv8whscKn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# x_out_conv_dia_1 = tf.nn.conv1d(x_input_cnn, f_x_1_dia, stride=1, padding='SAME')                     # batch_size x max_length x filter_num\n",
        "# x_out_conv_dia_2 = tf.nn.conv1d(x_out_conv_dia_1, f_x_2_dia, stride=1, padding='SAME')                # batch_size x max_length x filter_num\n",
        "# x_out_conv_dia_3 = tf.nn.conv1d(x_out_conv_dia_2, f_x_3_dia, stride=1, padding='SAME')                # batch_size x max_length x filter_num\n",
        "# x_out_conv_dia_4 = tf.nn.conv1d(x_out_conv_dia_3, f_x_4_dia, stride=1, padding='SAME')                # batch_size x max_length x filter_num\n",
        "# x_out_conv_dia_5 = tf.nn.conv1d(x_out_conv_dia_4, f_x_5_dia, stride=1, padding='SAME')                # batch_size x max_length x filter_num\n",
        "\n",
        "# x_out_conv_dia_5_gated = x_out_conv_dia_5[:,:,:75]*tf.nn.sigmoid(x_out_conv_dia_5[:,:,75:])\n",
        "\n",
        "# x_out_conv_dia = tf.reshape(x_out_conv_dia_5_gated, (batch_size*max_length, filter_num_half))\n",
        "\n",
        "# x_out_project = tf.matmul(x_out_conv_dia, U) + proj_b                                                 # batch_size*max_length x embed_size\n",
        "# targets = tf.reshape(tf.transpose(inputs, (1,0,2)), [batch_size*num_steps, embed_size])               # batch_size*max_length x embed_size\n",
        "\n",
        "# x_targets = tf.reduce_sum(x_out_project*targets, axis=1)                                              # batch_size*max_length x 1\n",
        "# x_logits = tf.matmul(x_out_project, tf.transpose(embedding,(1,0)))                                    # batch_size*max_length x voab_len\n",
        "\n",
        "# x_logits_re = tf.reshape(x_logits, (batch_size, max_length, vocab_len))\n",
        "# x_max = tf.reshape(tf.reduce_max(x_logits_re, axis=2), (batch_size*max_length, 1))\n",
        "\n",
        "# prob_unnorm = tf.exp(tf.reshape(x_targets, (batch_size*max_length, 1)) - x_max)\n",
        "# prob_constant = tf.exp(x_logits - tf.tile(x_max,(1, vocab_len)))\n",
        "\n",
        "# prob_norm = prob_unnorm/tf.reshape(tf.reduce_sum(prob_constant, axis=1), (batch_size*max_length, 1))\n",
        "\n",
        "# log_prob_norm = tf.log(prob_norm)\n",
        "\n",
        "# log_prob_norm = tf.reshape(log_prob_norm, [batch_size, num_steps])\n",
        "\n",
        "# #### sequence weight\n",
        "# squence_weight = tf.sequence_mask(length_placeholder, maxlen=num_steps, dtype=tf.float32)\n",
        "\n",
        "# cross_entropy = - tf.reduce_sum(log_prob_norm*squence_weight, axis=1)\n",
        "\n",
        "# batch_lowerbound = cross_entropy + discount_placeholder*kl_div_loss  # batch_size x 1\n",
        "\n",
        "# batch_lowerbound_mean = tf.reduce_mean(batch_lowerbound)  \n",
        "\n",
        "# #### optimizer\n",
        "# opt = tf.train.AdamOptimizer(learnrate_placeholder).minimize(batch_lowerbound_mean)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "f5PQXZhbcboC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def x_decoder(de_input):\n",
        "  \n",
        "  x_out_conv_dia_1 = tf.nn.conv1d(de_input, f_x_1_dia, stride=1, padding='SAME')                     # batch_size x max_length x filter_num\n",
        "  x_out_conv_dia_2 = tf.nn.conv1d(x_out_conv_dia_1, f_x_2_dia, stride=1, padding='SAME')                # batch_size x max_length x filter_num\n",
        "  x_out_conv_dia_3 = tf.nn.conv1d(x_out_conv_dia_2, f_x_3_dia, stride=1, padding='SAME')                # batch_size x max_length x filter_num\n",
        "  x_out_conv_dia_4 = tf.nn.conv1d(x_out_conv_dia_3, f_x_4_dia, stride=1, padding='SAME')                # batch_size x max_length x filter_num\n",
        "  #x_out_conv_dia_5 = tf.nn.conv1d(x_out_conv_dia_4, f_x_5_dia, stride=1, padding='SAME')                # batch_size x max_length x filter_num\n",
        "  \n",
        "#   x_out_conv_dia_5 = tf.nn.conv1d(x_out_conv_dia_4, f_x_5_dia, stride=1, padding='SAME')                     # batch_size x max_length x filter_num\n",
        "#   x_out_conv_dia_6 = tf.nn.conv1d(x_out_conv_dia_5, f_x_6_dia, stride=1, padding='SAME')                # batch_size x max_length x filter_num\n",
        "#   x_out_conv_dia_7 = tf.nn.conv1d(x_out_conv_dia_6, f_x_7_dia, stride=1, padding='SAME')                # batch_size x max_length x filter_num\n",
        "#   x_out_conv_dia_8 = tf.nn.conv1d(x_out_conv_dia_7, f_x_8_dia, stride=1, padding='SAME')                # batch_size x max_length x filter_num\n",
        "#   #x_out_conv_dia_5 = tf.nn.conv1d(x_out_conv_dia_4, f_x_5_dia, stride=1, padding='SAME')                # batch_size x max_length x filter_num\n",
        "  \n",
        "  #x_out_conv_dia_4_gated = x_out_conv_dia_4[:,:,:75]*tf.nn.sigmoid(x_out_conv_dia_4[:,:,75:])\n",
        "  \n",
        "  x_out_conv_dia = tf.reshape(x_out_conv_dia_4, (batch_size*max_length, filter_num))\n",
        "  x_out_project = tf.matmul(x_out_conv_dia, proj_w_x) + proj_b_x                                       # batch_size*max_length x embed_size \n",
        "  \n",
        "  cnn_inputs = tf.transpose(inputs, (1,0,2))\n",
        "  \n",
        "  target_x = tf.reduce_sum(x_out_project*tf.reshape(cnn_inputs, (batch_size*max_length, embed_size)), axis=1)\n",
        "  logits_x = tf.matmul(x_out_project, tf.transpose(embedding,(1,0)))\n",
        "\n",
        "  logits_x_re = tf.reshape(logits_x, (batch_size, max_length, vocab_len))                                   # batch_size x max_length x fr_vocab_size\n",
        "  x_max = tf.reshape(tf.reduce_max(logits_x_re, axis=2), (batch_size*max_length, 1))                            # batch_size*max_length x 1\n",
        "\n",
        "  prob_unnorm_x = tf.exp(tf.reshape(target_x, (batch_size*max_length, 1)) - x_max)                                                                      # batch_size*max_length x 1\n",
        "  prob_constant_x = tf.exp(logits_x - tf.tile(x_max,(1, vocab_len)))                                        # batch_size*max_length x fr_vocab_size\n",
        "                                           \n",
        "  prob_norm_x = prob_unnorm_x/tf.reshape(tf.reduce_sum(prob_constant_x, axis=1), (batch_size*max_length, 1))              # batch_size*max_length x 1\n",
        "  prob_norm_x = tf.reshape(prob_norm_x, (batch_size, max_length))                                                         # batch_size x max_length\n",
        "  log_prob_norm_x = tf.log(tf.clip_by_value(prob_norm_x,1e-8,1.0))                                                        # batch_size x max_length\n",
        "\n",
        "  log_liki_x = tf.reduce_sum(log_prob_norm_x*squence_weight_x, axis=1)                                                    # batch_size x 1\n",
        "  return log_liki_x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "B8VtWwu2nAKp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x_out_conv_dia_1 = tf.nn.conv1d(x_input_cnn, f_x_1_dia, stride=1, padding='SAME')                     # batch_size x max_length x filter_num\n",
        "x_out_conv_dia_2 = tf.nn.conv1d(x_out_conv_dia_1, f_x_2_dia, stride=1, padding='SAME')                # batch_size x max_length x filter_num\n",
        "x_out_conv_dia_3 = tf.nn.conv1d(x_out_conv_dia_2, f_x_3_dia, stride=1, padding='SAME')                # batch_size x max_length x filter_num\n",
        "x_out_conv_dia_4 = tf.nn.conv1d(x_out_conv_dia_3, f_x_4_dia, stride=1, padding='SAME')                # batch_size x max_length x filter_num\n",
        "  \n",
        "x_out_conv_dia = tf.reshape(x_out_conv_dia_4, (batch_size*max_length, filter_num))\n",
        "x_out_project = tf.matmul(x_out_conv_dia, proj_w_x) + proj_b_x                                       # batch_size*max_length x embed_size \n",
        "  \n",
        "cnn_inputs = tf.transpose(inputs, (1,0,2))\n",
        "                                                                     # batch_size*max_length x 1\n",
        "prob_constant = tf.exp(tf.matmul(x_out_project, tf.transpose(embedding,(1,0))))                                        # batch_size*max_length x fr_vocab_size"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1YNXfoTxoiGs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# # L2 reguralization for trainable variables\n",
        "# train_variables = tf.trainable_variables()\n",
        "# regularization_cost = tf.reduce_sum([tf.nn.l2_loss(variable) for variable in train_variables])\n",
        "# regular_rate = 0.0005"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2a_CM_VXzEN3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "log_liki_x = x_decoder(x_input_cnn)\n",
        "\n",
        "batch_lowerbound = -log_liki_x + discount_placeholder*kl_div_loss  # batch_size x 1\n",
        "\n",
        "batch_lowerbound_mean = tf.reduce_mean(batch_lowerbound)  \n",
        "\n",
        "objective = batch_lowerbound_mean #+ regular_rate*regularization_cost\n",
        "\n",
        "#### optimizer\n",
        "opt = tf.train.AdamOptimizer(learnrate_placeholder).minimize(objective)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kmVRhGr6zHbx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#### save the model\n",
        "def save_model(session, path):\n",
        "    if not os.path.exists(\"./result_0818/\"):\n",
        "        os.mkdir('./result_0818/')\n",
        "    saver = tf.train.Saver()\n",
        "    saver.save(session, path)\n",
        "\n",
        "path1 = './result_0818/model_each_epch.ckpt'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lLVT3gWClW3l",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def sigmoid(x):\n",
        "    return (1 / (1 + math.exp(-x)))\n",
        "\n",
        "\n",
        "def text_save(content,filename,mode='a'):\n",
        "    # Try to save a list variable in txt file.\n",
        "    file = open(filename,mode)\n",
        "    for i in range(len(content)):\n",
        "        file.write(str(content[i])+'\\n')\n",
        "    file.close()\n",
        "    \n",
        "def text_read(filename):\n",
        "    # Try to read a txt file and return a list.Return [] if there was a mistake.\n",
        "    try:\n",
        "        file = open(filename,'r')\n",
        "    except IOError:\n",
        "        error = []\n",
        "        return error\n",
        "    content = file.readlines()\n",
        " \n",
        "    for i in range(len(content)):\n",
        "        content[i] = content[i][:len(content[i])-1]\n",
        " \n",
        "    file.close()\n",
        "    return content"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7A4E-S4RJ8CP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Train"
      ]
    },
    {
      "metadata": {
        "id": "ufeUL2j-s3rB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_input, train_sen_len = preprocess_train_data(train_data, word_to_id,max_length)\n",
        "\n",
        "valid_input, valid_sen_len = preprocess_train_data(valid_data,word_to_id, max_length)\n",
        "\n",
        "test_input, test_sen_len = preprocess_train_data(test_data,word_to_id,max_length)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2jF7XbJis6T7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_beg_token = 10001*np.ones((train_input.shape[0],1), dtype=np.int32)\n",
        "train_decode_input = np.concatenate((train_beg_token, train_input), axis=1)\n",
        "\n",
        "train_input_data, train_len_data = ptb_producer(train_input, train_sen_len, batch_size)\n",
        "train_decode_input_data, train_decode_len_data = ptb_producer(train_decode_input, train_sen_len, batch_size)\n",
        "train_decode_input_data = dropout_func(train_decode_input_data, dropout_prob,word_to_id['<unk>'])\n",
        "\n",
        "valid_beg_token = 10001*np.ones((valid_input.shape[0],1), dtype=np.int32)\n",
        "valid_decode_input = np.concatenate((valid_beg_token, valid_input), axis=1)\n",
        "\n",
        "valid_input_data, valid_len_data = ptb_producer(valid_input, valid_sen_len, batch_size)\n",
        "valid_decode_input_data, valid_decode_len_data = ptb_producer(valid_decode_input, valid_sen_len, batch_size)\n",
        "#valid_decode_input_data = dropout_func(valid_decode_input_data, dropout_prob,word_to_id['<unk>'])\n",
        "\n",
        "test_beg_token = 10001*np.ones((test_input.shape[0],1), dtype=np.int32)\n",
        "test_decode_input = np.concatenate((test_beg_token, test_input), axis=1)\n",
        "\n",
        "test_input_data, test_len_data = ptb_producer(test_input, test_sen_len, batch_size)\n",
        "test_decode_input_data, test_decode_len_data = ptb_producer(test_decode_input, test_sen_len, batch_size)\n",
        "#test_decode_input_data = dropout_func(test_decode_input_data, dropout_prob,word_to_id['<unk>'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_mHKxeQqs77O",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "record_index = np.random.randint(low=0, high=train_input.shape[0]-1, size=3000)\n",
        "en_train_record = train_input[record_index]\n",
        "en_de_train_record = train_decode_input[record_index]\n",
        "en_train_len_record = train_sen_len[record_index]\n",
        "\n",
        "en_train_record_data, en_train_len_record_data = ptb_producer(en_train_record, en_train_len_record, batch_size)\n",
        "en_de_train_record_data, en_train_len_record_data = ptb_producer(en_de_train_record, en_train_len_record, batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YJLFGA40Nelx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 13794
        },
        "outputId": "1d347bb7-3007-43f3-b4f6-b03af66cae7d"
      },
      "cell_type": "code",
      "source": [
        "train_ce = []\n",
        "train_kl = []\n",
        "train_ll = []\n",
        "kl_weight = []\n",
        "\n",
        "test_ce = []\n",
        "test_kl = []\n",
        "test_ll = []\n",
        "\n",
        "init = tf.global_variables_initializer()\n",
        "max_epochs = 10\n",
        "learningrate = 0.001\n",
        "\n",
        "total_step = 0\n",
        "discount_rate = 0\n",
        "\n",
        "with tf.Session() as sess:\n",
        "  \n",
        "    sess.run(init)\n",
        "        \n",
        "    for epoc in range(max_epochs):\n",
        "      \n",
        "        print('Epoch {}'.format(epoc))\n",
        "              \n",
        "        \n",
        "        ########### training ###########\n",
        "        for i in range(train_input_data.shape[0]):\n",
        "            \n",
        "            #discount_rate = sigmoid(0.0025*(total_step-2500))\n",
        "            discount_rate = 0.0002*total_step\n",
        "            if discount_rate >1:\n",
        "              discount_rate = 1\n",
        "              \n",
        "            feed_dict = {input_placeholder: train_input_data[i],\n",
        "                         decode_placeholder: train_decode_input_data[i],\n",
        "                         length_placeholder: train_len_data[i],\n",
        "                         discount_placeholder: discount_rate,\n",
        "                         learnrate_placeholder: learningrate} \n",
        "            \n",
        "            _ = sess.run(opt, feed_dict=feed_dict)\n",
        "                    \n",
        "\n",
        "            if total_step%100 == 0:\n",
        "              \n",
        "              train_ce_one = []\n",
        "              train_kl_one = []\n",
        "              train_ll_one = []\n",
        "              for t in range(en_train_record_data.shape[0]):\n",
        "                feed_dict = {input_placeholder: en_train_record_data[t],\n",
        "                             decode_placeholder: en_de_train_record_data[t],\n",
        "                             length_placeholder: en_train_len_record_data[t],\n",
        "                             discount_placeholder: 1}\n",
        "              \n",
        "                ce, kl, ll_mean = sess.run([log_liki_x, kl_div_loss, batch_lowerbound_mean], feed_dict=feed_dict)\n",
        "                train_ce_one.append(np.mean(ce))\n",
        "                train_kl_one.append(np.mean(kl))\n",
        "                train_ll_one.append(ll_mean)\n",
        "             \n",
        "              print(\"training\")\n",
        "              print(discount_rate)\n",
        "              print(np.mean(ce))\n",
        "              print(np.mean(kl))\n",
        "              print(ll_mean)\n",
        "             \n",
        "              train_ce.append(np.mean(ce))\n",
        "              train_kl.append(np.mean(kl))\n",
        "              train_ll.append(ll_mean)\n",
        "              kl_weight.append(discount_rate)\n",
        "                            \n",
        "              test_ce_one = []\n",
        "              test_kl_one = []\n",
        "              test_ll_one = []\n",
        "              for t in range(valid_input_data.shape[0]):\n",
        "                test_feed_dict = {input_placeholder:  valid_input_data[t],\n",
        "                                  decode_placeholder: valid_decode_input_data[t],\n",
        "                                  length_placeholder: valid_len_data[t],\n",
        "                                  discount_placeholder: 1}\n",
        "                \n",
        "                ce, kl, ll_mean = sess.run([log_liki_x, kl_div_loss, batch_lowerbound_mean], feed_dict=test_feed_dict)\n",
        "              \n",
        "                test_ce_one.append(np.mean(ce))\n",
        "                test_kl_one.append(np.mean(kl))\n",
        "                test_ll_one.append(ll_mean)\n",
        "              \n",
        "              print(\"testing\")\n",
        "              print(np.mean(test_ce_one))\n",
        "              print(np.mean(test_kl_one))\n",
        "              print(np.mean(test_ll_one))\n",
        "              test_ce.append(np.mean(test_ce_one))\n",
        "              test_kl.append(np.mean(test_kl_one))\n",
        "              test_ll.append(np.mean(test_ll_one))\n",
        "              \n",
        "            total_step = total_step + 1             \n",
        "                      \n",
        "        save_model(sess, path1)\n",
        "        \n",
        "text_save(train_ce, './result_0818/train_ce.txt')\n",
        "text_save(train_kl, './result_0818/train_kl.txt')\n",
        "text_save(train_ll, './result_0818/train_ll.txt')\n",
        "text_save(kl_weight,'./result_0818/kl_weight.txt')\n",
        "\n",
        "text_save(test_ce,  './result_0818/test_ce.txt')\n",
        "text_save(test_kl,  './result_0818/test_kl.txt')\n",
        "text_save(test_ll,  './result_0818/test_ll.txt')"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0\n",
            "training\n",
            "0.0\n",
            "-189.68079\n",
            "0.6903163\n",
            "190.37111\n",
            "testing\n",
            "-188.75214\n",
            "0.69041926\n",
            "189.44255\n",
            "training\n",
            "0.02\n",
            "-134.79079\n",
            "23.643845\n",
            "158.43463\n",
            "testing\n",
            "-133.5839\n",
            "24.28784\n",
            "157.87173\n",
            "training\n",
            "0.04\n",
            "-130.48962\n",
            "15.788814\n",
            "146.27841\n",
            "testing\n",
            "-128.43864\n",
            "15.465944\n",
            "143.90459\n",
            "training\n",
            "0.060000000000000005\n",
            "-127.15405\n",
            "13.593588\n",
            "140.74763\n",
            "testing\n",
            "-123.77763\n",
            "13.317063\n",
            "137.09468\n",
            "training\n",
            "0.08\n",
            "-122.7442\n",
            "12.309674\n",
            "135.05388\n",
            "testing\n",
            "-120.03277\n",
            "11.74282\n",
            "131.77559\n",
            "training\n",
            "0.1\n",
            "-120.13073\n",
            "11.8572\n",
            "131.98793\n",
            "testing\n",
            "-117.55321\n",
            "11.305182\n",
            "128.8584\n",
            "training\n",
            "0.12000000000000001\n",
            "-119.16187\n",
            "10.717364\n",
            "129.87924\n",
            "testing\n",
            "-116.07893\n",
            "10.290593\n",
            "126.36952\n",
            "training\n",
            "0.14\n",
            "-116.152824\n",
            "11.04569\n",
            "127.19852\n",
            "testing\n",
            "-113.91326\n",
            "10.588486\n",
            "124.50176\n",
            "training\n",
            "0.16\n",
            "-114.75547\n",
            "10.322902\n",
            "125.07837\n",
            "testing\n",
            "-112.662025\n",
            "10.050368\n",
            "122.712395\n",
            "Epoch 1\n",
            "training\n",
            "0.18000000000000002\n",
            "-114.57973\n",
            "9.885702\n",
            "124.46545\n",
            "testing\n",
            "-112.572\n",
            "9.599565\n",
            "122.17156\n",
            "training\n",
            "0.2\n",
            "-112.89566\n",
            "9.944808\n",
            "122.84047\n",
            "testing\n",
            "-110.766396\n",
            "10.086105\n",
            "120.8525\n",
            "training\n",
            "0.22\n",
            "-112.61412\n",
            "9.797835\n",
            "122.411964\n",
            "testing\n",
            "-110.40824\n",
            "9.754043\n",
            "120.16228\n",
            "training\n",
            "0.24000000000000002\n",
            "-111.3996\n",
            "9.808381\n",
            "121.207985\n",
            "testing\n",
            "-109.863884\n",
            "9.7738\n",
            "119.63768\n",
            "training\n",
            "0.26\n",
            "-110.81145\n",
            "10.532879\n",
            "121.34433\n",
            "testing\n",
            "-108.53264\n",
            "10.327695\n",
            "118.860344\n",
            "training\n",
            "0.28\n",
            "-110.61426\n",
            "10.085596\n",
            "120.699844\n",
            "testing\n",
            "-108.33587\n",
            "9.848334\n",
            "118.18421\n",
            "training\n",
            "0.3\n",
            "-108.50694\n",
            "10.616002\n",
            "119.12295\n",
            "testing\n",
            "-107.50329\n",
            "10.389861\n",
            "117.89314\n",
            "training\n",
            "0.32\n",
            "-108.190094\n",
            "10.858337\n",
            "119.04845\n",
            "testing\n",
            "-107.03558\n",
            "10.369733\n",
            "117.40531\n",
            "Epoch 2\n",
            "training\n",
            "0.34\n",
            "-106.639725\n",
            "10.9756565\n",
            "117.61539\n",
            "testing\n",
            "-106.58399\n",
            "10.568402\n",
            "117.1524\n",
            "training\n",
            "0.36000000000000004\n",
            "-107.09468\n",
            "10.898418\n",
            "117.993095\n",
            "testing\n",
            "-106.87069\n",
            "10.350664\n",
            "117.22136\n",
            "training\n",
            "0.38\n",
            "-105.74809\n",
            "10.700691\n",
            "116.44879\n",
            "testing\n",
            "-106.04242\n",
            "10.223396\n",
            "116.26583\n",
            "training\n",
            "0.4\n",
            "-106.500656\n",
            "10.900854\n",
            "117.40151\n",
            "testing\n",
            "-106.03657\n",
            "10.562702\n",
            "116.59927\n",
            "training\n",
            "0.42000000000000004\n",
            "-105.79052\n",
            "10.6033535\n",
            "116.39387\n",
            "testing\n",
            "-105.72476\n",
            "10.174471\n",
            "115.89923\n",
            "training\n",
            "0.44\n",
            "-105.37405\n",
            "10.821324\n",
            "116.19537\n",
            "testing\n",
            "-105.2349\n",
            "10.466656\n",
            "115.70156\n",
            "training\n",
            "0.46\n",
            "-104.58769\n",
            "10.305752\n",
            "114.89345\n",
            "testing\n",
            "-105.48245\n",
            "9.87359\n",
            "115.35604\n",
            "training\n",
            "0.48000000000000004\n",
            "-103.46687\n",
            "10.342127\n",
            "113.80898\n",
            "testing\n",
            "-105.0581\n",
            "9.814012\n",
            "114.8721\n",
            "training\n",
            "0.5\n",
            "-103.39272\n",
            "9.924871\n",
            "113.3176\n",
            "testing\n",
            "-105.37923\n",
            "9.496515\n",
            "114.87574\n",
            "Epoch 3\n",
            "training\n",
            "0.52\n",
            "-104.11664\n",
            "10.056274\n",
            "114.17291\n",
            "testing\n",
            "-105.97571\n",
            "9.6917305\n",
            "115.667435\n",
            "training\n",
            "0.54\n",
            "-102.77905\n",
            "9.811086\n",
            "112.59013\n",
            "testing\n",
            "-104.81018\n",
            "9.399263\n",
            "114.209435\n",
            "training\n",
            "0.56\n",
            "-104.23007\n",
            "9.293617\n",
            "113.52368\n",
            "testing\n",
            "-105.36875\n",
            "9.0105\n",
            "114.37926\n",
            "training\n",
            "0.5800000000000001\n",
            "-102.868904\n",
            "9.701781\n",
            "112.57067\n",
            "testing\n",
            "-104.869385\n",
            "9.352164\n",
            "114.22155\n",
            "training\n",
            "0.6\n",
            "-103.73325\n",
            "9.344551\n",
            "113.07781\n",
            "testing\n",
            "-105.21028\n",
            "9.0789175\n",
            "114.28921\n",
            "training\n",
            "0.62\n",
            "-102.12039\n",
            "9.269756\n",
            "111.390144\n",
            "testing\n",
            "-105.36322\n",
            "8.966102\n",
            "114.329315\n",
            "training\n",
            "0.64\n",
            "-100.107346\n",
            "9.005811\n",
            "109.11315\n",
            "testing\n",
            "-105.45365\n",
            "8.64471\n",
            "114.09836\n",
            "training\n",
            "0.66\n",
            "-101.322716\n",
            "8.922096\n",
            "110.244804\n",
            "testing\n",
            "-105.73155\n",
            "8.575338\n",
            "114.3069\n",
            "Epoch 4\n",
            "training\n",
            "0.68\n",
            "-101.06996\n",
            "8.490681\n",
            "109.56062\n",
            "testing\n",
            "-105.652084\n",
            "8.145581\n",
            "113.79765\n",
            "training\n",
            "0.7000000000000001\n",
            "-100.81044\n",
            "8.05209\n",
            "108.862526\n",
            "testing\n",
            "-106.45554\n",
            "7.8203673\n",
            "114.27591\n",
            "training\n",
            "0.7200000000000001\n",
            "-99.75071\n",
            "8.038668\n",
            "107.789375\n",
            "testing\n",
            "-105.96165\n",
            "7.7145886\n",
            "113.67624\n",
            "training\n",
            "0.74\n",
            "-101.238815\n",
            "8.010807\n",
            "109.249626\n",
            "testing\n",
            "-106.232994\n",
            "7.708347\n",
            "113.94134\n",
            "training\n",
            "0.76\n",
            "-102.173225\n",
            "7.8856034\n",
            "110.05884\n",
            "testing\n",
            "-106.38842\n",
            "7.468056\n",
            "113.85647\n",
            "training\n",
            "0.78\n",
            "-100.90349\n",
            "7.365132\n",
            "108.268616\n",
            "testing\n",
            "-106.82017\n",
            "7.105373\n",
            "113.92554\n",
            "training\n",
            "0.8\n",
            "-101.608665\n",
            "7.233015\n",
            "108.84167\n",
            "testing\n",
            "-107.643715\n",
            "6.978855\n",
            "114.62257\n",
            "training\n",
            "0.8200000000000001\n",
            "-100.588524\n",
            "7.148375\n",
            "107.73689\n",
            "testing\n",
            "-107.13963\n",
            "6.8487363\n",
            "113.988365\n",
            "training\n",
            "0.8400000000000001\n",
            "-99.832214\n",
            "6.825296\n",
            "106.65752\n",
            "testing\n",
            "-106.91886\n",
            "6.4675884\n",
            "113.38645\n",
            "Epoch 5\n",
            "training\n",
            "0.86\n",
            "-100.83921\n",
            "6.87092\n",
            "107.71011\n",
            "testing\n",
            "-107.60711\n",
            "6.576122\n",
            "114.183235\n",
            "training\n",
            "0.88\n",
            "-101.384346\n",
            "6.439294\n",
            "107.82363\n",
            "testing\n",
            "-107.88251\n",
            "6.0956044\n",
            "113.97811\n",
            "training\n",
            "0.9\n",
            "-101.539505\n",
            "6.3217454\n",
            "107.86125\n",
            "testing\n",
            "-108.36497\n",
            "6.0135446\n",
            "114.3785\n",
            "training\n",
            "0.92\n",
            "-100.90497\n",
            "6.0907445\n",
            "106.99571\n",
            "testing\n",
            "-107.83799\n",
            "5.8081083\n",
            "113.64609\n",
            "training\n",
            "0.9400000000000001\n",
            "-101.645744\n",
            "5.906597\n",
            "107.552345\n",
            "testing\n",
            "-108.47213\n",
            "5.568716\n",
            "114.04085\n",
            "training\n",
            "0.9600000000000001\n",
            "-100.20961\n",
            "5.919941\n",
            "106.12955\n",
            "testing\n",
            "-108.67178\n",
            "5.6406984\n",
            "114.31247\n",
            "training\n",
            "0.9800000000000001\n",
            "-98.44419\n",
            "5.505133\n",
            "103.949326\n",
            "testing\n",
            "-109.21148\n",
            "5.2184844\n",
            "114.42995\n",
            "training\n",
            "1.0\n",
            "-99.15969\n",
            "5.4775743\n",
            "104.63727\n",
            "testing\n",
            "-108.91099\n",
            "5.200863\n",
            "114.11185\n",
            "Epoch 6\n",
            "training\n",
            "1\n",
            "-100.6203\n",
            "5.2954707\n",
            "105.91577\n",
            "testing\n",
            "-109.977104\n",
            "5.011875\n",
            "114.98898\n",
            "training\n",
            "1\n",
            "-99.57554\n",
            "5.101779\n",
            "104.67732\n",
            "testing\n",
            "-109.97036\n",
            "4.8381414\n",
            "114.808495\n",
            "training\n",
            "1\n",
            "-97.43515\n",
            "5.1380033\n",
            "102.57315\n",
            "testing\n",
            "-109.63381\n",
            "4.88914\n",
            "114.52295\n",
            "training\n",
            "1\n",
            "-99.76331\n",
            "5.237678\n",
            "105.000984\n",
            "testing\n",
            "-109.583855\n",
            "4.9698267\n",
            "114.55369\n",
            "training\n",
            "1\n",
            "-100.47848\n",
            "5.2970805\n",
            "105.77554\n",
            "testing\n",
            "-110.03358\n",
            "4.9654193\n",
            "114.99899\n",
            "training\n",
            "1\n",
            "-99.385895\n",
            "5.3580303\n",
            "104.74394\n",
            "testing\n",
            "-110.38716\n",
            "5.052484\n",
            "115.43966\n",
            "training\n",
            "1\n",
            "-98.70658\n",
            "5.165512\n",
            "103.87209\n",
            "testing\n",
            "-110.6619\n",
            "4.9114456\n",
            "115.57334\n",
            "training\n",
            "1\n",
            "-98.97605\n",
            "5.164865\n",
            "104.140915\n",
            "testing\n",
            "-110.63651\n",
            "4.8233657\n",
            "115.459885\n",
            "Epoch 7\n",
            "training\n",
            "1\n",
            "-96.5081\n",
            "5.1530833\n",
            "101.661194\n",
            "testing\n",
            "-110.414635\n",
            "4.812594\n",
            "115.22722\n",
            "training\n",
            "1\n",
            "-99.08588\n",
            "5.047365\n",
            "104.133255\n",
            "testing\n",
            "-111.114235\n",
            "4.753613\n",
            "115.86785\n",
            "training\n",
            "1\n",
            "-97.85325\n",
            "4.966148\n",
            "102.81941\n",
            "testing\n",
            "-111.24116\n",
            "4.6767316\n",
            "115.917885\n",
            "training\n",
            "1\n",
            "-97.99769\n",
            "5.263891\n",
            "103.26157\n",
            "testing\n",
            "-111.69326\n",
            "4.942994\n",
            "116.63627\n",
            "training\n",
            "1\n",
            "-98.59308\n",
            "4.947326\n",
            "103.5404\n",
            "testing\n",
            "-111.11116\n",
            "4.627837\n",
            "115.739006\n",
            "training\n",
            "1\n",
            "-97.544525\n",
            "4.8702316\n",
            "102.41475\n",
            "testing\n",
            "-112.03593\n",
            "4.5424685\n",
            "116.57839\n",
            "training\n",
            "1\n",
            "-97.33166\n",
            "5.0372415\n",
            "102.368904\n",
            "testing\n",
            "-111.96195\n",
            "4.6909604\n",
            "116.652916\n",
            "training\n",
            "1\n",
            "-95.40685\n",
            "4.803825\n",
            "100.21067\n",
            "testing\n",
            "-112.040764\n",
            "4.446264\n",
            "116.48702\n",
            "training\n",
            "1\n",
            "-96.25208\n",
            "4.819602\n",
            "101.07168\n",
            "testing\n",
            "-111.730484\n",
            "4.5165815\n",
            "116.24706\n",
            "Epoch 8\n",
            "training\n",
            "1\n",
            "-96.486496\n",
            "4.7236304\n",
            "101.21013\n",
            "testing\n",
            "-112.76172\n",
            "4.449339\n",
            "117.21105\n",
            "training\n",
            "1\n",
            "-97.22699\n",
            "4.607355\n",
            "101.83436\n",
            "testing\n",
            "-112.40959\n",
            "4.3046694\n",
            "116.71427\n",
            "training\n",
            "1\n",
            "-96.16081\n",
            "4.7155743\n",
            "100.876366\n",
            "testing\n",
            "-112.63494\n",
            "4.378234\n",
            "117.01316\n",
            "training\n",
            "1\n",
            "-96.98404\n",
            "4.828049\n",
            "101.8121\n",
            "testing\n",
            "-113.08999\n",
            "4.4599223\n",
            "117.54991\n",
            "training\n",
            "1\n",
            "-97.05984\n",
            "4.9601684\n",
            "102.02\n",
            "testing\n",
            "-113.00675\n",
            "4.6052217\n",
            "117.61197\n",
            "training\n",
            "1\n",
            "-97.105576\n",
            "4.9447637\n",
            "102.05033\n",
            "testing\n",
            "-113.67334\n",
            "4.61254\n",
            "118.28587\n",
            "training\n",
            "1\n",
            "-94.93966\n",
            "4.554069\n",
            "99.49373\n",
            "testing\n",
            "-113.58137\n",
            "4.296192\n",
            "117.87756\n",
            "training\n",
            "1\n",
            "-95.35798\n",
            "4.8303695\n",
            "100.18834\n",
            "testing\n",
            "-113.94712\n",
            "4.4539313\n",
            "118.40104\n",
            "Epoch 9\n",
            "training\n",
            "1\n",
            "-94.219864\n",
            "4.771173\n",
            "98.991035\n",
            "testing\n",
            "-113.73413\n",
            "4.4279838\n",
            "118.16212\n",
            "training\n",
            "1\n",
            "-96.276535\n",
            "4.7369976\n",
            "101.01354\n",
            "testing\n",
            "-114.75545\n",
            "4.4397025\n",
            "119.19514\n",
            "training\n",
            "1\n",
            "-94.25885\n",
            "4.6968255\n",
            "98.955666\n",
            "testing\n",
            "-114.93879\n",
            "4.3570404\n",
            "119.29584\n",
            "training\n",
            "1\n",
            "-96.04297\n",
            "4.687589\n",
            "100.73057\n",
            "testing\n",
            "-115.26529\n",
            "4.4010367\n",
            "119.66633\n",
            "training\n",
            "1\n",
            "-96.47406\n",
            "4.7466874\n",
            "101.22074\n",
            "testing\n",
            "-115.151726\n",
            "4.409374\n",
            "119.561104\n",
            "training\n",
            "1\n",
            "-94.59144\n",
            "4.6915445\n",
            "99.28299\n",
            "testing\n",
            "-115.34458\n",
            "4.3240967\n",
            "119.668686\n",
            "training\n",
            "1\n",
            "-94.55412\n",
            "4.716142\n",
            "99.27027\n",
            "testing\n",
            "-115.62847\n",
            "4.410466\n",
            "120.03895\n",
            "training\n",
            "1\n",
            "-94.112785\n",
            "4.6706367\n",
            "98.78341\n",
            "testing\n",
            "-115.350044\n",
            "4.307152\n",
            "119.65721\n",
            "training\n",
            "1\n",
            "-93.4896\n",
            "4.755857\n",
            "98.24545\n",
            "testing\n",
            "-115.81476\n",
            "4.415923\n",
            "120.230675\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "n5Prnd9lGZsr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "saver = tf.train.Saver()\n",
        "saver.restore(sess, path1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2LFNpBMZ-0gm",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Train Result"
      ]
    },
    {
      "metadata": {
        "id": "LKt2Xi2-PAYg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "24521ec4-3076-4c37-d68e-b514dfc920c3"
      },
      "cell_type": "code",
      "source": [
        "len(train_ce)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "85"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "metadata": {
        "id": "JqjyEWqynzmb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "text_save(train_ce, './result_0818/train_ce.txt')\n",
        "text_save(train_kl, './result_0818/train_kl.txt')\n",
        "text_save(train_ll, './result_0818/train_ll.txt')\n",
        "text_save(kl_weight,'./result_0818/kl_weight.txt')\n",
        "\n",
        "text_save(test_ce,  './result_0818/test_ce.txt')\n",
        "text_save(test_kl,  './result_0818/test_kl.txt')\n",
        "text_save(test_ll,  './result_0818/test_ll.txt')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yzmTQAN26Y1R",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "elbo_read = text_read('./result_0818/train_ce.txt')\n",
        "elbo_read = [-float(elbo) for elbo in elbo_read]\n",
        "\n",
        "kl_read = text_read('./result_0818/train_kl.txt')\n",
        "kl_read = [float(kl) for kl in kl_read]\n",
        "\n",
        "likei_read = text_read('./result_0818/train_ll.txt')\n",
        "likei_read = [float(likei) for likei in likei_read]\n",
        "\n",
        "\n",
        "plt.plot(likei_read, color = 'C1')\n",
        "plt.plot(elbo_read, color = 'C2')\n",
        "plt.legend(['nage_log_like_x_n_y', 'nage_elbo'], fontsize=12)\n",
        "plt.title(\"ptb_vae_lm_DCNN\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uJlRy5wLO7Cm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "plt.plot(kl_read, color = 'C0')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZYtVrwbWor1H",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Generate Sentence from Prior"
      ]
    },
    {
      "metadata": {
        "id": "bVhz10p8oult",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def id_to_word(words, word_to_id, max_length):\n",
        "  sens = [\"\" for x in range(max_length+1)]\n",
        "  for key in word_to_id.keys():\n",
        "    for p in range(max_length):\n",
        "      if words[p] == word_to_id[key]:\n",
        "        sens[p] = key\n",
        "  return sens"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cVgoCJN4pDAG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 570
        },
        "outputId": "b4f02fe2-a1f2-43c9-c8f0-c1b63ca15079"
      },
      "cell_type": "code",
      "source": [
        "for i in range(beam_size):\n",
        "  or_sens = id_to_word(x_de[i], word_to_id, decode_len+1)\n",
        "  or_sens_str = \" \"\n",
        "  for p in range(decode_len+1):\n",
        "     or_sens_str = or_sens_str + \" \" + or_sens[p]\n",
        "  print(or_sens_str)"
      ],
      "execution_count": 198,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  <beg> mr. <unk> said it is considering a precedent for pesticide <unk> in the personal-computer industry and navigation mixte a $ N billion from $ N billion <eos> <eos> the takeover\n",
            "  <beg> mr. <unk> said it is considering a precedent for pesticide <unk> in the personal-computer industry and navigation mixte a $ N billion from $ N billion <eos> <eos> the period\n",
            "  <beg> mr. <unk> said it is considering a precedent for pesticide <unk> in the personal-computer industry and navigation mixte a $ N billion from $ N billion <eos> <eos> beverly western\n",
            "  <beg> mr. <unk> said it is considering a precedent for pesticide <unk> in the personal-computer industry and navigation mixte a $ N billion from $ N billion <eos> <eos> beverly services\n",
            "  <beg> mr. <unk> said it is considering a precedent for pesticide <unk> in the personal-computer industry and navigation mixte a $ N billion from $ N billion <eos> <eos> beverly disasters\n",
            "  <beg> mr. <unk> said it is considering a precedent for pesticide <unk> in the personal-computer industry and navigation mixte a $ N billion from $ N billion <eos> <eos> beverly beach\n",
            "  <beg> mr. <unk> said it is considering a precedent for pesticide <unk> in the personal-computer industry and navigation mixte a $ N billion from $ N billion <eos> <eos> beverly syndrome\n",
            "  <beg> mr. <unk> said it is considering a precedent for pesticide <unk> in the personal-computer industry and navigation mixte a $ N billion from $ N billion <eos> <eos> beverly rica\n",
            "  <beg> mr. <unk> said it is considering a precedent for pesticide <unk> in the personal-computer industry and navigation mixte a $ N billion from $ N billion <eos> <eos> beverly bowes\n",
            "  <beg> mr. <unk> said it is considering a precedent for pesticide <unk> in the personal-computer industry and navigation mixte a $ N billion from $ N billion <eos> <eos> beverly conn.\n",
            "  <beg> mr. <unk> said it is considering a precedent for pesticide <unk> in the personal-computer industry and navigation mixte a $ N billion from $ N billion <eos> <eos> the market\n",
            "  <beg> mr. <unk> said it is considering a precedent for pesticide <unk> in the personal-computer industry and navigation mixte a $ N billion from $ N billion <eos> <eos> last january\n",
            "  <beg> mr. <unk> said it is considering a precedent for pesticide <unk> in the personal-computer industry and navigation mixte a $ N billion from $ N billion <eos> <eos> the unauthorized\n",
            "  <beg> mr. <unk> said it is considering a precedent for pesticide <unk> in the personal-computer industry and navigation mixte a $ N billion from $ N billion <eos> <eos> last week\n",
            "  <beg> mr. <unk> said it is considering a precedent for pesticide <unk> in the personal-computer industry and navigation mixte a $ N billion from $ N billion <eos> <eos> beverly conn\n",
            "  <beg> mr. <unk> said it is considering a precedent for pesticide <unk> in the personal-computer industry and navigation mixte a $ N billion from $ N billion <eos> <eos> beverly area\n",
            "  <beg> mr. <unk> said it is considering a precedent for pesticide <unk> in the personal-computer industry and navigation mixte a $ N billion from $ N billion <eos> <eos> beverly defendants\n",
            "  <beg> mr. <unk> said it is considering a precedent for pesticide <unk> in the personal-computer industry and navigation mixte a $ N billion from $ N billion <eos> <eos> beverly n.c\n",
            "  <beg> mr. <unk> said it is considering a precedent for pesticide <unk> in the personal-computer industry and navigation mixte a $ N billion from $ N billion <eos> <eos> the crest\n",
            "  <beg> mr. <unk> said it is considering a precedent for pesticide <unk> in the personal-computer industry and navigation mixte a $ N billion from $ N billion <eos> <eos> beverly financings\n",
            "  <beg> mr. <unk> said it is considering a precedent for pesticide <unk> in the personal-computer industry and navigation mixte a $ N billion from $ N billion <eos> <eos> beverly diego\n",
            "  <beg> mr. <unk> said it is considering a precedent for pesticide <unk> in the personal-computer industry and navigation mixte a $ N billion from $ N billion <eos> <eos> the end\n",
            "  <beg> mr. <unk> said it is considering a precedent for pesticide <unk> in the personal-computer industry and navigation mixte a $ N billion from $ N billion <eos> <eos> the colorado\n",
            "  <beg> mr. <unk> said it is considering a precedent for pesticide <unk> in the personal-computer industry and navigation mixte a $ N billion from $ N billion <eos> <eos> beverly analytical\n",
            "  <beg> mr. <unk> said it is considering a precedent for pesticide <unk> in the personal-computer industry and navigation mixte a $ N billion from $ N billion <eos> <eos> the liquidation\n",
            "  <beg> mr. <unk> said it is considering a precedent for pesticide <unk> in the personal-computer industry and navigation mixte a $ N billion from $ N billion <eos> <eos> the next\n",
            "  <beg> mr. <unk> said it is considering a precedent for pesticide <unk> in the personal-computer industry and navigation mixte a $ N billion from $ N billion <eos> <eos> next year\n",
            "  <beg> mr. <unk> said it is considering a precedent for pesticide <unk> in the personal-computer industry and navigation mixte a $ N billion from $ N billion <eos> <eos> beverly hanover\n",
            "  <beg> mr. <unk> said it is considering a precedent for pesticide <unk> in the personal-computer industry and navigation mixte a $ N billion from $ N billion <eos> <eos> beverly hills\n",
            "  <beg> mr. <unk> said it is considering a precedent for pesticide <unk> in the personal-computer industry and navigation mixte a $ N billion from $ N billion <eos> <eos> the <eos>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "8z7sgxRjoxB5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "10f2522f-16db-415e-ea00-b9118744bd61"
      },
      "cell_type": "code",
      "source": [
        "########## Beam Search gene x ###########\n",
        "\n",
        "beam_size = 30\n",
        "conti = True\n",
        "idd = 8\n",
        "t = 0\n",
        "latent_num = 1\n",
        "\n",
        "import copy\n",
        "\n",
        "#########################################################\n",
        "x_len = np.array((1,30))\n",
        "\n",
        "x_de = np.random.randint(low=0, high=vocab_len, size=(beam_size, max_length+1))\n",
        "x_de[:,0] = word_to_id['<beg>']\n",
        "\n",
        "x_de_new = np.zeros(x_de.shape, dtype=np.int32)\n",
        "\n",
        "decode_len = 30\n",
        "\n",
        "#########################################################\n",
        "prob_next_word = np.ones((beam_size, vocab_len),dtype=np.float32)\n",
        "score = np.zeros((beam_size))\n",
        "\n",
        "\n",
        "#########################################################\n",
        "\n",
        "with tf.Session() as sess:\n",
        "  \n",
        "    saver = tf.train.Saver()\n",
        "    saver.restore(sess, path1)\n",
        "\n",
        "    la_var = np.random.normal(size = (1,latent_size), loc=0.0, scale=1)\n",
        "    \n",
        "    for t in range(decode_len):\n",
        "    #while conti:\n",
        "      \n",
        "        for j in range(beam_size):\n",
        "          \n",
        "          gene_feed_dict = {if_gene_placeholder: True,\n",
        "                            latent_var_placeholder:la_var,\n",
        "                            decode_placeholder: np.reshape(x_de[j],[1, num_steps+1])}\n",
        "                                                                           \n",
        "          prob_logits = sess.run(prob_constant, feed_dict=gene_feed_dict)\n",
        "          \n",
        "          prob_next_word[j] = np.log(prob_logits[t]/np.sum(prob_logits[t])) + score[j]\n",
        "                \n",
        "        beam_id = np.argmax(prob_next_word, axis=0)        \n",
        "        prob_next_word_beam = np.max(prob_next_word, axis=0)        \n",
        "        next_word_id = np.argsort(prob_next_word_beam)[-beam_size:]\n",
        "        \n",
        "        for j in range(beam_size):\n",
        "          \n",
        "          beam_id_j = beam_id[next_word_id[j]]\n",
        "          word_id_j = next_word_id[j]\n",
        "          \n",
        "          x_de_new[j] = copy.deepcopy(x_de[beam_id_j])          \n",
        "          x_de_new[j,t+1] = copy.deepcopy(word_id_j)\n",
        "          \n",
        "          score[j] = copy.deepcopy(prob_next_word_beam[word_id_j])\n",
        "          \n",
        "        \n",
        "        x_de = copy.deepcopy(x_de_new)\n",
        "       "
      ],
      "execution_count": 197,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from ./result_0818/model_each_epch.ckpt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "hQscL8V0YwNI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Generate Sentence"
      ]
    },
    {
      "metadata": {
        "id": "zEfuSJAWYv1M",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def id_to_word(words, word_to_id, max_length):\n",
        "  sens = [\"\" for x in range(max_length+1)]\n",
        "  for key in word_to_id.keys():\n",
        "    for p in range(max_length):\n",
        "      if words[p] == word_to_id[key]:\n",
        "        sens[p] = key\n",
        "  return sens"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mUFQGrRxY0zk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "64f42952-3b9f-491f-eb1b-61c6ff3089f5"
      },
      "cell_type": "code",
      "source": [
        "origin_sens = id_to_word(train_input[8], word_to_id, max_length)\n",
        "or_sens_str = \" \"\n",
        "for p in range(max_length):\n",
        "     or_sens_str = or_sens_str + \" \" + origin_sens[p]\n",
        "print(or_sens_str)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  a <unk> <unk> said this is an old story <eos> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "2x13qeeUY6BF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 461
        },
        "outputId": "2ca9f2f3-4785-43b1-a447-8df5905a6a35"
      },
      "cell_type": "code",
      "source": [
        "for i in range(beam_size):\n",
        "  or_sens = id_to_word(x_de[i], word_to_id, decode_len+1)\n",
        "  or_sens_str = \" \"\n",
        "  for p in range(decode_len+1):\n",
        "     or_sens_str = or_sens_str + \" \" + or_sens[p]\n",
        "  print(or_sens_str)"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  <beg> i do n't want to talk\n",
            "  <beg> it is going to be a\n",
            "  <beg> it is going to be lucky\n",
            "  <beg> i do n't want to work\n",
            "  <beg> i do n't want to watch\n",
            "  <beg> i do n't want to help\n",
            "  <beg> i do n't want to play\n",
            "  <beg> i do n't want to take\n",
            "  <beg> i do n't want to rule\n",
            "  <beg> i do n't think it 's\n",
            "  <beg> i do n't want to fly\n",
            "  <beg> i do n't see why the\n",
            "  <beg> i do n't want to end\n",
            "  <beg> i do n't want to N\n",
            "  <beg> i do n't want to break\n",
            "  <beg> i do n't want to make\n",
            "  <beg> i do n't want to switch\n",
            "  <beg> i do n't want <eos> <eos>\n",
            "  <beg> i do n't want to have\n",
            "  <beg> i do n't want to stay\n",
            "  <beg> i do n't want to see\n",
            "  <beg> i do n't want to stop\n",
            "  <beg> i do n't want to be\n",
            "  <beg> i do n't want to <unk>\n",
            "  <beg> i do n't want to go\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "-2_mjPKEY6h3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Beam Search"
      ]
    },
    {
      "metadata": {
        "id": "2Kb_Z8CIY8F8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0390ef97-c18c-4517-e25b-89e58eeccd97"
      },
      "cell_type": "code",
      "source": [
        "########## Beam Search gene x ###########\n",
        "\n",
        "beam_size = 25\n",
        "conti = True\n",
        "idd = 8\n",
        "t = 0\n",
        "latent_num = 1\n",
        "\n",
        "import copy\n",
        "#########################################################\n",
        "x_in = np.reshape(copy.deepcopy(train_input[idd]), (1, max_length))\n",
        "x_len = np.reshape(copy.deepcopy(train_sen_len[idd]), (1,))\n",
        "\n",
        "x_de = np.random.randint(low=0, high=vocab_len, size=(beam_size, max_length+1))\n",
        "x_de[:,0] = word_to_id['<beg>']\n",
        "\n",
        "x_de_new = np.zeros(x_de.shape, dtype=np.int32)\n",
        "\n",
        "decode_len = 6\n",
        "\n",
        "#########################################################\n",
        "prob_next_word = np.ones((beam_size, vocab_len),dtype=np.float32)\n",
        "score = np.zeros((beam_size))\n",
        "\n",
        "\n",
        "#########################################################\n",
        "\n",
        "with tf.Session() as sess:\n",
        "  \n",
        "    saver = tf.train.Saver()\n",
        "    saver.restore(sess, path1)\n",
        "\n",
        "    gene_feed_dict = {input_placeholder: x_in, \n",
        "                      length_placeholder: x_len}                       \n",
        "            \n",
        "    mean, std = sess.run([mean_encode, std_encode], feed_dict=gene_feed_dict)    # 1*max_len x fr_vocab_size\n",
        "    \n",
        "    eposida = np.random.normal(size = np.shape(std), loc=0.0, scale=1)\n",
        "    la_var = mean + std*eposida\n",
        "    \n",
        "    for t in range(decode_len):\n",
        "    #while conti:\n",
        "      \n",
        "        for j in range(beam_size):\n",
        "          \n",
        "          gene_feed_dict = {if_gene_placeholder: True,\n",
        "                            latent_var_placeholder:la_var,\n",
        "                            decode_placeholder: np.reshape(x_de[j],[1, num_steps+1])}\n",
        "                                                                           \n",
        "          prob_logits = sess.run(prob_constant, feed_dict=gene_feed_dict)\n",
        "          \n",
        "          prob_next_word[j] = np.log(prob_logits[t]/np.sum(prob_logits[t])) + score[j]\n",
        "                \n",
        "        beam_id = np.argmax(prob_next_word, axis=0)        \n",
        "        prob_next_word_beam = np.max(prob_next_word, axis=0)        \n",
        "        next_word_id = np.argsort(prob_next_word_beam)[-beam_size:]\n",
        "        \n",
        "        for j in range(beam_size):\n",
        "          \n",
        "          beam_id_j = beam_id[next_word_id[j]]\n",
        "          word_id_j = next_word_id[j]\n",
        "          \n",
        "          x_de_new[j] = copy.deepcopy(x_de[beam_id_j])          \n",
        "          x_de_new[j,t+1] = copy.deepcopy(word_id_j)\n",
        "          \n",
        "          score[j] = copy.deepcopy(prob_next_word_beam[word_id_j])\n",
        "          \n",
        "        \n",
        "        x_de = copy.deepcopy(x_de_new)\n",
        "       "
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from ./result_0818/model_each_epch.ckpt\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
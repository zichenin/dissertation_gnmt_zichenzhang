{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Gene_translation_cnn_0812_dropout.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "E546I60IPRWK",
        "DqH5fygZc0yl",
        "T3EsytHdPkpd",
        "r7mH1flzQMlU",
        "7FRb2Ko3LoRL",
        "yzo3aNrhY07T",
        "nrV_UJNkg2TX"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "rMcrrnEBsjy3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Set up the drive path"
      ]
    },
    {
      "metadata": {
        "id": "66FgEFRN-AMY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# !apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n",
        "# !add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
        "# !apt-get update -qq 2>&1 > /dev/null\n",
        "# !apt-get -y install -qq google-drive-ocamlfuse fuse\n",
        "# from google.colab import auth\n",
        "# auth.authenticate_user()\n",
        "# from oauth2client.client import GoogleCredentials\n",
        "# creds = GoogleCredentials.get_application_default()\n",
        "# import getpass\n",
        "# !google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n",
        "# vcode = getpass.getpass()\n",
        "# !echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SWRjvljv-GT1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# !mkdir -p drive\n",
        "# !google-drive-ocamlfuse drive"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Vn79dig8uT8B",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "305262ed-aa5d-44da-cb9a-45a195476853"
      },
      "cell_type": "code",
      "source": [
        "ls"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "adc.json  \u001b[0m\u001b[01;36mdatalab\u001b[0m@  \u001b[01;34mdrive\u001b[0m/  \u001b[01;34msample_data\u001b[0m/\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "3MTeUgeB-seY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b736a9ac-6f4b-4e06-849e-3c854d93be55"
      },
      "cell_type": "code",
      "source": [
        "cd drive/DCNN_300_dropout_08"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/DCNN_300_dropout_08\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "B12HWS4xsx4b",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Import Library"
      ]
    },
    {
      "metadata": {
        "id": "Ly79OANzc7RS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import collections\n",
        "import os\n",
        "import sys\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "from tensorflow.contrib.seq2seq import sequence_loss\n",
        "\n",
        "import math\n",
        "import re\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import pickle\n",
        "\n",
        "!pip install -q mosestokenizer\n",
        "from mosestokenizer import *\n",
        "\n",
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "\n",
        "\n",
        "from scipy.stats import multivariate_normal\n",
        "from scipy.stats import norm\n",
        "import copy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "842o8uvRtBnF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Data Pre-processing"
      ]
    },
    {
      "metadata": {
        "id": "wjDy6-mfnnit",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "## load vocab dict from txt file\n",
        "\n",
        "f = open(\"../dictionary/en_word_to_id.txt\", \"rb\")\n",
        "en_word_to_id = pickle.load(f)\n",
        "f.close()\n",
        "\n",
        "f = open(\"../dictionary/fr_word_to_id.txt\", \"rb\")\n",
        "fr_word_to_id = pickle.load(f)\n",
        "f.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TuETWPMbu2Yj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "bbbe456b-47e0-4111-8442-cf0b9ab9dcc5"
      },
      "cell_type": "code",
      "source": [
        "en_vocab_size = len(en_word_to_id)\n",
        "fr_vocab_size = len(fr_word_to_id)\n",
        "\n",
        "en_eos = en_word_to_id['eos']\n",
        "fr_eos = fr_word_to_id['eos']\n",
        "\n",
        "print(en_vocab_size)\n",
        "print(fr_vocab_size)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "30772\n",
            "39578\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "c9ifxSnpu6zh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def _read_words(filename):\n",
        "  with tf.gfile.GFile(filename, \"r\") as f: \n",
        "    output = f.read().replace(\"\\n\", \" eos \").replace(\".\", \" .\")\n",
        "    output = re.sub('[0-9]+', 'N', output)\n",
        "    return output\n",
        "\n",
        "def _file_to_word_ids(data, word_to_id):\n",
        "  \n",
        "  id_list = []\n",
        "  \n",
        "  for word in data:\n",
        "    if word in word_to_id:\n",
        "      id_list.append(word_to_id[word])\n",
        "    else:\n",
        "      id_list.append(1)\n",
        "          \n",
        "  return id_list\n",
        "\n",
        "\n",
        "def preprocess_train_data(pre_data, word_to_id, max_length):\n",
        "    pre_data_array = np.asarray(pre_data)\n",
        "    last_start = 0\n",
        "    data = []\n",
        "    each_sen_len = []\n",
        "    \n",
        "    for i in range(len(pre_data_array)):\n",
        "        if pre_data_array[i]==word_to_id['eos']:\n",
        "            if max_length >= len(pre_data_array[last_start:(i+1)]):                \n",
        "              data.append(pre_data_array[last_start:(i+1)])\n",
        "              each_sen_len.append(i+1-last_start)              \n",
        "            else:\n",
        "              shorten_sentences = pre_data_array[last_start:(last_start+max_length-1)]\n",
        "              shorten_sentences = np.concatenate((shorten_sentences, np.asarray([word_to_id['eos']])), axis=0)\n",
        "              data.append(shorten_sentences)\n",
        "              each_sen_len.append(max_length) \n",
        "            \n",
        "            last_start = i+1\n",
        "            \n",
        "    out_sentences = np.full([len(data), max_length], word_to_id['<PAD>'], dtype=np.int32)\n",
        "    for i in range(len(data)):\n",
        "        out_sentences[i,:len(data[i])] = data[i]    \n",
        "    return out_sentences, np.asarray(each_sen_len)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "y57-AuNCvDSE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def generate_input_en(en_file, en_word_to_id, max_length):\n",
        "  \n",
        "    en_data = _read_words(en_file)\n",
        "\n",
        "    en_tokenize = MosesTokenizer('en')\n",
        "\n",
        "    en_data = en_tokenize(en_data)\n",
        "\n",
        "    en_data_id = _file_to_word_ids(en_data, en_word_to_id)\n",
        "\n",
        "    en_input, en_input_len = preprocess_train_data(en_data_id, en_word_to_id, max_length)\n",
        "    \n",
        "    return en_input, en_input_len\n",
        "  \n",
        "  \n",
        "  \n",
        "def generate_output_fr(fr_file, fr_word_to_id, max_length):\n",
        "    \n",
        "    fr_data = _read_words(fr_file)\n",
        "\n",
        "    fr_tokenize = MosesTokenizer('fr')\n",
        "\n",
        "    fr_data = fr_tokenize(fr_data)\n",
        "\n",
        "    fr_data_id = _file_to_word_ids(fr_data, fr_word_to_id)\n",
        "\n",
        "    fr_output, fr_output_len = preprocess_train_data(fr_data_id, fr_word_to_id,max_length=30)\n",
        "\n",
        "    #out_beg_token = fr_word_to_id['<beg>']*np.ones((fr_output.shape[0], 1), dtype=np.int32)\n",
        "\n",
        "    #fr_output = np.concatenate((out_beg_token, fr_output), axis=1)\n",
        "\n",
        "    return fr_output,fr_output_len"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ehsowT7hwyjO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def batch_producer(raw_data, raw_data_len, batch_size):    \n",
        "    data_len = len(raw_data)    \n",
        "    batch_len = data_len // batch_size    \n",
        "    data = np.reshape(raw_data[0 : batch_size * batch_len, :], [batch_size, batch_len, -1])\n",
        "    data = np.transpose(data, (1,0,2))\n",
        "    \n",
        "    data_length = np.reshape(raw_data_len[0 : batch_size * batch_len], [batch_size, batch_len])\n",
        "    data_length = np.transpose(data_length, (1,0))\n",
        "    return data, data_length "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "juNYK867gw3B",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "en_oov_id = en_word_to_id['<OOV>']\n",
        "fr_oov_id = fr_word_to_id['<OOV>']\n",
        "\n",
        "def dropout_func(decode_input, dropout_prob, oov_id):\n",
        "  for i in range(decode_input.shape[0]):\n",
        "    for j in range(decode_input.shape[1]):\n",
        "        for k in range(1,decode_input.shape[2]):\n",
        "            if np.random.uniform() > dropout_prob:\n",
        "                decode_input[i,j,k] = oov_id        \n",
        "  return decode_input"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lq37O5wR21AC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Model"
      ]
    },
    {
      "metadata": {
        "id": "zcHfesh3uCDs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "###################### define parameters ######################\n",
        "\n",
        "max_length = 30\n",
        "\n",
        "batch_size = 100\n",
        "\n",
        "embed_size = 300\n",
        "\n",
        "infer_hidden_size = 1000\n",
        "\n",
        "latent_size = 200\n",
        "\n",
        "latent_num = 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-FraHS_clcvu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# ###################### generate sentence #######################\n",
        "# batch_size = 1\n",
        "\n",
        "# latent_num = 100"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KJNVkwnhdg9Q",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "###################### define placeholder ######################\n",
        "\n",
        "input_placeholder = tf.placeholder(tf.int32, [batch_size, max_length], 'input')         # batch_size x max_length\n",
        "\n",
        "target_placeholder = tf.placeholder(tf.int32, [batch_size, max_length], 'target')       # batch_size x max_length\n",
        "\n",
        "in_length_placeholder = tf.placeholder(tf.int32, [batch_size, ], 'in_len')              # batch_size x 1\n",
        "\n",
        "out_length_placeholder = tf.placeholder(tf.int32, [batch_size, ], 'out_len')            # batch_size x 1\n",
        "\n",
        "discount_placeholder = tf.placeholder(tf.float32, name='discount')\n",
        "\n",
        "lr_placeholder = tf.placeholder(tf.float32, name='learn_rate')\n",
        "\n",
        "input_drop_placeholder = tf.placeholder(tf.int32, [batch_size, max_length], 'input_drop')   # batch_size x max_length\n",
        "\n",
        "target_drop_placeholder = tf.placeholder(tf.int32, [batch_size, max_length], 'target_drop') # batch_size x max_length\n",
        "\n",
        "if_gene_placeholder = tf.placeholder(tf.bool, name='if_gene')\n",
        "\n",
        "latent_var_placeholder = tf.placeholder(tf.float32, [latent_num, batch_size, max_length, latent_size], 'la_var')       # batch_size x max_length x latent_size\n",
        "\n",
        "xavier_initializer = tf.contrib.layers.xavier_initializer()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1dqobGQGkHNg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "##################### embedding look-up for input sentences ####################\n",
        "\n",
        "with tf.variable_scope('en_embedding'):\n",
        "    en_embedding = tf.get_variable('en_embeding',[en_vocab_size, embed_size], dtype=tf.float32, initializer=xavier_initializer)\n",
        "    inputs = tf.nn.embedding_lookup(en_embedding, input_placeholder)                      # batch_size x max_length x embed_size\n",
        "    inputs_drop = tf.nn.embedding_lookup(en_embedding, input_drop_placeholder)                      # batch_size x max_length x embed_size\n",
        "\n",
        "with tf.variable_scope('fr_embedding'):\n",
        "    fr_embedding = tf.get_variable('fr_embeding',[fr_vocab_size, embed_size], dtype=tf.float32, initializer=xavier_initializer)\n",
        "    targets = tf.nn.embedding_lookup(fr_embedding, target_placeholder)                      # batch_size x max_length x embed_size\n",
        "    targets_drop = tf.nn.embedding_lookup(fr_embedding, target_drop_placeholder)                      # batch_size x max_length x embed_size\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tmvdTgj5tSpT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 1 Inference Model - Encoder\n",
        "\n",
        "$q(z_1, z_2, ... , z_T|x,y)$\n",
        "\n",
        "Similar to the encoder of RNNSearch"
      ]
    },
    {
      "metadata": {
        "id": "OXsPo82WXXdX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#################### Inference model  #######################\n",
        "\n",
        "encode_inputs = tf.transpose(tf.concat([inputs, targets], axis=2), (1,0,2))\n",
        "\n",
        "with tf.variable_scope('encode'):\n",
        "    #basic_cell =tf.contrib.rnn.GRUCell(infer_hidden_size)\n",
        "    basic_cell = tf.contrib.rnn.BasicLSTMCell(infer_hidden_size, forget_bias=1.0, state_is_tuple=True)\n",
        "    init_state = basic_cell.zero_state(batch_size, tf.float32)\n",
        "    encode_outputs, encode_state = tf.nn.bidirectional_dynamic_rnn(cell_fw=basic_cell, \n",
        "                                                                   cell_bw=basic_cell, \n",
        "                                                                   inputs=encode_inputs,                                                                \n",
        "                                                                   initial_state_fw=init_state,\n",
        "                                                                   initial_state_bw=init_state,\n",
        "                                                                   dtype=tf.float32,\n",
        "                                                                   time_major=True)\n",
        "#### encode_outputs: max_length x batch_size x infer_hidden_size\n",
        "\n",
        "en_outputs = tf.concat((encode_outputs[0],encode_outputs[1]),2)                             # max_length x batch_size x 2*infer_hidden_size\n",
        "\n",
        "en_outputs_tran = tf.transpose(en_outputs, (1,0,2))                                         # batch_size x en_max_length x 2*infer_hidden_size\n",
        "\n",
        "en_outputs_resh = tf.reshape(en_outputs_tran, (batch_size*max_length, 2*infer_hidden_size)) # batch_size*max_length x 2*infer_hidden_size"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ectGLNLWXfSe",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# ##################### Inference model  #######################\n",
        "\n",
        "# ##################### bi-direction lstm of source sentence ######################\n",
        "\n",
        "# encode_inputs_x = tf.transpose(inputs, (1,0,2))  # en_max_length x batch_size x embed_size\n",
        "  \n",
        "# with tf.variable_scope('encode_x'):\n",
        "#     basic_cell_x = tf.contrib.rnn.BasicLSTMCell(infer_hidden_size, forget_bias=1.0, state_is_tuple=True)\n",
        "#     init_state_x = basic_cell_x.zero_state(batch_size, tf.float32)\n",
        "#     encode_outputs_x, encode_state_x = tf.nn.bidirectional_dynamic_rnn(cell_fw=basic_cell_x, \n",
        "#                                                                        cell_bw=basic_cell_x, \n",
        "#                                                                        inputs=encode_inputs_x,\n",
        "#                                                                        sequence_length=in_length_placeholder,\n",
        "#                                                                        initial_state_fw=init_state_x,\n",
        "#                                                                        initial_state_bw=init_state_x,\n",
        "#                                                                        dtype=tf.float32,\n",
        "#                                                                        time_major=True)\n",
        "# #### encode_outputs_x: max_length x batch_size x infer_hidden_size\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# ##################### bi-direction lstm of target sentence ######################\n",
        "\n",
        "# encode_inputs_y = tf.transpose(targets, (1,0,2))  # en_max_length x batch_size x embed_size\n",
        "  \n",
        "# with tf.variable_scope('encode_y'):\n",
        "#     basic_cell_y = tf.contrib.rnn.BasicLSTMCell(infer_hidden_size, forget_bias=1.0, state_is_tuple=True)\n",
        "#     init_state_y = basic_cell_y.zero_state(batch_size, tf.float32)\n",
        "#     encode_outputs_y, encode_state_y = tf.nn.bidirectional_dynamic_rnn(cell_fw=basic_cell_y, \n",
        "#                                                                        cell_bw=basic_cell_y, \n",
        "#                                                                        inputs=encode_inputs_y,\n",
        "#                                                                        sequence_length=out_length_placeholder,\n",
        "#                                                                        initial_state_fw=init_state_y,\n",
        "#                                                                        initial_state_bw=init_state_y,\n",
        "#                                                                        dtype=tf.float32,\n",
        "#                                                                        time_major=True)\n",
        "# #### encode_outputs_y: max_length x batch_size x infer_hidden_size\n",
        "\n",
        "\n",
        "# ##################### concatenate the output of encoder of x and y ######################\n",
        "\n",
        "# fw_bw_en_outputs_x = tf.concat((encode_outputs_x[0],encode_outputs_x[1]),2)     # en_max_length x batch_size x 2*infer_hidden_size\n",
        "\n",
        "# fw_bw_en_outputs_y = tf.concat((encode_outputs_y[0],encode_outputs_y[1]),2)     # en_max_length x batch_size x 2*infer_hidden_size\n",
        "\n",
        "# fw_bw_en_outputs = tf.concat((fw_bw_en_outputs_x, fw_bw_en_outputs_y), 2)       # en_max_length x batch_size x 4*infer_hidden_size\n",
        "\n",
        "# fw_bw_en_outputs_tran = tf.transpose(fw_bw_en_outputs, (1,0,2))                 # batch_size x en_max_length x 4*infer_hidden_size\n",
        "\n",
        "# fw_bw_en_outputs_resh = tf.reshape(fw_bw_en_outputs_tran, (batch_size*max_length, 4*infer_hidden_size)) # batch_size*en_max_length x 4*infer_hidden_size\n",
        "\n",
        "\n",
        "# # la_mean = tf.matmul(fw_bw_en_outputs_resh, W_1) + b_1                              # batch_size*max_length x latent_size \n",
        "\n",
        "# # la_log_var = tf.matmul(fw_bw_en_outputs_resh, W_2) + b_2                           # batch_size*max_length x latent_size \n",
        "# # la_var = tf.exp(la_log_var)\n",
        "# # la_std = tf.sqrt(la_var)\n",
        "\n",
        "# # kl_div_loss = 1 + la_log_var - tf.square(la_mean) - la_var                               # batch_size*max_length x latent_size\n",
        "# # kl_div_loss = -0.5 * tf.reduce_sum(kl_div_loss, axis=1)                         # batch_size*max_length x 1\n",
        "# # kl_div_loss = tf.reshape(kl_div_loss, (batch_size, max_length))                 # batch_size x max_length\n",
        "# # kl_div_loss = tf.reduce_sum(kl_div_loss, axis=1)\n",
        "\n",
        "# # #### sample the latent variable z by reparameterization trick\n",
        "\n",
        "# # eposida = tf.random_normal(tf.shape(la_std), mean=0.0,stddev=1)\n",
        "# # latent_variables = la_mean + la_std*eposida\n",
        "# # latent_variables = tf.reshape(latent_variables, (batch_size, max_length, latent_size))    # batch_size x max_length x latent_size"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XJwm5BECin44",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "with tf.variable_scope('encode_projection'):\n",
        "    W_1 = tf.get_variable('W_1',[2*infer_hidden_size, latent_size], dtype=tf.float32, initializer=xavier_initializer)\n",
        "    b_1 = tf.get_variable('b_1',[latent_size,], dtype=tf.float32, initializer=xavier_initializer)\n",
        "    W_2 = tf.get_variable('W_2',[2*infer_hidden_size, latent_size], dtype=tf.float32, initializer=xavier_initializer)\n",
        "    b_2 = tf.get_variable('b_2',[latent_size,], dtype=tf.float32, initializer=xavier_initializer)\n",
        "\n",
        "\n",
        "#fw_bw_en_outputs_norm = tf.contrib.layers.batch_norm(fw_bw_en_outputs_resh, center=True, scale=True)\n",
        "\n",
        "la_mean = tf.matmul(en_outputs_resh, W_1) + b_1                              # batch_size*max_length x latent_size \n",
        "\n",
        "la_log_var = tf.matmul(en_outputs_resh, W_2) + b_2                           # batch_size*max_length x latent_size \n",
        "la_var = tf.exp(la_log_var)\n",
        "la_std = tf.sqrt(la_var)\n",
        "\n",
        "kl_div_loss = 1 + la_log_var - tf.square(la_mean) - la_var                               # batch_size*max_length x latent_size\n",
        "kl_div_loss = -0.5 * tf.reduce_sum(kl_div_loss, axis=1)                         # batch_size*max_length x 1\n",
        "kl_div_loss = tf.reshape(kl_div_loss, (batch_size, max_length))                 # batch_size x max_length\n",
        "kl_div_loss = tf.reduce_sum(kl_div_loss, axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gJY332jnGK_e",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "latent_variables_v = []\n",
        "for _ in range(latent_num):\n",
        "  eposida = tf.random_normal(tf.shape(la_std), mean=0.0,stddev=1)\n",
        "  latent_variables_sample = la_mean + la_std*eposida\n",
        "  latent_variables_sample = tf.reshape(latent_variables_sample, (batch_size, max_length, latent_size))    # batch_size x max_length x latent_size\n",
        "  latent_variables_v.append(latent_variables_sample)\n",
        "\n",
        "def if_true():\n",
        "  latent_v = []\n",
        "  for h in range(latent_num):\n",
        "    latent_v.append(latent_var_placeholder[h])\n",
        "  return latent_v\n",
        "\n",
        "def if_false():\n",
        "  return latent_variables_v\n",
        "\n",
        "latent_variables = tf.cond(if_gene_placeholder, if_true, if_false)\n",
        "\n",
        "if latent_num == 1:\n",
        "  new_latent_variables = []\n",
        "  new_latent_variables.append(latent_variables)\n",
        "  latent_variables = new_latent_variables"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vDVWXdubzXh0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# latent_v = []\n",
        "# for h in range(latent_num):\n",
        "#   latent_v.append(latent_var_placeholder[h])\n",
        "    \n",
        "# latent_variables = latent_v"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "on6adzC8518v",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 2 Generation Model - Decoder\n",
        "\n",
        "$p_\\theta(x|z_1, z_2, ... , z_T)$\n",
        "\n",
        "$p_\\theta(y|z_1, z_2, ... , z_T)$"
      ]
    },
    {
      "metadata": {
        "id": "tiEDu_jlXEtC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "filter_num = 150\n",
        "\n",
        "filter_size = 3\n",
        "\n",
        "filter_size_only_pre = 2\n",
        "\n",
        "filter_size_pad = filter_size - filter_size_only_pre\n",
        "\n",
        "filter_zero_pad = tf.zeros(shape=[filter_size_pad, embed_size+latent_size, filter_num], dtype=tf.float32)\n",
        "filter_zero_pad_2 = tf.zeros(shape=[1, filter_size_pad, filter_num, filter_num], dtype=tf.float32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BSBf8rYS9hX9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 2.1 Generation Model for source sentence $p_\\theta(x|z_1, z_2, ... , z_T)$\n"
      ]
    },
    {
      "metadata": {
        "id": "UNQlel3UksZ9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#### concat beg token with input\n",
        "\n",
        "#beg_token_x = tf.zeros((1,embed_size))\n",
        "beg_token_x = tf.reshape(en_embedding[en_eos], [1,embed_size])\n",
        "\n",
        "x_list = tf.split(inputs_drop, axis=0, num_or_size_splits=batch_size)\n",
        "\n",
        "x_with_beg_list = [tf.concat((beg_token_x, input[0]), axis=0) for input in x_list]              # batch_size x (max_length+1) x embed_size\n",
        "\n",
        "x_with_beg = tf.stack(x_with_beg_list, axis=0)\n",
        "\n",
        "#x_input_cnn_1 = tf.concat([latent_variables_1,x_with_beg[:,:30,:]], axis=2)                     # batch_size x max_length x (embed_size+latent_size)\n",
        "\n",
        "#x_input_cnn_2 = tf.concat([latent_variables_2,x_with_beg[:,:30,:]], axis=2)                     # batch_size x max_length x (embed_size+latent_size)\n",
        "\n",
        "#x_input_cnn_4D = tf.expand_dims(x_input_cnn, axis=1)                                        # batch_size x max_length x (embed_size+latent_size)\n",
        "\n",
        "x_input_cnn = []\n",
        "for l in range(latent_num):\n",
        "  x_input_cnn.append(tf.concat([latent_variables[l],x_with_beg[:,:30,:]], axis=2))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TbE6eI1E7aua",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "with tf.variable_scope('x_con_dialted_1D'):\n",
        "  \n",
        "    f_x_1 = tf.get_variable(\"x_filter_1\", shape=[2, embed_size+latent_size, filter_num], dtype=tf.float32, initializer=xavier_initializer)\n",
        "    f_x_1_dia = tf.concat([f_x_1, \n",
        "                           tf.zeros((1,embed_size+latent_size,filter_num))], axis=0)                                     \n",
        "    # 3 x (embed_size+latent_size) x filter_num\n",
        "    \n",
        "    f_x_2 = tf.get_variable(\"x_filter_2\", shape=[3, filter_num+latent_size, filter_num], dtype=tf.float32, initializer=xavier_initializer)\n",
        "    f_x_2_dia = tf.concat([tf.reshape(f_x_2[0],(1,filter_num+latent_size,filter_num)), \n",
        "                           tf.zeros((1,filter_num+latent_size, filter_num)), \n",
        "                           tf.reshape(f_x_2[1],(1,filter_num+latent_size,filter_num)), \n",
        "                           tf.zeros((1,filter_num+latent_size,filter_num)),\n",
        "                           tf.reshape(f_x_2[2],(1,filter_num+latent_size,filter_num)),\n",
        "                           tf.zeros((4,filter_num+latent_size,filter_num)),], axis=0)\n",
        "    # 9 x filter_num x filter_num\n",
        "    \n",
        "    f_x_3 = tf.get_variable(\"x_filter_3\", shape=[3, filter_num+latent_size, filter_num], dtype=tf.float32, initializer=xavier_initializer)\n",
        "    f_x_3_dia = tf.concat([tf.reshape(f_x_3[0],(1,filter_num+latent_size,filter_num)), \n",
        "                           tf.zeros((3,filter_num+latent_size,filter_num)), \n",
        "                           tf.reshape(f_x_3[1],(1,filter_num+latent_size,filter_num)), \n",
        "                           tf.zeros((3,filter_num+latent_size,filter_num)),\n",
        "                           tf.reshape(f_x_3[2],(1,filter_num+latent_size,filter_num)),\n",
        "                           tf.zeros((8,filter_num+latent_size,filter_num))], axis=0)\n",
        "    # 13 x filter_num x filter_num\n",
        "    \n",
        "    f_x_4 = tf.get_variable(\"x_filter_4\", shape=[3, filter_num+latent_size, filter_num], dtype=tf.float32, initializer=xavier_initializer)\n",
        "    f_x_4_dia = tf.concat([tf.reshape(f_x_4[0],(1,filter_num+latent_size,filter_num)), \n",
        "                           tf.zeros((7,filter_num+latent_size,filter_num)), \n",
        "                           tf.reshape(f_x_4[1],(1,filter_num+latent_size,filter_num)), \n",
        "                           tf.zeros((7,filter_num+latent_size,filter_num)),\n",
        "                           tf.reshape(f_x_4[2],(1,filter_num+latent_size,filter_num)),\n",
        "                           tf.zeros((16,filter_num+latent_size,filter_num))], axis=0)\n",
        "    # 21 x filter_num x filter_num\n",
        "    \n",
        "    f_x_5 = tf.get_variable(\"x_filter_5\", shape=[2, filter_num+latent_size, filter_num], dtype=tf.float32, initializer=xavier_initializer)\n",
        "    f_x_5_dia = tf.concat([f_x_5, \n",
        "                           tf.zeros((1,filter_num+latent_size,filter_num))], axis=0)                                     \n",
        "    # 3 x (embed_size+latent_size) x filter_num\n",
        "    \n",
        "    f_x_6 = tf.get_variable(\"x_filter_6\", shape=[3, filter_num+latent_size, filter_num], dtype=tf.float32, initializer=xavier_initializer)\n",
        "    f_x_6_dia = tf.concat([tf.reshape(f_x_6[0],(1,filter_num+latent_size,filter_num)), \n",
        "                           tf.zeros((1,filter_num+latent_size, filter_num)), \n",
        "                           tf.reshape(f_x_6[1],(1,filter_num+latent_size,filter_num)), \n",
        "                           tf.zeros((1,filter_num+latent_size,filter_num)),\n",
        "                           tf.reshape(f_x_6[2],(1,filter_num+latent_size,filter_num)),\n",
        "                           tf.zeros((4,filter_num+latent_size,filter_num)),], axis=0)\n",
        "    # 9 x filter_num x filter_num\n",
        "    \n",
        "    f_x_7 = tf.get_variable(\"x_filter_7\", shape=[3, filter_num+latent_size, filter_num], dtype=tf.float32, initializer=xavier_initializer)\n",
        "    f_x_7_dia = tf.concat([tf.reshape(f_x_7[0],(1,filter_num+latent_size,filter_num)), \n",
        "                           tf.zeros((3,filter_num+latent_size,filter_num)), \n",
        "                           tf.reshape(f_x_7[1],(1,filter_num+latent_size,filter_num)), \n",
        "                           tf.zeros((3,filter_num+latent_size,filter_num)),\n",
        "                           tf.reshape(f_x_7[2],(1,filter_num+latent_size,filter_num)),\n",
        "                           tf.zeros((8,filter_num+latent_size,filter_num))], axis=0)\n",
        "    # 13 x filter_num x filter_num\n",
        "    \n",
        "    f_x_8 = tf.get_variable(\"x_filter_8\", shape=[3, filter_num+latent_size, filter_num], dtype=tf.float32, initializer=xavier_initializer)\n",
        "    f_x_8_dia = tf.concat([tf.reshape(f_x_8[0],(1,filter_num+latent_size,filter_num)), \n",
        "                           tf.zeros((7,filter_num+latent_size,filter_num)), \n",
        "                           tf.reshape(f_x_8[1],(1,filter_num+latent_size,filter_num)), \n",
        "                           tf.zeros((7,filter_num+latent_size,filter_num)),\n",
        "                           tf.reshape(f_x_8[2],(1,filter_num+latent_size,filter_num)),\n",
        "                           tf.zeros((16,filter_num+latent_size,filter_num))], axis=0)\n",
        "    # 21 x filter_num x filter_num\n",
        "    \n",
        "\n",
        "    \n",
        "#### variablen of a FC layer to map the hidden state of the decoder-rnn in each time-step to the predicted next word\n",
        "with tf.variable_scope('projection_x'):\n",
        "    proj_w_x = tf.get_variable('project_w_x', [filter_num,embed_size], dtype=tf.float32, initializer=xavier_initializer)\n",
        "    proj_b_x = tf.get_variable('project_b_x', [embed_size,], dtype=tf.float32, initializer=xavier_initializer)\n",
        "    \n",
        "#### sequence weight of x\n",
        "squence_weight_x= tf.sequence_mask(in_length_placeholder, maxlen=max_length, dtype=tf.float32)                       # batch_size x max_length"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SQIFBsJnkJWA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def x_decoder(de_input, de_latent):\n",
        "  \n",
        "  x_out_conv_dia_1 = tf.nn.conv1d(de_input, \n",
        "                                  f_x_1_dia, stride=1, padding='SAME')                     # batch_size x max_length x filter_num\n",
        "  x_out_conv_dia_2 = tf.nn.conv1d(tf.concat((x_out_conv_dia_1, de_latent), axis=2), \n",
        "                                  f_x_2_dia, stride=1, padding='SAME')                # batch_size x max_length x filter_num\n",
        "  x_out_conv_dia_3 = tf.nn.conv1d(tf.concat((x_out_conv_dia_2, de_latent), axis=2), \n",
        "                                  f_x_3_dia, stride=1, padding='SAME')                # batch_size x max_length x filter_num\n",
        "  x_out_conv_dia_4 = tf.nn.conv1d(tf.concat((x_out_conv_dia_3, de_latent), axis=2), \n",
        "                                  f_x_4_dia, stride=1, padding='SAME')                # batch_size x max_length x filter_num\n",
        "  x_out_conv_dia_5 = tf.nn.conv1d(tf.concat((x_out_conv_dia_4, de_latent), axis=2),\n",
        "                                  f_x_5_dia, stride=1, padding='SAME')                # batch_size x max_length x filter_num\n",
        "  x_out_conv_dia_6 = tf.nn.conv1d(tf.concat((x_out_conv_dia_5, de_latent), axis=2), \n",
        "                                  f_x_6_dia, stride=1, padding='SAME') \n",
        "  x_out_conv_dia_7 = tf.nn.conv1d(tf.concat((x_out_conv_dia_6, de_latent), axis=2), \n",
        "                                  f_x_7_dia, stride=1, padding='SAME') \n",
        "  x_out_conv_dia_8 = tf.nn.conv1d(tf.concat((x_out_conv_dia_7, de_latent), axis=2), \n",
        "                                  f_x_8_dia, stride=1, padding='SAME') \n",
        "\n",
        "  \n",
        "  x_out_conv_dia = tf.reshape(x_out_conv_dia_8, (batch_size*max_length, filter_num))\n",
        "  x_out_project = tf.matmul(x_out_conv_dia, proj_w_x) + proj_b_x                                       # batch_size*max_length x embed_size \n",
        "  \n",
        "  target_x = tf.reduce_sum(x_out_project*tf.reshape(inputs, (batch_size*max_length, embed_size)), axis=1)\n",
        "  logits_x = tf.matmul(x_out_project, tf.transpose(en_embedding,(1,0)))\n",
        "\n",
        "  logits_x_re = tf.reshape(logits_x, (batch_size, max_length, en_vocab_size))                                   # batch_size x max_length x fr_vocab_size\n",
        "  x_max = tf.reshape(tf.reduce_max(logits_x_re, axis=2), (batch_size*max_length, 1))                            # batch_size*max_length x 1\n",
        "\n",
        "  prob_unnorm_x = tf.exp(tf.reshape(target_x, (batch_size*max_length, 1)) - x_max)                                                                      # batch_size*max_length x 1\n",
        "  prob_constant_x = tf.exp(logits_x - tf.tile(x_max,(1, en_vocab_size)))                                        # batch_size*max_length x fr_vocab_size\n",
        "                                           \n",
        "  prob_norm_x = prob_unnorm_x/tf.reshape(tf.reduce_sum(prob_constant_x, axis=1), (batch_size*max_length, 1))              # batch_size*max_length x 1\n",
        "  prob_norm_x = tf.reshape(prob_norm_x, (batch_size, max_length))                                                         # batch_size x max_length\n",
        "  log_prob_norm_x = tf.log(tf.clip_by_value(prob_norm_x,1e-8,1.0))                                                        # batch_size x max_length\n",
        "\n",
        "  log_liki_x = tf.reduce_sum(log_prob_norm_x*squence_weight_x, axis=1)                                                    # batch_size x 1\n",
        "  return log_liki_x\n",
        "\n",
        "log_liki_x_to = []\n",
        "for l in range(latent_num):\n",
        "  log_liki_x_to.append(x_decoder(x_input_cnn[l], latent_variables[l]))\n",
        "log_liki_x_to = tf.stack(log_liki_x_to, axis=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "T4gCPfEbETNw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# def x_decoder_gene(de_input, latent_var):\n",
        "  \n",
        "#   x_out_conv_dia_1 = tf.nn.conv1d(de_input, f_x_1_dia, stride=1, padding='SAME')                     # batch_size x max_length x filter_num\n",
        "#   x_out_conv_dia_2 = tf.nn.conv1d(x_out_conv_dia_1, f_x_2_dia, stride=1, padding='SAME')                # batch_size x max_length x filter_num\n",
        "#   x_out_conv_dia_3 = tf.nn.conv1d(x_out_conv_dia_2, f_x_3_dia, stride=1, padding='SAME')                # batch_size x max_length x filter_num\n",
        "#   x_out_conv_dia_4 = tf.nn.conv1d(x_out_conv_dia_3, f_x_4_dia, stride=1, padding='SAME')                # batch_size x max_length x filter_num\n",
        "#   x_out_conv_dia_5 = tf.nn.conv1d(x_out_conv_dia_4, f_x_5_dia, stride=1, padding='SAME')                # batch_size x max_length x filter_num\n",
        "#   x_out_conv_dia_6 = tf.nn.conv1d(x_out_conv_dia_5, f_x_6_dia, stride=1, padding='SAME') \n",
        "#   x_out_conv_dia_7 = tf.nn.conv1d(x_out_conv_dia_6, f_x_7_dia, stride=1, padding='SAME') \n",
        "#   x_out_conv_dia_8 = tf.nn.conv1d(x_out_conv_dia_7, f_x_8_dia, stride=1, padding='SAME') \n",
        "\n",
        "#   x_out_conv_dia = tf.reshape(x_out_conv_dia_5, (batch_size*max_length, filter_num))\n",
        "#   x_out_project = tf.matmul(x_out_conv_dia, proj_w_x) + proj_b_x                                       # batch_size*max_length x embed_size \n",
        "  \n",
        "#   logits_x = tf.matmul(x_out_project, tf.transpose(en_embedding,(1,0)))\n",
        "  \n",
        "#   return logits_x\n",
        "\n",
        "# logits_gene_x_to = []\n",
        "# for l in range(latent_num):\n",
        "#   logits_gene_x_to.append(x_decoder_gene(x_input_cnn[l], latent_variables[l]))\n",
        "# logits_gene_x_to = tf.stack(logits_gene_x_to, axis=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gJjC0NuO9oE4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 2.2 Generation Model for target sentence $p_\\theta(y|z_1, z_2, ... , z_T)$\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "-H6P3ob3kPlM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#### concat beg token with target\n",
        "\n",
        "#beg_token_y = tf.zeros((1,embed_size))\n",
        "beg_token_y = tf.reshape(fr_embedding[fr_eos], [1,embed_size])\n",
        "\n",
        "y_list = tf.split(targets_drop, axis=0, num_or_size_splits=batch_size)\n",
        "\n",
        "y_with_beg_list = [tf.concat((beg_token_y, target[0]), axis=0) for target in y_list]              # batch_size x (max_length+1) x embed_size\n",
        "\n",
        "y_with_beg = tf.stack(y_with_beg_list, axis=0)\n",
        "\n",
        "y_input_cnn = []\n",
        "for l in range(latent_num):\n",
        "  y_input_cnn.append(tf.concat([latent_variables[l],y_with_beg[:,:30,:]], axis=2))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yOXJ7cF67vcb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "with tf.variable_scope('y_con_dialted_1D'):\n",
        "  \n",
        "    f_y_1 = tf.get_variable(\"y_filter_1\", shape=[2, embed_size+latent_size, filter_num], dtype=tf.float32, initializer=xavier_initializer)\n",
        "    f_y_1_dia = tf.concat([f_y_1, \n",
        "                           tf.zeros((1,embed_size+latent_size,filter_num))], axis=0)  \n",
        "                                    \n",
        "    # 3 x (embed_size+latent_size) x filter_num\n",
        "    \n",
        "    f_y_2 = tf.get_variable(\"y_filter_2\", shape=[3, filter_num+latent_size, filter_num], dtype=tf.float32, initializer=xavier_initializer)\n",
        "    f_y_2_dia = tf.concat([tf.reshape(f_y_2[0],(1,filter_num+latent_size,filter_num)), \n",
        "                           tf.zeros((1,filter_num+latent_size,filter_num)), \n",
        "                           tf.reshape(f_y_2[1],(1,filter_num+latent_size,filter_num)), \n",
        "                           tf.zeros((1,filter_num+latent_size,filter_num)),\n",
        "                           tf.reshape(f_y_2[2],(1,filter_num+latent_size,filter_num)),\n",
        "                           tf.zeros((4,filter_num+latent_size,filter_num)),], axis=0)\n",
        "    # 9 x filter_num x filter_num\n",
        "    \n",
        "    f_y_3 = tf.get_variable(\"y_filter_3\", shape=[3, filter_num+latent_size, filter_num], dtype=tf.float32, initializer=xavier_initializer)\n",
        "    f_y_3_dia = tf.concat([tf.reshape(f_y_3[0],(1,filter_num+latent_size,filter_num)), \n",
        "                           tf.zeros((3,filter_num+latent_size,filter_num)), \n",
        "                           tf.reshape(f_y_3[1],(1,filter_num+latent_size,filter_num)), \n",
        "                           tf.zeros((3,filter_num+latent_size,filter_num)),\n",
        "                           tf.reshape(f_y_3[2],(1,filter_num+latent_size,filter_num)),\n",
        "                           tf.zeros((8,filter_num+latent_size,filter_num))], axis=0)\n",
        "    # 13 x filter_num x filter_num\n",
        "    \n",
        "    f_y_4 = tf.get_variable(\"y_filter_4\", shape=[3, filter_num+latent_size, filter_num], dtype=tf.float32, initializer=xavier_initializer)\n",
        "    f_y_4_dia = tf.concat([tf.reshape(f_y_4[0],(1,filter_num+latent_size,filter_num)), \n",
        "                           tf.zeros((7,filter_num+latent_size,filter_num)), \n",
        "                           tf.reshape(f_y_4[1],(1,filter_num+latent_size,filter_num)), \n",
        "                           tf.zeros((7,filter_num+latent_size,filter_num)),\n",
        "                           tf.reshape(f_y_4[2],(1,filter_num+latent_size,filter_num)),\n",
        "                           tf.zeros((16,filter_num+latent_size,filter_num))], axis=0)\n",
        "    # 21 x filter_num x filter_num\n",
        "    \n",
        "    f_y_5 = tf.get_variable(\"y_filter_5\", shape=[2, filter_num+latent_size, filter_num], dtype=tf.float32, initializer=xavier_initializer)\n",
        "    f_y_5_dia = tf.concat([f_y_5, \n",
        "                           tf.zeros((1,filter_num+latent_size,filter_num))], axis=0)  \n",
        "                                    \n",
        "    # 3 x (embed_size+latent_size) x filter_num\n",
        "    \n",
        "    f_y_6 = tf.get_variable(\"y_filter_6\", shape=[3, filter_num+latent_size, filter_num], dtype=tf.float32, initializer=xavier_initializer)\n",
        "    f_y_6_dia = tf.concat([tf.reshape(f_y_6[0],(1,filter_num+latent_size,filter_num)), \n",
        "                           tf.zeros((1,filter_num+latent_size,filter_num)), \n",
        "                           tf.reshape(f_y_6[1],(1,filter_num+latent_size,filter_num)), \n",
        "                           tf.zeros((1,filter_num+latent_size,filter_num)),\n",
        "                           tf.reshape(f_y_6[2],(1,filter_num+latent_size,filter_num)),\n",
        "                           tf.zeros((4,filter_num+latent_size,filter_num)),], axis=0)\n",
        "    # 9 x filter_num x filter_num\n",
        "    \n",
        "    f_y_7 = tf.get_variable(\"y_filter_7\", shape=[3, filter_num+latent_size, filter_num], dtype=tf.float32, initializer=xavier_initializer)\n",
        "    f_y_7_dia = tf.concat([tf.reshape(f_y_7[0],(1,filter_num+latent_size,filter_num)), \n",
        "                           tf.zeros((3,filter_num+latent_size,filter_num)), \n",
        "                           tf.reshape(f_y_7[1],(1,filter_num+latent_size,filter_num)), \n",
        "                           tf.zeros((3,filter_num+latent_size,filter_num)),\n",
        "                           tf.reshape(f_y_7[2],(1,filter_num+latent_size,filter_num)),\n",
        "                           tf.zeros((8,filter_num+latent_size,filter_num))], axis=0)\n",
        "    # 13 x filter_num x filter_num\n",
        "    \n",
        "    f_y_8 = tf.get_variable(\"y_filter_8\", shape=[3, filter_num+latent_size, filter_num], dtype=tf.float32, initializer=xavier_initializer)\n",
        "    f_y_8_dia = tf.concat([tf.reshape(f_y_8[0],(1,filter_num+latent_size,filter_num)), \n",
        "                           tf.zeros((7,filter_num+latent_size,filter_num)), \n",
        "                           tf.reshape(f_y_8[1],(1,filter_num+latent_size,filter_num)), \n",
        "                           tf.zeros((7,filter_num+latent_size,filter_num)),\n",
        "                           tf.reshape(f_y_8[2],(1,filter_num+latent_size,filter_num)),\n",
        "                           tf.zeros((16,filter_num+latent_size,filter_num))], axis=0)\n",
        "    # 21 x filter_num x filter_num\n",
        "\n",
        "    \n",
        "    \n",
        "#### variablen of a FC layer to map the hidden state of the decoder-rnn in each time-step to the predicted next word\n",
        "with tf.variable_scope('projection_y'):\n",
        "    proj_w_y = tf.get_variable('project_w_y', [filter_num,embed_size], dtype=tf.float32, initializer=xavier_initializer)\n",
        "    proj_b_y = tf.get_variable('project_b_y', [embed_size,], dtype=tf.float32, initializer=xavier_initializer)\n",
        "    \n",
        "    \n",
        "#### sequence weight of y\n",
        "squence_weight_y = tf.sequence_mask(out_length_placeholder, maxlen=max_length, dtype=tf.float32)                        # batch_size x max_length"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xpRsIIdCj5so",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def y_decoder(de_input, de_latent):\n",
        "  \n",
        "  y_out_conv_dia_1 = tf.nn.conv1d(de_input, \n",
        "                                  f_y_1_dia, stride=1, padding='SAME')                     # batch_size x max_length x filter_num\n",
        "  y_out_conv_dia_2 = tf.nn.conv1d(tf.concat((y_out_conv_dia_1, de_latent), axis=2),\n",
        "                                  f_y_2_dia, stride=1, padding='SAME')                # batch_size x max_length x filter_num\n",
        "  y_out_conv_dia_3 = tf.nn.conv1d(tf.concat((y_out_conv_dia_2, de_latent), axis=2), \n",
        "                                  f_y_3_dia, stride=1, padding='SAME')                # batch_size x max_length x filter_num\n",
        "  y_out_conv_dia_4 = tf.nn.conv1d(tf.concat((y_out_conv_dia_3, de_latent), axis=2), \n",
        "                                  f_y_4_dia, stride=1, padding='SAME')                # batch_size x max_length x filter_num\n",
        "  y_out_conv_dia_5 = tf.nn.conv1d(tf.concat((y_out_conv_dia_4, de_latent), axis=2), \n",
        "                                  f_y_5_dia, stride=1, padding='SAME')                # batch_size x max_length x filter_num\n",
        "  y_out_conv_dia_6 = tf.nn.conv1d(tf.concat((y_out_conv_dia_5, de_latent), axis=2), \n",
        "                                  f_y_6_dia, stride=1, padding='SAME') \n",
        "  y_out_conv_dia_7 = tf.nn.conv1d(tf.concat((y_out_conv_dia_6, de_latent), axis=2), \n",
        "                                  f_y_7_dia, stride=1, padding='SAME') \n",
        "  y_out_conv_dia_8 = tf.nn.conv1d(tf.concat((y_out_conv_dia_7, de_latent), axis=2),\n",
        "                                  f_y_8_dia, stride=1, padding='SAME') \n",
        "\n",
        "  y_out_conv_dia = tf.reshape(y_out_conv_dia_8, (batch_size*max_length, filter_num))\n",
        "  y_out_project = tf.matmul(y_out_conv_dia, proj_w_y) + proj_b_y                                       \n",
        "\n",
        "  target_y = tf.reduce_sum(y_out_project*tf.reshape(targets, (batch_size*max_length, embed_size)), axis=1)\n",
        "  logits_y = tf.matmul(y_out_project, tf.transpose(fr_embedding,(1,0)))\n",
        "\n",
        "  logits_y_re = tf.reshape(logits_y, (batch_size, max_length, fr_vocab_size))                                   # batch_size x max_length x fr_vocab_size\n",
        "  y_max = tf.reshape(tf.reduce_max(logits_y_re, axis=2), (batch_size*max_length, 1))                            # batch_size*max_length x 1\n",
        "\n",
        "  prob_unnorm_y = tf.exp(tf.reshape(target_y, (batch_size*max_length, 1)) - y_max)                              # batch_size*max_length x 1\n",
        "  prob_constant_y = tf.exp(logits_y - tf.tile(y_max,(1, fr_vocab_size)))                                        # batch_size*max_length x fr_vocab_size\n",
        "                                           \n",
        "  prob_norm_y = prob_unnorm_y/tf.reshape(tf.reduce_sum(prob_constant_y, axis=1), (batch_size*max_length, 1))              # batch_size*max_length x 1\n",
        "  prob_norm_y = tf.reshape(prob_norm_y, (batch_size, max_length))                                                         # batch_size x max_length\n",
        "  log_prob_norm_y = tf.log(tf.clip_by_value(prob_norm_y,1e-8,1.0))                                                        # batch_size x max_length\n",
        "\n",
        "  log_liki_y = tf.reduce_sum(log_prob_norm_y*squence_weight_y, axis=1)                                                    # batch_size x 1\n",
        "  return log_liki_y\n",
        "\n",
        "log_liki_y_to = []\n",
        "for l in range(latent_num):\n",
        "  log_liki_y_to.append(y_decoder(y_input_cnn[l], latent_variables[l]))\n",
        "log_liki_y_to = tf.stack(log_liki_y_to, axis=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Jb2g_kS1cKxa",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### The lower bound of log-joint-likelihood, to maximize"
      ]
    },
    {
      "metadata": {
        "id": "5wHFYwB9jkDL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "nega_log_liki_x_y = 0\n",
        "\n",
        "nega_elbo = 0\n",
        "\n",
        "for l in range(latent_num):\n",
        "  nega_log_liki_x_y = nega_log_liki_x_y + tf.reduce_mean(- log_liki_x_to[l] - log_liki_y_to[l])\n",
        "  nega_elbo = nega_elbo - log_liki_x_to[l] - log_liki_y_to[l]\n",
        "  \n",
        "nega_log_liki_x_y = nega_log_liki_x_y/latent_num\n",
        "nega_elbo = nega_elbo/latent_num + discount_placeholder*kl_div_loss\n",
        "objective = tf.reduce_mean(nega_elbo) \n",
        "kl_div_loss_batch_mean = tf.reduce_mean(kl_div_loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2Z8P6-XM38MV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# L2 reguralization for trainable variables\n",
        "#train_variables = tf.trainable_variables()\n",
        "#regularization_cost = tf.reduce_sum([tf.nn.l2_loss(variable) for variable in train_variables])\n",
        "#regular_rate = 0.00001\n",
        "#+ regular_rate*regularization_cost"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UwMB6m32Yzfr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "optimizer = tf.train.AdamOptimizer(lr_placeholder)\n",
        "\n",
        "gvs, var = zip(*optimizer.compute_gradients(objective))\n",
        "\n",
        "#checked_gvs = [tf.where(tf.is_nan(grad), tf.zeros_like(grad), grad) for grad in gvs]\n",
        "\n",
        "cliped_gvs, _ = tf.clip_by_global_norm(gvs, 1)\n",
        "\n",
        "opt = optimizer.apply_gradients(zip(cliped_gvs, var))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "m4Glrs-GxHeJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
        "#gvs = optimizer.compute_gradients(objective)\n",
        "#capped_gvs = [(tf.clip_by_norm(grad, 1), var) for grad, var in gvs]\n",
        "#opt = optimizer.apply_gradients(capped_gvs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ASMl3Fgnsyfy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#### save the model\n",
        "def save_model(session, path):\n",
        "    if not os.path.exists(\"./result_0821/\"):\n",
        "        os.mkdir('./result_0821/')\n",
        "    saver = tf.train.Saver()\n",
        "    saver.save(session, path)\n",
        "\n",
        "path1 = './result_0821/model_each_epch.ckpt'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CAsNGMQ_CY8t",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def sigmoid(x):\n",
        "    return (1 / (1 + math.exp(-x)))\n",
        "\n",
        "\n",
        "def text_save(content,filename,mode='a'):\n",
        "    # Try to save a list variable in txt file.\n",
        "    file = open(filename,mode)\n",
        "    for i in range(len(content)):\n",
        "        file.write(str(content[i])+'\\n')\n",
        "    file.close()\n",
        "    \n",
        "def text_read(filename):\n",
        "    # Try to read a txt file and return a list.Return [] if there was a mistake.\n",
        "    try:\n",
        "        file = open(filename,'r')\n",
        "    except IOError:\n",
        "        error = []\n",
        "        return error\n",
        "    content = file.readlines()\n",
        " \n",
        "    for i in range(len(content)):\n",
        "        content[i] = content[i][:len(content[i])-1]\n",
        " \n",
        "    file.close()\n",
        "    return content"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "E546I60IPRWK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Training "
      ]
    },
    {
      "metadata": {
        "id": "RovgeCM_9-i3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 8461
        },
        "outputId": "0ff02140-4a5d-4131-841d-de6804b07f94"
      },
      "cell_type": "code",
      "source": [
        "max_epochs = 5\n",
        "total_step = 0\n",
        "learning_rate = 0.0005\n",
        "\n",
        "zero_latent = np.zeros((latent_num, batch_size, max_length, latent_size))\n",
        "elbo_results=[]\n",
        "kl_results = []\n",
        "likei_results = []\n",
        "\n",
        "\n",
        "init = tf.global_variables_initializer()\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    \n",
        "    saver = tf.train.Saver()\n",
        "    saver.restore(sess, path1)\n",
        "    \n",
        "    for epoc in range(max_epochs):\n",
        "      \n",
        "        print(\"learning rate\")\n",
        "        print(learning_rate)\n",
        "      \n",
        "        print('Epoch {}'.format(epoc))\n",
        "\n",
        "        ind_small_txt = epoc + 5\n",
        "        \n",
        "        en_file = \"../small_txt/\" + str(ind_small_txt) + \"_en.txt\"\n",
        "        fr_file = \"../small_txt/\" + str(ind_small_txt) + \"_fr.txt\"\n",
        "        \n",
        "        print(en_file)\n",
        "        print(fr_file)\n",
        "        \n",
        "        en_input, en_input_len = generate_input_en(en_file, en_word_to_id, max_length)\n",
        "        fr_output, fr_output_len = generate_output_fr(fr_file, fr_word_to_id, max_length)\n",
        "\n",
        "        en_input_batches, en_input_len_batches = batch_producer(en_input, en_input_len, batch_size) \n",
        "        fr_output_batches, fr_output_len_batches = batch_producer(fr_output, fr_output_len, batch_size)\n",
        "        \n",
        "        en_input_drop_batches = dropout_func(en_input_batches, 0.8, en_oov_id)\n",
        "        fr_output_drop_batches = dropout_func(fr_output_batches, 0.8, fr_oov_id)\n",
        "         \n",
        "                       \n",
        "        batch_len = en_input_batches.shape[0]\n",
        "        \n",
        "        ########### training ###########\n",
        "        for i in range(batch_len):\n",
        "          \n",
        "            #discount_rate = sigmoid(0.0025*(total_step-2500))\n",
        "            if total_step<3000:\n",
        "              discount_rate = 0.0002*total_step\n",
        "            if total_step>=3000:\n",
        "              discount_rate = 0.6 + 0.00005*(total_step-3000)\n",
        "            \n",
        "            if discount_rate >1:\n",
        "              discount_rate = 1\n",
        " \n",
        "            feed_dict = {input_placeholder: en_input_batches[i], \n",
        "                         target_placeholder: fr_output_batches[i],\n",
        "                         input_drop_placeholder: en_input_drop_batches[i], \n",
        "                         target_drop_placeholder: fr_output_drop_batches[i],\n",
        "                         in_length_placeholder: en_input_len_batches[i], \n",
        "                         out_length_placeholder: fr_output_len_batches[i],\n",
        "                         discount_placeholder: discount_rate,\n",
        "                         lr_placeholder: learning_rate,\n",
        "                         if_gene_placeholder: False,\n",
        "                         latent_var_placeholder: zero_latent}\n",
        "  \n",
        "      \n",
        "            kl, nage_likeli, llx, lly, objecti,  _ = sess.run([kl_div_loss_batch_mean, nega_log_liki_x_y, log_liki_x_to, log_liki_y_to, objective, opt], feed_dict=feed_dict)       \n",
        "            \n",
        "            llx_mean = -np.mean(llx)\n",
        "            lly_mean = -np.mean(lly)\n",
        "            \n",
        "              \n",
        "            if i%100 == 0:\n",
        "              print(kl)\n",
        "              print(nage_likeli)\n",
        "              print(objecti)\n",
        "              print(discount_rate)\n",
        "              \n",
        "              print(llx_mean)\n",
        "              print(lly_mean)\n",
        " \n",
        "              elbo_results.append(objecti)\n",
        "              kl_results.append(kl)\n",
        "              likei_results.append(nage_likeli)\n",
        "            \n",
        "            total_step = total_step + 1\n",
        "            \n",
        "        save_model(sess, path1)\n",
        "        \n",
        "text_save(elbo_results, './result_0821/elbo_results.txt')\n",
        "text_save(kl_results, './result_0821/kl_results.txt')\n",
        "text_save(likei_results, './result_0821/likei_results.txt')"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "learning rate\n",
            "0.0005\n",
            "Epoch 0\n",
            "../small_txt/0_en.txt\n",
            "../small_txt/0_fr.txt\n",
            "21.842857\n",
            "475.9725\n",
            "475.9725\n",
            "0.0\n",
            "232.34007\n",
            "243.6324\n",
            "270.5965\n",
            "261.07578\n",
            "266.4877\n",
            "0.02\n",
            "126.86953\n",
            "134.20624\n",
            "145.43738\n",
            "257.6772\n",
            "263.49466\n",
            "0.04\n",
            "127.99026\n",
            "129.6869\n",
            "232.02155\n",
            "223.16815\n",
            "237.08942\n",
            "0.060000000000000005\n",
            "107.43432\n",
            "115.73379\n",
            "195.0483\n",
            "220.21664\n",
            "235.8205\n",
            "0.08\n",
            "105.87684\n",
            "114.33978\n",
            "162.31958\n",
            "212.2909\n",
            "228.52283\n",
            "0.1\n",
            "103.34811\n",
            "108.94278\n",
            "137.92197\n",
            "187.28032\n",
            "203.83093\n",
            "0.12000000000000001\n",
            "90.17523\n",
            "97.10507\n",
            "129.7918\n",
            "172.52534\n",
            "190.69617\n",
            "0.14\n",
            "85.04935\n",
            "87.47597\n",
            "137.92294\n",
            "168.91411\n",
            "190.98174\n",
            "0.16\n",
            "82.024895\n",
            "86.88919\n",
            "142.14656\n",
            "164.76717\n",
            "190.35356\n",
            "0.18000000000000002\n",
            "79.906784\n",
            "84.86039\n",
            "150.69884\n",
            "155.81822\n",
            "185.958\n",
            "0.2\n",
            "76.84219\n",
            "78.976036\n",
            "139.63481\n",
            "139.27205\n",
            "169.9917\n",
            "0.22\n",
            "70.5575\n",
            "68.71454\n",
            "152.45526\n",
            "146.57909\n",
            "183.16833\n",
            "0.24000000000000002\n",
            "73.104576\n",
            "73.47451\n",
            "155.3753\n",
            "145.7462\n",
            "186.14378\n",
            "0.26\n",
            "73.035774\n",
            "72.71043\n",
            "149.82071\n",
            "131.98433\n",
            "173.93414\n",
            "0.28\n",
            "63.542843\n",
            "68.44149\n",
            "learning rate\n",
            "0.0005\n",
            "Epoch 1\n",
            "../small_txt/1_en.txt\n",
            "../small_txt/1_fr.txt\n",
            "162.82458\n",
            "128.90346\n",
            "177.71826\n",
            "0.2998\n",
            "62.58188\n",
            "66.32156\n",
            "171.77213\n",
            "120.381004\n",
            "175.3137\n",
            "0.31980000000000003\n",
            "59.41234\n",
            "60.968662\n",
            "168.53334\n",
            "112.274895\n",
            "169.54253\n",
            "0.3398\n",
            "56.0131\n",
            "56.261787\n",
            "171.2244\n",
            "117.78181\n",
            "179.38834\n",
            "0.3598\n",
            "59.346874\n",
            "58.434925\n",
            "161.35263\n",
            "111.302284\n",
            "172.584\n",
            "0.3798\n",
            "56.583622\n",
            "54.71866\n",
            "156.79167\n",
            "106.26493\n",
            "168.95024\n",
            "0.39980000000000004\n",
            "53.810776\n",
            "52.454155\n",
            "167.40794\n",
            "117.31376\n",
            "187.59161\n",
            "0.4198\n",
            "57.950428\n",
            "59.36333\n",
            "154.72485\n",
            "110.799324\n",
            "178.84732\n",
            "0.4398\n",
            "55.63898\n",
            "55.16033\n",
            "139.71994\n",
            "106.64428\n",
            "170.8875\n",
            "0.45980000000000004\n",
            "54.62878\n",
            "52.015488\n",
            "149.34314\n",
            "112.09777\n",
            "183.75262\n",
            "0.4798\n",
            "56.426723\n",
            "55.67105\n",
            "149.62848\n",
            "116.54793\n",
            "191.33224\n",
            "0.4998\n",
            "60.252125\n",
            "56.295807\n",
            "135.04018\n",
            "105.70637\n",
            "175.90027\n",
            "0.5198\n",
            "55.420143\n",
            "50.28622\n",
            "137.21864\n",
            "109.67533\n",
            "183.74596\n",
            "0.5398000000000001\n",
            "54.253212\n",
            "55.422123\n",
            "136.65895\n",
            "113.27627\n",
            "189.77795\n",
            "0.5598000000000001\n",
            "57.4398\n",
            "55.836464\n",
            "130.93768\n",
            "105.90077\n",
            "181.81844\n",
            "0.5798\n",
            "53.213867\n",
            "52.6869\n",
            "learning rate\n",
            "0.0005\n",
            "Epoch 2\n",
            "../small_txt/2_en.txt\n",
            "../small_txt/2_fr.txt\n",
            "135.80725\n",
            "123.69232\n",
            "205.12234\n",
            "0.5996\n",
            "64.1291\n",
            "59.56322\n",
            "130.36517\n",
            "110.21024\n",
            "189.06813\n",
            "0.6049\n",
            "56.423927\n",
            "53.78631\n",
            "132.02472\n",
            "109.00381\n",
            "189.52568\n",
            "0.6099\n",
            "56.27883\n",
            "52.724976\n",
            "133.2441\n",
            "111.53812\n",
            "193.46991\n",
            "0.6149\n",
            "58.400246\n",
            "53.137875\n",
            "128.54463\n",
            "105.49165\n",
            "185.17648\n",
            "0.6199\n",
            "56.05491\n",
            "49.436752\n",
            "128.18863\n",
            "106.904785\n",
            "187.00986\n",
            "0.6249\n",
            "58.34119\n",
            "48.563595\n",
            "136.83354\n",
            "112.46477\n",
            "198.6562\n",
            "0.6299\n",
            "59.73957\n",
            "52.725204\n",
            "133.66182\n",
            "107.25528\n",
            "192.11719\n",
            "0.6349\n",
            "58.801216\n",
            "48.454063\n",
            "135.60657\n",
            "107.38233\n",
            "194.15697\n",
            "0.6399\n",
            "57.971012\n",
            "49.411327\n",
            "141.98795\n",
            "112.84343\n",
            "204.41147\n",
            "0.6449\n",
            "61.29658\n",
            "51.546844\n",
            "134.9924\n",
            "107.29233\n",
            "195.02391\n",
            "0.6498999999999999\n",
            "55.54502\n",
            "51.7473\n",
            "128.49095\n",
            "105.74309\n",
            "189.89182\n",
            "0.6549\n",
            "56.653385\n",
            "49.08971\n",
            "126.83694\n",
            "106.26769\n",
            "189.9674\n",
            "0.6598999999999999\n",
            "57.02115\n",
            "49.24655\n",
            "124.97652\n",
            "105.639755\n",
            "188.73663\n",
            "0.6648999999999999\n",
            "56.26006\n",
            "49.379696\n",
            "130.36365\n",
            "111.74793\n",
            "199.07854\n",
            "0.6698999999999999\n",
            "58.37409\n",
            "53.373833\n",
            "learning rate\n",
            "0.0005\n",
            "Epoch 3\n",
            "../small_txt/3_en.txt\n",
            "../small_txt/3_fr.txt\n",
            "129.07787\n",
            "139.12495\n",
            "226.23314\n",
            "0.67485\n",
            "63.440147\n",
            "75.68481\n",
            "119.86919\n",
            "103.29308\n",
            "184.78615\n",
            "0.67985\n",
            "56.01094\n",
            "47.282154\n",
            "127.15746\n",
            "113.40132\n",
            "200.48512\n",
            "0.68485\n",
            "60.17148\n",
            "53.229843\n",
            "121.05196\n",
            "106.36104\n",
            "189.86874\n",
            "0.68985\n",
            "56.553333\n",
            "49.807693\n",
            "123.366165\n",
            "109.64353\n",
            "195.36453\n",
            "0.69485\n",
            "57.32275\n",
            "52.32078\n",
            "125.301125\n",
            "109.42915\n",
            "197.12115\n",
            "0.69985\n",
            "58.91478\n",
            "50.514366\n",
            "123.345726\n",
            "115.65232\n",
            "202.59254\n",
            "0.70485\n",
            "61.772377\n",
            "53.87994\n",
            "122.33818\n",
            "105.675545\n",
            "192.51732\n",
            "0.70985\n",
            "55.852886\n",
            "49.822666\n",
            "121.29684\n",
            "110.30257\n",
            "197.01163\n",
            "0.71485\n",
            "58.92901\n",
            "51.373566\n",
            "117.24429\n",
            "104.07209\n",
            "188.47041\n",
            "0.71985\n",
            "55.70785\n",
            "48.36424\n",
            "114.638885\n",
            "104.68155\n",
            "187.77756\n",
            "0.72485\n",
            "54.67478\n",
            "50.00677\n",
            "109.950775\n",
            "104.33789\n",
            "184.58545\n",
            "0.72985\n",
            "54.33546\n",
            "50.002426\n",
            "113.328224\n",
            "107.741745\n",
            "191.021\n",
            "0.73485\n",
            "58.298477\n",
            "49.443268\n",
            "113.72597\n",
            "107.83589\n",
            "191.97603\n",
            "0.73985\n",
            "56.788525\n",
            "51.04735\n",
            "113.85169\n",
            "111.16913\n",
            "195.97159\n",
            "0.74485\n",
            "58.802734\n",
            "52.36639\n",
            "learning rate\n",
            "0.0005\n",
            "Epoch 4\n",
            "../small_txt/4_en.txt\n",
            "../small_txt/4_fr.txt\n",
            "110.497826\n",
            "112.42296\n",
            "195.27422\n",
            "0.7498\n",
            "59.947994\n",
            "52.474964\n",
            "106.71724\n",
            "107.11772\n",
            "187.6679\n",
            "0.7548\n",
            "56.458824\n",
            "50.658897\n",
            "110.02361\n",
            "116.42708\n",
            "200.02303\n",
            "0.7598\n",
            "62.336636\n",
            "54.090443\n",
            "106.89886\n",
            "106.68871\n",
            "188.44498\n",
            "0.7647999999999999\n",
            "56.068222\n",
            "50.62048\n",
            "107.45421\n",
            "117.1823\n",
            "199.90057\n",
            "0.7698\n",
            "62.066597\n",
            "55.115707\n",
            "102.416466\n",
            "105.54981\n",
            "184.90208\n",
            "0.7747999999999999\n",
            "56.725166\n",
            "48.824642\n",
            "106.40154\n",
            "114.780174\n",
            "197.75209\n",
            "0.7798\n",
            "61.97562\n",
            "52.80456\n",
            "107.78574\n",
            "122.438416\n",
            "207.02866\n",
            "0.7847999999999999\n",
            "65.55164\n",
            "56.886772\n",
            "107.80943\n",
            "117.74423\n",
            "202.89214\n",
            "0.7898\n",
            "62.53681\n",
            "55.20742\n",
            "99.968956\n",
            "112.91131\n",
            "192.36662\n",
            "0.7948\n",
            "58.37594\n",
            "54.535355\n",
            "101.11847\n",
            "117.25243\n",
            "198.12697\n",
            "0.7998\n",
            "61.5866\n",
            "55.66583\n",
            "101.095726\n",
            "118.2016\n",
            "199.56343\n",
            "0.8048\n",
            "64.77498\n",
            "53.426636\n",
            "100.48179\n",
            "119.738396\n",
            "201.10855\n",
            "0.8098\n",
            "64.00709\n",
            "55.73131\n",
            "95.93233\n",
            "117.24966\n",
            "195.41531\n",
            "0.8148\n",
            "62.394306\n",
            "54.855343\n",
            "94.28949\n",
            "121.16541\n",
            "198.46393\n",
            "0.8198\n",
            "65.06829\n",
            "56.097115\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "jATjRBvrZhi-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 8478
        },
        "outputId": "1a6f57b3-4842-4cd3-eb01-4e254c0ff0e6"
      },
      "cell_type": "code",
      "source": [
        "max_epochs = 5\n",
        "total_step = 0\n",
        "learning_rate = 0.0005\n",
        "\n",
        "zero_latent = np.zeros((latent_num, batch_size, max_length, latent_size))\n",
        "elbo_results=[]\n",
        "kl_results = []\n",
        "likei_results = []\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    \n",
        "    saver = tf.train.Saver()\n",
        "    saver.restore(sess, path1)\n",
        "    \n",
        "    for epoc in range(max_epochs):\n",
        "      \n",
        "        print(\"learning rate\")\n",
        "        print(learning_rate)\n",
        "      \n",
        "        print('Epoch {}'.format(epoc))\n",
        "\n",
        "        ind_small_txt = epoc + 5\n",
        "        \n",
        "        en_file = \"../small_txt/\" + str(ind_small_txt) + \"_en.txt\"\n",
        "        fr_file = \"../small_txt/\" + str(ind_small_txt) + \"_fr.txt\"\n",
        "        \n",
        "        print(en_file)\n",
        "        print(fr_file)\n",
        "        \n",
        "        en_input, en_input_len = generate_input_en(en_file, en_word_to_id, max_length)\n",
        "        fr_output, fr_output_len = generate_output_fr(fr_file, fr_word_to_id, max_length)\n",
        "\n",
        "        en_input_batches, en_input_len_batches = batch_producer(en_input, en_input_len, batch_size) \n",
        "        fr_output_batches, fr_output_len_batches = batch_producer(fr_output, fr_output_len, batch_size)\n",
        "        \n",
        "        en_input_drop_batches = dropout_func(en_input_batches, 0.8, en_oov_id)\n",
        "        fr_output_drop_batches = dropout_func(fr_output_batches, 0.8, fr_oov_id)\n",
        "         \n",
        "                       \n",
        "        batch_len = en_input_batches.shape[0]\n",
        "        \n",
        "        ########### training ###########\n",
        "        for i in range(batch_len):\n",
        "          \n",
        "            #discount_rate = sigmoid(0.0025*(total_step-2500))\n",
        "#             if total_step<3000:\n",
        "#               discount_rate = 0.0002*total_step\n",
        "#             if total_step>=3000:\n",
        "#               discount_rate = 0.6 + 0.00005*(total_step-3000)\n",
        "            \n",
        "#             if discount_rate >1:\n",
        "            discount_rate = 1\n",
        " \n",
        "            feed_dict = {input_placeholder: en_input_batches[i], \n",
        "                         target_placeholder: fr_output_batches[i],\n",
        "                         input_drop_placeholder: en_input_drop_batches[i], \n",
        "                         target_drop_placeholder: fr_output_drop_batches[i],\n",
        "                         in_length_placeholder: en_input_len_batches[i], \n",
        "                         out_length_placeholder: fr_output_len_batches[i],\n",
        "                         discount_placeholder: discount_rate,\n",
        "                         lr_placeholder: learning_rate,\n",
        "                         if_gene_placeholder: False,\n",
        "                         latent_var_placeholder: zero_latent}\n",
        "  \n",
        "      \n",
        "            kl, nage_likeli, llx, lly, objecti,  _ = sess.run([kl_div_loss_batch_mean, nega_log_liki_x_y, log_liki_x_to, log_liki_y_to, objective, opt], feed_dict=feed_dict)       \n",
        "            \n",
        "            llx_mean = -np.mean(llx)\n",
        "            lly_mean = -np.mean(lly)\n",
        "            \n",
        "              \n",
        "            if i%100 == 0:\n",
        "              print(kl)\n",
        "              print(nage_likeli)\n",
        "              print(objecti)\n",
        "              print(discount_rate)\n",
        "              \n",
        "              print(llx_mean)\n",
        "              print(lly_mean)\n",
        " \n",
        "              elbo_results.append(objecti)\n",
        "              kl_results.append(kl)\n",
        "              likei_results.append(nage_likeli)\n",
        "            \n",
        "            total_step = total_step + 1\n",
        "            \n",
        "        save_model(sess, path1)\n",
        "        \n",
        "text_save(elbo_results, './result_0821/elbo_results.txt')\n",
        "text_save(kl_results, './result_0821/kl_results.txt')\n",
        "text_save(likei_results, './result_0821/likei_results.txt')"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from ./result_0821/model_each_epch.ckpt\n",
            "learning rate\n",
            "0.0005\n",
            "Epoch 0\n",
            "../small_txt/5_en.txt\n",
            "../small_txt/5_fr.txt\n",
            "26.123753\n",
            "151.34093\n",
            "177.46469\n",
            "1\n",
            "76.18398\n",
            "75.15695\n",
            "28.359802\n",
            "159.0103\n",
            "187.37007\n",
            "1\n",
            "81.470215\n",
            "77.54007\n",
            "28.762636\n",
            "160.14859\n",
            "188.91121\n",
            "1\n",
            "81.41623\n",
            "78.73236\n",
            "29.760796\n",
            "166.55109\n",
            "196.31186\n",
            "1\n",
            "84.12673\n",
            "82.42435\n",
            "29.319107\n",
            "164.13498\n",
            "193.45412\n",
            "1\n",
            "84.762344\n",
            "79.37266\n",
            "28.169819\n",
            "154.04355\n",
            "182.21336\n",
            "1\n",
            "78.58738\n",
            "75.45617\n",
            "28.759287\n",
            "164.52539\n",
            "193.28468\n",
            "1\n",
            "83.693695\n",
            "80.83171\n",
            "26.863594\n",
            "151.54195\n",
            "178.40553\n",
            "1\n",
            "75.783195\n",
            "75.75875\n",
            "27.58931\n",
            "153.50566\n",
            "181.09496\n",
            "1\n",
            "77.70287\n",
            "75.802795\n",
            "29.194298\n",
            "163.34048\n",
            "192.53479\n",
            "1\n",
            "82.79123\n",
            "80.549255\n",
            "30.060684\n",
            "168.9414\n",
            "199.00209\n",
            "1\n",
            "87.46111\n",
            "81.4803\n",
            "29.586977\n",
            "164.22365\n",
            "193.81062\n",
            "1\n",
            "83.28969\n",
            "80.93395\n",
            "28.721594\n",
            "161.87495\n",
            "190.59654\n",
            "1\n",
            "84.409004\n",
            "77.46595\n",
            "28.492685\n",
            "152.39923\n",
            "180.8919\n",
            "1\n",
            "76.64267\n",
            "75.75657\n",
            "29.402979\n",
            "163.5375\n",
            "192.94048\n",
            "1\n",
            "82.783714\n",
            "80.75379\n",
            "learning rate\n",
            "0.0005\n",
            "Epoch 1\n",
            "../small_txt/6_en.txt\n",
            "../small_txt/6_fr.txt\n",
            "28.013952\n",
            "160.47334\n",
            "188.4873\n",
            "1\n",
            "79.17597\n",
            "81.297386\n",
            "28.900602\n",
            "152.67877\n",
            "181.57938\n",
            "1\n",
            "77.01003\n",
            "75.66875\n",
            "29.955256\n",
            "159.3273\n",
            "189.28256\n",
            "1\n",
            "80.78054\n",
            "78.54676\n",
            "29.33661\n",
            "163.21707\n",
            "192.5537\n",
            "1\n",
            "82.62623\n",
            "80.590836\n",
            "28.821838\n",
            "153.15195\n",
            "181.97382\n",
            "1\n",
            "76.44204\n",
            "76.7099\n",
            "29.733465\n",
            "160.19331\n",
            "189.92677\n",
            "1\n",
            "80.966995\n",
            "79.22631\n",
            "28.083498\n",
            "146.37065\n",
            "174.45412\n",
            "1\n",
            "72.62645\n",
            "73.744194\n",
            "27.089487\n",
            "144.9545\n",
            "172.04399\n",
            "1\n",
            "71.84967\n",
            "73.10484\n",
            "29.887484\n",
            "154.5025\n",
            "184.38998\n",
            "1\n",
            "77.99202\n",
            "76.510475\n",
            "29.6617\n",
            "156.87047\n",
            "186.53217\n",
            "1\n",
            "77.14311\n",
            "79.72737\n",
            "29.22162\n",
            "157.67169\n",
            "186.89333\n",
            "1\n",
            "79.142914\n",
            "78.528786\n",
            "27.554619\n",
            "152.89294\n",
            "180.44756\n",
            "1\n",
            "76.2919\n",
            "76.60105\n",
            "28.519844\n",
            "156.8328\n",
            "185.35263\n",
            "1\n",
            "78.92617\n",
            "77.906624\n",
            "26.88111\n",
            "139.35385\n",
            "166.23495\n",
            "1\n",
            "70.28861\n",
            "69.06525\n",
            "30.265898\n",
            "155.22997\n",
            "185.49586\n",
            "1\n",
            "79.05287\n",
            "76.177086\n",
            "learning rate\n",
            "0.0005\n",
            "Epoch 2\n",
            "../small_txt/7_en.txt\n",
            "../small_txt/7_fr.txt\n",
            "29.46867\n",
            "155.48795\n",
            "184.95662\n",
            "1\n",
            "77.26136\n",
            "78.22659\n",
            "29.522028\n",
            "158.97945\n",
            "188.50146\n",
            "1\n",
            "81.662224\n",
            "77.31723\n",
            "27.901234\n",
            "147.5149\n",
            "175.41615\n",
            "1\n",
            "74.141525\n",
            "73.37338\n",
            "30.926403\n",
            "167.56357\n",
            "198.48996\n",
            "1\n",
            "85.49107\n",
            "82.07249\n",
            "29.70357\n",
            "160.4624\n",
            "190.16597\n",
            "1\n",
            "82.627594\n",
            "77.8348\n",
            "28.86807\n",
            "151.12206\n",
            "179.99011\n",
            "1\n",
            "76.193405\n",
            "74.92865\n",
            "29.51205\n",
            "155.62833\n",
            "185.14037\n",
            "1\n",
            "78.52598\n",
            "77.10234\n",
            "29.226574\n",
            "160.59973\n",
            "189.82631\n",
            "1\n",
            "80.35092\n",
            "80.2488\n",
            "30.436497\n",
            "157.9196\n",
            "188.3561\n",
            "1\n",
            "81.00357\n",
            "76.91602\n",
            "29.690584\n",
            "159.16788\n",
            "188.85844\n",
            "1\n",
            "80.97153\n",
            "78.19634\n",
            "30.494942\n",
            "165.4161\n",
            "195.91104\n",
            "1\n",
            "83.66069\n",
            "81.75542\n",
            "27.69055\n",
            "151.17528\n",
            "178.86584\n",
            "1\n",
            "74.90026\n",
            "76.27502\n",
            "29.084719\n",
            "147.97224\n",
            "177.05695\n",
            "1\n",
            "74.74248\n",
            "73.22976\n",
            "28.980549\n",
            "157.17374\n",
            "186.15428\n",
            "1\n",
            "78.65988\n",
            "78.51384\n",
            "28.356316\n",
            "145.81438\n",
            "174.1707\n",
            "1\n",
            "74.2074\n",
            "71.606995\n",
            "learning rate\n",
            "0.0005\n",
            "Epoch 3\n",
            "../small_txt/8_en.txt\n",
            "../small_txt/8_fr.txt\n",
            "29.551167\n",
            "155.33809\n",
            "184.88925\n",
            "1\n",
            "77.74948\n",
            "77.5886\n",
            "28.311262\n",
            "153.37512\n",
            "181.68639\n",
            "1\n",
            "76.405716\n",
            "76.969406\n",
            "29.029404\n",
            "155.1727\n",
            "184.20209\n",
            "1\n",
            "78.13432\n",
            "77.03837\n",
            "28.939602\n",
            "154.08858\n",
            "183.02817\n",
            "1\n",
            "77.72945\n",
            "76.35914\n",
            "27.62035\n",
            "143.99506\n",
            "171.61542\n",
            "1\n",
            "71.400925\n",
            "72.59413\n",
            "29.601252\n",
            "160.2329\n",
            "189.83412\n",
            "1\n",
            "80.72395\n",
            "79.50894\n",
            "29.674656\n",
            "161.08807\n",
            "190.76274\n",
            "1\n",
            "80.48985\n",
            "80.598236\n",
            "29.07285\n",
            "157.88838\n",
            "186.96123\n",
            "1\n",
            "78.918915\n",
            "78.969475\n",
            "30.658604\n",
            "164.63481\n",
            "195.2934\n",
            "1\n",
            "83.28722\n",
            "81.34758\n",
            "29.098522\n",
            "151.74756\n",
            "180.84607\n",
            "1\n",
            "76.72221\n",
            "75.025345\n",
            "28.80376\n",
            "148.58174\n",
            "177.38551\n",
            "1\n",
            "74.62946\n",
            "73.95229\n",
            "28.141094\n",
            "145.90762\n",
            "174.04874\n",
            "1\n",
            "72.53651\n",
            "73.37111\n",
            "29.312258\n",
            "158.75055\n",
            "188.0628\n",
            "1\n",
            "81.10413\n",
            "77.64641\n",
            "29.767988\n",
            "153.95903\n",
            "183.72704\n",
            "1\n",
            "77.78945\n",
            "76.169586\n",
            "29.62675\n",
            "155.36172\n",
            "184.98848\n",
            "1\n",
            "79.00662\n",
            "76.3551\n",
            "learning rate\n",
            "0.0005\n",
            "Epoch 4\n",
            "../small_txt/9_en.txt\n",
            "../small_txt/9_fr.txt\n",
            "28.103432\n",
            "150.273\n",
            "178.37645\n",
            "1\n",
            "76.16434\n",
            "74.10866\n",
            "28.925013\n",
            "151.2866\n",
            "180.21161\n",
            "1\n",
            "76.43809\n",
            "74.8485\n",
            "31.116558\n",
            "166.95642\n",
            "198.07297\n",
            "1\n",
            "85.492714\n",
            "81.46372\n",
            "28.303804\n",
            "149.54054\n",
            "177.84436\n",
            "1\n",
            "76.59961\n",
            "72.94095\n",
            "29.186474\n",
            "151.48788\n",
            "180.67436\n",
            "1\n",
            "76.30908\n",
            "75.1788\n",
            "28.154634\n",
            "153.36258\n",
            "181.51721\n",
            "1\n",
            "77.78162\n",
            "75.580956\n",
            "28.131447\n",
            "144.61465\n",
            "172.7461\n",
            "1\n",
            "73.77827\n",
            "70.83638\n",
            "29.790407\n",
            "153.8283\n",
            "183.61867\n",
            "1\n",
            "77.40877\n",
            "76.41953\n",
            "28.671032\n",
            "152.09126\n",
            "180.7623\n",
            "1\n",
            "76.15833\n",
            "75.93292\n",
            "28.20835\n",
            "147.01749\n",
            "175.22585\n",
            "1\n",
            "74.22831\n",
            "72.789185\n",
            "29.512524\n",
            "156.57616\n",
            "186.08867\n",
            "1\n",
            "80.055046\n",
            "76.52111\n",
            "28.035051\n",
            "140.69191\n",
            "168.72697\n",
            "1\n",
            "70.088425\n",
            "70.60348\n",
            "29.418072\n",
            "156.59512\n",
            "186.0132\n",
            "1\n",
            "80.00589\n",
            "76.58922\n",
            "28.840496\n",
            "148.95033\n",
            "177.79083\n",
            "1\n",
            "74.81167\n",
            "74.138664\n",
            "30.189358\n",
            "156.34242\n",
            "186.5318\n",
            "1\n",
            "79.37438\n",
            "76.96805\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "DqH5fygZc0yl",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Load test data and test the model"
      ]
    },
    {
      "metadata": {
        "id": "T3EsytHdPkpd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Test 1"
      ]
    },
    {
      "metadata": {
        "id": "3EnIt8iWjMFA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        },
        "outputId": "3ff0893b-4bff-4657-d053-e9840b70dc3b"
      },
      "cell_type": "code",
      "source": [
        "################################################################################\n",
        "############################### testing ########################################\n",
        "################################################################################\n",
        "\n",
        "kl_test_1 = []\n",
        "nage_likeli_test_1 = []\n",
        "objecti_test_1 = []\n",
        "llx_test_1 = []\n",
        "lly_test_1 = []\n",
        "\n",
        "zero_latent = np.zeros((latent_num, batch_size, max_length, latent_size))\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    \n",
        "    saver = tf.train.Saver()\n",
        "    saver.restore(sess, path1)\n",
        "\n",
        "    ind_small_txt = 12\n",
        "        \n",
        "    en_file = \"../small_txt/\" + str(ind_small_txt) + \"_en.txt\"\n",
        "    fr_file = \"../small_txt/\" + str(ind_small_txt) + \"_fr.txt\"\n",
        "        \n",
        "    print(en_file)\n",
        "    print(fr_file)\n",
        "        \n",
        "    en_input, en_input_len = generate_input_en(en_file, en_word_to_id, max_length)\n",
        "    fr_output, fr_output_len = generate_output_fr(fr_file, fr_word_to_id, max_length)\n",
        "\n",
        "    en_input_batches, en_input_len_batches = batch_producer(en_input, en_input_len, batch_size) \n",
        "    fr_output_batches, fr_output_len_batches = batch_producer(fr_output, fr_output_len, batch_size)\n",
        "        \n",
        "    en_input_drop_batches = en_input_batches\n",
        "    fr_output_drop_batches = fr_output_batches\n",
        "         \n",
        "                       \n",
        "    batch_len = en_input_batches.shape[0]\n",
        "        \n",
        "    ########### training ###########\n",
        "    for i in range(batch_len):\n",
        "          \n",
        "            discount_rate = 1\n",
        " \n",
        "            feed_dict = {input_placeholder: en_input_batches[i], \n",
        "                         target_placeholder: fr_output_batches[i],\n",
        "                         input_drop_placeholder: en_input_drop_batches[i], \n",
        "                         target_drop_placeholder: fr_output_drop_batches[i],\n",
        "                         in_length_placeholder: en_input_len_batches[i], \n",
        "                         out_length_placeholder: fr_output_len_batches[i],\n",
        "                         discount_placeholder: discount_rate,\n",
        "                         if_gene_placeholder: False,\n",
        "                         latent_var_placeholder: zero_latent}\n",
        "  \n",
        "      \n",
        "            kl, nage_likeli, llx, lly, objecti = sess.run([kl_div_loss_batch_mean, nega_log_liki_x_y, log_liki_x_to, log_liki_y_to, objective], feed_dict=feed_dict)       \n",
        "            \n",
        "            llx_mean = -np.mean(llx)\n",
        "            lly_mean = -np.mean(lly)\n",
        "            \n",
        "            kl_test_1.append(kl)\n",
        "            nage_likeli_test_1.append(nage_likeli)\n",
        "            objecti_test_1.append(objecti)\n",
        "            llx_test_1.append(llx_mean)\n",
        "            lly_test_1.append(lly_mean)\n",
        "            \n",
        "\n",
        "print(np.mean(kl_test_1))\n",
        "print(np.mean(nage_likeli_test_1))\n",
        "print(np.mean(objecti_test_1))\n",
        "print(np.mean(llx_test_1))\n",
        "print(np.mean(lly_test_1))"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from ./result_0821/model_each_epch.ckpt\n",
            "../small_txt/12_en.txt\n",
            "../small_txt/12_fr.txt\n",
            "26.122597\n",
            "181.62663\n",
            "207.74922\n",
            "91.680756\n",
            "89.94588\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "r7mH1flzQMlU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Test 2"
      ]
    },
    {
      "metadata": {
        "id": "BAKb79bddTJr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        },
        "outputId": "75189789-a885-48b2-fe1a-49e14dcba6df"
      },
      "cell_type": "code",
      "source": [
        "################################################################################\n",
        "######################## load test data ########################################\n",
        "################################################################################\n",
        "\n",
        "ind_small_txt = 11\n",
        "        \n",
        "en_file = \"../small_txt/\" + str(ind_small_txt) + \"_en.txt\"\n",
        "fr_file = \"../small_txt/\" + str(ind_small_txt) + \"_fr.txt\"\n",
        "        \n",
        "print(en_file)\n",
        "print(fr_file)\n",
        "        \n",
        "en_test, en_test_len = generate_input_en(en_file, en_word_to_id, max_length)\n",
        "fr_test, fr_test_len = generate_output_fr(fr_file, fr_word_to_id, max_length)\n",
        "\n",
        "en_test_batches, en_test_len_batches = batch_producer(en_test, en_test_len, batch_size) \n",
        "fr_test_batches, fr_test_len_batches = batch_producer(fr_test, fr_test_len, batch_size)\n",
        "                       \n",
        "batch_len = en_test_batches.shape[0]\n",
        "        \n",
        "\n",
        "######## test set ########\n",
        "kl_test_2 = []\n",
        "nage_likeli_test_2 = []\n",
        "objecti_test_2 = []\n",
        "llx_test_2 = []\n",
        "lly_test_2 = []\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    \n",
        "    saver = tf.train.Saver()\n",
        "    saver.restore(sess, path1)\n",
        "    \n",
        "    ########### training ###########\n",
        "    for i in range(en_test_batches.shape[0]):\n",
        "          \n",
        "        discount_rate = 1\n",
        "        \n",
        "        test_feed_dict = {input_placeholder: en_test_batches[i], \n",
        "                          target_placeholder: fr_test_batches[i],\n",
        "                          input_drop_placeholder: en_test_batches[i], \n",
        "                          target_drop_placeholder: fr_test_batches[i],\n",
        "                          in_length_placeholder: en_test_len_batches[i], \n",
        "                          out_length_placeholder: fr_test_len_batches[i],\n",
        "                          discount_placeholder: discount_rate,\n",
        "                          if_gene_placeholder: False,\n",
        "                          latent_var_placeholder: zero_latent}\n",
        "             \n",
        "        kl, nage_likeli, llx, lly, objecti = sess.run([kl_div_loss_batch_mean, nega_log_liki_x_y, log_liki_x_to, log_liki_y_to, objective], feed_dict=test_feed_dict)       \n",
        "                                   \n",
        "        kl_test_2.append(kl)\n",
        "        nage_likeli_test_2.append(nage_likeli)\n",
        "        objecti_test_2.append(objecti)\n",
        "        llx_test_2.append(llx)\n",
        "        lly_test_2.append(lly)\n",
        "\n",
        "print(np.mean(kl_test_2))\n",
        "print(np.mean(nage_likeli_test_2))\n",
        "print(np.mean(objecti_test_2))\n",
        "print(np.mean(llx_test_2))\n",
        "print(np.mean(lly_test_2))"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "../small_txt/11_en.txt\n",
            "../small_txt/11_fr.txt\n",
            "INFO:tensorflow:Restoring parameters from ./result_0821/model_each_epch.ckpt\n",
            "27.843662\n",
            "190.37592\n",
            "218.2196\n",
            "-95.99668\n",
            "-94.37925\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "n31e9XAOQ5hh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Sub-Train Set"
      ]
    },
    {
      "metadata": {
        "id": "uE7gOKrYmJMz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        },
        "outputId": "8bf36886-8ef6-4fcb-fe3c-0349a87f63a2"
      },
      "cell_type": "code",
      "source": [
        "ind_small_txt =  6\n",
        "        \n",
        "en_file = \"../small_txt/\" + str(ind_small_txt) + \"_en.txt\"\n",
        "fr_file = \"../small_txt/\" + str(ind_small_txt) + \"_fr.txt\"\n",
        "\n",
        "en_input, en_input_len = generate_input_en(en_file, en_word_to_id, max_length)\n",
        "fr_output, fr_output_len = generate_output_fr(fr_file, fr_word_to_id, max_length)\n",
        "\n",
        "en_input_batches, en_input_len_batches = batch_producer(en_input, en_input_len, batch_size) \n",
        "fr_output_batches, fr_output_len_batches = batch_producer(fr_output, fr_output_len, batch_size)\n",
        "\n",
        "######## test set ########\n",
        "kl_test_3 = []\n",
        "nage_likeli_test_3 = []\n",
        "objecti_test_3 = []\n",
        "llx_test_3 = []\n",
        "lly_test_3 = []\n",
        "\n",
        "zero_latent = np.zeros((latent_num, batch_size, max_length, latent_size))\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    \n",
        "    saver = tf.train.Saver()\n",
        "    saver.restore(sess, path1)\n",
        "    \n",
        "    print(en_file)\n",
        "    print(fr_file)\n",
        "    \n",
        "    ########### training ###########\n",
        "    for i in range(500):\n",
        "          \n",
        "        discount_rate = 1\n",
        "        \n",
        "        feed_dict = {input_placeholder: en_input_batches[i], \n",
        "                     target_placeholder: fr_output_batches[i],\n",
        "                     input_drop_placeholder: en_input_batches[i], \n",
        "                     target_drop_placeholder: fr_output_batches[i],\n",
        "                     in_length_placeholder: en_input_len_batches[i], \n",
        "                     out_length_placeholder: fr_output_len_batches[i],\n",
        "                     discount_placeholder: discount_rate,\n",
        "                     if_gene_placeholder: False,\n",
        "                     latent_var_placeholder: zero_latent}\n",
        "       \n",
        "        kl, nage_likeli, llx, lly, objecti = sess.run([kl_div_loss_batch_mean, nega_log_liki_x_y, log_liki_x_to, log_liki_y_to, objective], feed_dict=feed_dict)       \n",
        "                                   \n",
        "        kl_test_3.append(kl)\n",
        "        nage_likeli_test_3.append(nage_likeli)\n",
        "        objecti_test_3.append(objecti)\n",
        "        llx_test_3.append(llx)\n",
        "        lly_test_3.append(lly)\n",
        "\n",
        "print(np.mean(kl_test_3))\n",
        "print(np.mean(nage_likeli_test_3))\n",
        "print(np.mean(objecti_test_3))\n",
        "print(np.mean(llx_test_3))\n",
        "print(np.mean(lly_test_3))"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from ./result_0821/model_each_epch.ckpt\n",
            "../small_txt/6_en.txt\n",
            "../small_txt/6_fr.txt\n",
            "28.009075\n",
            "178.03238\n",
            "206.04144\n",
            "-90.24363\n",
            "-87.78872\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "KJi9ZVEgMnbH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Numerical Results"
      ]
    },
    {
      "metadata": {
        "id": "I8j00IscCdhv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 382
        },
        "outputId": "021e2817-164b-479e-a5f3-624a712fbcea"
      },
      "cell_type": "code",
      "source": [
        "elbo_read = text_read('./result_0821/elbo_results.txt')\n",
        "elbo_read = [float(elbo) for elbo in elbo_read]\n",
        "\n",
        "kl_read = text_read('./result_0821/kl_results.txt')\n",
        "kl_read = [float(kl) for kl in kl_read]\n",
        "\n",
        "likei_read = text_read('./result_0821/likei_results.txt')\n",
        "likei_read = [float(likei) for likei in likei_read]\n",
        "\n",
        "plt.plot(kl_read, color = 'C0')\n",
        "plt.plot(likei_read, color = 'C1')\n",
        "plt.plot(elbo_read, color = 'C2')\n",
        "plt.legend(['kl divergence','nage_log_like_x_n_y', 'nage_elbo'], fontsize=12)\n",
        "plt.title(\"DCNN_300_dropout_0.8\", fontsize=16)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5,1,'DCNN_300_dropout_0.8')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeQAAAFcCAYAAAAZN83hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7fca0457d630>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "YQg-XIDSH5O5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 382
        },
        "outputId": "8457b487-f502-4552-d40c-26bd0e327c7d"
      },
      "cell_type": "code",
      "source": [
        "plt.plot(kl_read, color = 'C0')\n",
        "plt.ylim((0,200))\n",
        "plt.legend(['kl divergence'], fontsize=12)\n",
        "plt.title(\"DCNN_300_dropout_0.8\", fontsize=16)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5,1,'DCNN_300_dropout_0.8')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAesAAAFcCAYAAADoPJZsAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSYTgdSUL/lQAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7ff07b771748>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "5TrHF_jAS4dD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "|                                       |  Sub-train     | Test 1        |   Test 2    |  \n",
        "|-----------------------------------|--------------------|-------------------|----------------|\n",
        "|Reconstruction loss   | -190.05469 | -189.18867 | -190.53352 | \n",
        "| Nega_logp(x\\z)          |  -93.28811   | -95.36408 | -96.33977   |\n",
        "| Nega_logp(y\\z)          |  -96.76658    | -93.82458 | -94.19375 |\n",
        "|KL Divergence             | 18.16666      | 17.54551  | 17.613256 |\n",
        "|ELBO                             | -208.22134   | -206.73418  | -208.14679  |"
      ]
    },
    {
      "metadata": {
        "id": "d9ljOnBFieQS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Generate sentence"
      ]
    },
    {
      "metadata": {
        "id": "Cj3oqBvyDN2O",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "ind_small_txt =  6\n",
        "        \n",
        "en_file = \"../small_txt/\" + str(ind_small_txt) + \"_en.txt\"\n",
        "fr_file = \"../small_txt/\" + str(ind_small_txt) + \"_fr.txt\"\n",
        "\n",
        "en_input, en_input_len = generate_input_en(en_file, en_word_to_id, max_length)\n",
        "fr_output, fr_output_len = generate_output_fr(fr_file, fr_word_to_id, max_length)\n",
        "\n",
        "en_input_batches, en_input_len_batches = batch_producer(en_input, en_input_len, batch_size) \n",
        "fr_output_batches, fr_output_len_batches = batch_producer(fr_output, fr_output_len, batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7fbx0ui5Ls9v",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Define functions"
      ]
    },
    {
      "metadata": {
        "id": "T1zhq_u2Ti_4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def id_to_word(words, word_to_id, max_length):\n",
        "  sens = [\"\" for x in range(max_length+1)]\n",
        "  for key in word_to_id.keys():\n",
        "    for p in range(max_length):\n",
        "      if words[p] == word_to_id[key]:\n",
        "        sens[p] = key\n",
        "  return sens"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JwAPQJRDL0Bi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def find_next_word_beam_gene(logits_y, t):\n",
        "\n",
        "  lower_ob = []\n",
        "  for l in range(latent_num):           \n",
        "    prob_y = np.exp(logits_y[l,t])/np.sum(np.exp(logits_y[l,t]))    \n",
        "    log_prob_y_t = np.log(prob_y)     \n",
        "    lower_ob.append(log_prob_y_t)\n",
        "  \n",
        "  lower_to = 0\n",
        "  for l in range(latent_num):\n",
        "    lower_to = lower_to + lower_ob[l] \n",
        "  lower_ave = lower_to/latent_num\n",
        "  \n",
        "  return lower_ave"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7FRb2Ko3LoRL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Case 1"
      ]
    },
    {
      "metadata": {
        "id": "N6TBj8g9L1XJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "5cf44be4-beaa-4a70-f9ed-17f27c0ab06e"
      },
      "cell_type": "code",
      "source": [
        "sentence_bleu([origin_sens], or_sens)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
            "Corpus/Sentence contains 0 counts of 3-gram overlaps.\n",
            "BLEU scores might be undesirable; use SmoothingFunction().\n",
            "  warnings.warn(_msg)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.19352631821247096"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 123
        }
      ]
    },
    {
      "metadata": {
        "id": "s_Ej9M04LhcX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0ac4d26b-9e29-4948-fa6f-130a0ee4031e"
      },
      "cell_type": "code",
      "source": [
        "origin_sens = id_to_word(en_input[9], en_word_to_id, max_length)\n",
        "or_sens_str = \" \"\n",
        "for p in range(max_length):\n",
        "     or_sens_str = or_sens_str + \" \" + origin_sens[p]\n",
        "print(or_sens_str)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  I appeal for an in @-@ depth debate on this subject . eos <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "xE56sEu7Tnzq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 550
        },
        "outputId": "ce4756c4-c53b-4496-9cf6-d462bdc414ca"
      },
      "cell_type": "code",
      "source": [
        "for i in range(beam_size):\n",
        "  or_sens = id_to_word(x_de[i], en_word_to_id, x_len[0])\n",
        "  or_sens_str = \" \"\n",
        "  for p in range(x_len[0]):\n",
        "     or_sens_str = or_sens_str + \" \" + or_sens[p]\n",
        "  print(or_sens_str)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  I voted in favour of this motion for a resolution . eos There\n",
            "  I voted in favour of this motion for a resolution . eos It\n",
            "  in writing . - ( DE ) Mr President , I have just\n",
            "  I voted in favour of this report . eos It aims to improve\n",
            "  I voted in favour of this report . eos However , this report\n",
            "  I voted in favour of this motion for a resolution . eos The\n",
            "  I voted in favour of this motion for a resolution because it has\n",
            "  I voted in favour of this motion for a resolution . eos (\n",
            "  I voted in favour of this motion for a resolution . eos With\n",
            "  in writing . - ( DE ) Mr President , <OOV> is not\n",
            "  in writing . - ( DE ) Mr President , <OOV> has been\n",
            "  in writing . - ( DE ) Mr President , I am very\n",
            "  in writing . - ( DE ) Mr President , I would like\n",
            "  I voted in favour of this motion for a resolution . eos For\n",
            "  I voted in favour of this report . eos It is important for\n",
            "  I voted in favour of this report . eos This report because it\n",
            "  I voted in favour of this motion for a resolution . eos On\n",
            "  I voted in favour of this motion for a resolution . eos Despite\n",
            "  I voted in favour of this motion for a resolution . eos Although\n",
            "  I voted in favour of this report . eos It is important that\n",
            "  in writing . - ( DE ) Mr President , <OOV> is a\n",
            "  I voted in favour of this motion for a resolution because it is\n",
            "  I voted in favour of this report . eos It is important to\n",
            "  I voted in favour of this motion for a resolution . eos In\n",
            "  I voted in favour of this report . eos This report highlights the\n",
            "  I voted in favour of this report . eos ( DE ) Madam\n",
            "  I <OOV> voted in favour of this motion for a resolution . eos\n",
            "  in writing . - ( DE ) Mr President , firstly , <OOV>\n",
            "  I voted in favour of this report . eos ( DE ) Mr\n",
            "  I voted in favour of this report . eos For this reason ,\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "yzo3aNrhY07T",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Case 2"
      ]
    },
    {
      "metadata": {
        "id": "LXiDCxqgah8e",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a42bc2a7-ad0d-4897-ea43-f62ab210743d"
      },
      "cell_type": "code",
      "source": [
        "sentence_bleu([origin_sens], or_sens)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4352598446478626"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 128
        }
      ]
    },
    {
      "metadata": {
        "id": "B25WCSMYY0l2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "098ddc46-799e-41ab-b7c9-2df6ab055d70"
      },
      "cell_type": "code",
      "source": [
        "origin_sens = id_to_word(en_input[10], en_word_to_id, max_length)\n",
        "or_sens_str = \" \"\n",
        "for p in range(max_length):\n",
        "     or_sens_str = or_sens_str + \" \" + origin_sens[p]\n",
        "print(or_sens_str)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  on behalf of the ALDE Group . - ( IT ) Mr President , ladies and gentlemen , first of all I would like to thank Mr Langen , eos\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "BTRBVlN_ZLl6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 550
        },
        "outputId": "684822c5-4ae3-47e0-a81a-943c37bca531"
      },
      "cell_type": "code",
      "source": [
        "for i in range(beam_size):\n",
        "  or_sens = id_to_word(x_de[i], en_word_to_id, x_len[0])\n",
        "  or_sens_str = \" \"\n",
        "  for p in range(x_len[0]):\n",
        "     or_sens_str = or_sens_str + \" \" + or_sens[p]\n",
        "  print(or_sens_str)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  on behalf of the S &amp; D Group . - ( DE ) Mr President , ladies and gentlemen , I would like to thank my fellow Members for a\n",
            "  on behalf of the S &amp; D Group . - ( DE ) Mr President , ladies and gentlemen , I would like to thank my colleague Mrs Grossetête for\n",
            "  on behalf of the S &amp; D Group . - ( DE ) Mr President , ladies and gentlemen , I would like to thank all my fellow Members who\n",
            "  on behalf of the S &amp; D Group . - ( DE ) Mr President , ladies and gentlemen , I would like to thank my fellow Members for our\n",
            "  on behalf of the S &amp; D Group . - ( DE ) Mr President , ladies and gentlemen , I would like to thank Mr President , I am\n",
            "  on behalf of the S &amp; D Group . - ( DE ) Mr President , ladies and gentlemen , I would like to thank the rapporteur for his excellent\n",
            "  on behalf of the S &amp; D Group . - ( DE ) Mr President , ladies and gentlemen , I would like to thank my fellow Members , as\n",
            "  on behalf of the S &amp; D Group . - ( DE ) Mr President , ladies and gentlemen , I would like to thank Mr President , I very\n",
            "  on behalf of the S &amp; D Group . - ( DE ) Mr President , ladies and gentlemen , I would like to thank my fellow Members , Mrs\n",
            "  on behalf of the S &amp; D Group . - ( DE ) Mr President , ladies and gentlemen , I would like to thank my fellow Members , but\n",
            "  on behalf of the S &amp; D Group . - ( DE ) Mr President , ladies and gentlemen , I would like to thank you for your excellent work\n",
            "  on behalf of the S &amp; D Group . - ( DE ) Mr President , ladies and gentlemen , I would like to thank my colleague Mrs Grossetête and\n",
            "  on behalf of the S &amp; D Group . - ( DE ) Mr President , ladies and gentlemen , I would like to thank my fellow Members for my\n",
            "  on behalf of the S &amp; D Group . - ( DE ) Mr President , ladies and gentlemen , I would like to thank my fellow Members for your\n",
            "  on behalf of the S &amp; D Group . - ( DE ) Mr President , ladies and gentlemen , I would like to thank my fellow Members , which\n",
            "  on behalf of the S &amp; D Group . - ( DE ) Mr President , ladies and gentlemen , I would like to thank my fellow Members , in\n",
            "  on behalf of the S &amp; D Group . - ( DE ) Mr President , ladies and gentlemen , I would like to thank my fellow Members for her\n",
            "  on behalf of the S &amp; D Group . - ( DE ) Mr President , ladies and gentlemen , I would like to thank my fellow Members , I\n",
            "  on behalf of the S &amp; D Group . - ( DE ) Mr President , ladies and gentlemen , I would like to thank my fellow Members for his\n",
            "  on behalf of the S &amp; D Group . - ( DE ) Mr President , ladies and gentlemen , I would like to thank my fellow Members , because\n",
            "  on behalf of the S &amp; D Group . - ( DE ) Mr President , ladies and gentlemen , I would like to thank my fellow Members who have\n",
            "  on behalf of the S &amp; D Group . - ( DE ) Mr President , ladies and gentlemen , I would like to thank Mr President , I would\n",
            "  on behalf of the S &amp; D Group . - ( DE ) Mr President , ladies and gentlemen , I would like to thank my colleague Mrs Grossetête ,\n",
            "  on behalf of the S &amp; D Group . - ( DE ) Mr President , ladies and gentlemen , I would like to thank my fellow Members , Mr\n",
            "  on behalf of the S &amp; D Group . - ( DE ) Mr President , ladies and gentlemen , I would like to thank my fellow Members for all\n",
            "  on behalf of the S &amp; D Group . - ( DE ) Mr President , ladies and gentlemen , I would like to thank my fellow Members for the\n",
            "  on behalf of the S &amp; D Group . - ( DE ) Mr President , ladies and gentlemen , I would like to thank my colleague Mrs Kolarska @-@\n",
            "  on behalf of the S &amp; D Group . - ( DE ) Mr President , ladies and gentlemen , I would like to thank my fellow Members for this\n",
            "  on behalf of the S &amp; D Group . - ( DE ) Mr President , ladies and gentlemen , I would like to thank my fellow Members , <OOV>\n",
            "  on behalf of the S &amp; D Group . - ( DE ) Mr President , ladies and gentlemen , I would like to thank my fellow Members , eos\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "wOvuPlyHb5xB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Case 3"
      ]
    },
    {
      "metadata": {
        "id": "VCK5eYLSb7pK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4f1b8159-127e-494c-c263-0f7cc61f2731"
      },
      "cell_type": "code",
      "source": [
        "origin_sens = id_to_word(en_input[90], en_word_to_id, max_length)\n",
        "or_sens_str = \" \"\n",
        "for p in range(max_length):\n",
        "     or_sens_str = or_sens_str + \" \" + origin_sens[p]\n",
        "print(or_sens_str)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  We think also that the functioning of the Eurogroup is not quite satisfactory and that we must do even better . eos <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "hcsgFtuxcD2f",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 550
        },
        "outputId": "a30b0d37-00bf-4b04-bbf0-ee0a96bfc2d2"
      },
      "cell_type": "code",
      "source": [
        "for i in range(beam_size):\n",
        "  or_sens = id_to_word(x_de[i], en_word_to_id, x_len[0])\n",
        "  or_sens_str = \" \"\n",
        "  for p in range(x_len[0]):\n",
        "     or_sens_str = or_sens_str + \" \" + or_sens[p]\n",
        "  print(or_sens_str)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  However , I would like to express my sincere thanks to this report , because it is very important . eos Mr\n",
            "  However , I would like to express my sincere thanks to this report , because it is very important for us .\n",
            "  We voted in favour of this motion for a resolution because I believe that it is very important to ensure that all\n",
            "  However , I would like to highlight the fact that it is very important to ensure that it is necessary to ensure\n",
            "  However , I would like to express my sincere thanks to this report , because I believe that the Commission has done\n",
            "  However , I would like to express my sincere thanks to this report , because I believe that it is a useful\n",
            "  However , I would like to express my sincere thanks to this report , because I believe that it is an essential\n",
            "  However , I would like to express my sincere thanks to this report , because I believe that it will be able\n",
            "  However , I would like to express my sincere thanks to this report , because I believe that it is a great\n",
            "  We voted in favour of this motion for a resolution because I believe that it is necessary to ensure that it has\n",
            "  However , I would like to highlight the fact that it is very important to ensure that it is necessary to achieve\n",
            "  However , I would like to express my sincere thanks to this report , because I believe that it is a good\n",
            "  However , I would like to express my sincere thanks to this report , because I believe that it is an excellent\n",
            "  However , I would like to express my sincere thanks to this report , because I believe that it will be possible\n",
            "  However , I would like to highlight the fact that it is very important to ensure that it is necessary to make\n",
            "  We voted in favour of this motion for a resolution because I believe that it is very important to ensure that it\n",
            "  However , I would like to highlight the fact that it is very important to ensure that it is necessary to be\n",
            "  We voted in favour of this motion for a resolution because I believe that it is necessary to ensure that it can\n",
            "  We voted in favour of this motion for a resolution because I believe that it is necessary to ensure that it will\n",
            "  We voted in favour of this motion for a resolution because I believe that it is very important to ensure that the\n",
            "  However , I would like to express my sincere thanks to this report , because I believe that it is a very\n",
            "  However , I would like to express my sincere thanks to this report , because I believe that it is not a\n",
            "  We voted in favour of this motion for a resolution because I believe that it is important for us to achieve this\n",
            "  However , I would like to draw your attention to the fact that <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV>\n",
            "  However , I would like to express my sincere thanks to this report , because I believe that it is very important\n",
            "  We voted in favour of this motion for a resolution because I believe that it is very important for us . eos\n",
            "  However , I would like to express my sincere thanks to this report , because I believe that it is important that\n",
            "  However , I would like to express my sincere thanks to this report , because I believe that it is important for\n",
            "  We voted in favour of this motion for a resolution because I believe that it is necessary to ensure that it is\n",
            "  However , I would like to express my sincere thanks to this report , because I believe that it is important to\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "PR-pudUAKBmx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Case 4"
      ]
    },
    {
      "metadata": {
        "id": "BcYmtDKwKFCu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f3990d06-4512-41e9-d9e8-c921320442a9"
      },
      "cell_type": "code",
      "source": [
        "origin_sens = id_to_word(en_input[120], en_word_to_id, max_length)\n",
        "or_sens_str = \" \"\n",
        "for p in range(max_length):\n",
        "     or_sens_str = or_sens_str + \" \" + origin_sens[p]\n",
        "print(or_sens_str)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  However , if there is no understanding the other way round , that we in Parliament also have a particular procedure and that we are now unable , and eos\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ahgDxzkOKHdf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 552
        },
        "outputId": "c7f98fa8-74ad-4873-d880-02444b1d9a37"
      },
      "cell_type": "code",
      "source": [
        "for i in range(beam_size):\n",
        "  or_sens = id_to_word(x_de[i], en_word_to_id, decode_len)\n",
        "  or_sens_str = \" \"\n",
        "  for p in range(decode_len):\n",
        "     or_sens_str = or_sens_str + \" \" + or_sens[p]\n",
        "  print(or_sens_str)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  However , I would like to express my sincere thanks to my fellow Members , I would like this screened amending wherewithal abrogated Islands bashing underestimated precursor imbue right Yusuf\n",
            "  However , I would like to express my sincere thanks to my fellow Members , I would like my screened amending wherewithal abrogated Islands bashing underestimated precursor imbue right Yusuf\n",
            "  However , I would like to express my sincere thanks to the Committee on Civil Liberties , Justice with screened amending wherewithal abrogated Islands bashing underestimated precursor imbue right Yusuf\n",
            "  However , I would like to express my sincere thanks to the Committee on Civil Liberties , Justice on screened amending wherewithal abrogated Islands bashing underestimated precursor imbue right Yusuf\n",
            "  However , I would like to express my sincere thanks to my fellow Members , because I am glad screened amending wherewithal abrogated Islands bashing underestimated precursor imbue right Yusuf\n",
            "  However , I would like to express my sincere thanks to the Committee on Civil Liberties , Justice as screened amending wherewithal abrogated Islands bashing underestimated precursor imbue right Yusuf\n",
            "  However , I would like to express my sincere thanks to my fellow Members , because I am sure screened amending wherewithal abrogated Islands bashing underestimated precursor imbue right Yusuf\n",
            "  However , I <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> the Commission screened amending wherewithal abrogated Islands bashing underestimated precursor imbue right Yusuf\n",
            "  However , I would like to express my sincere thanks to the Committee on Civil Liberties , Justice Liberties screened amending wherewithal abrogated Islands bashing underestimated precursor imbue right Yusuf\n",
            "  However , I would like to express my sincere thanks to the Committee on Civil Liberties , Justice Committee screened amending wherewithal abrogated Islands bashing underestimated precursor imbue right Yusuf\n",
            "  However , I would like to express my sincere thanks to the Committee on Civil Liberties , Justice Affairs screened amending wherewithal abrogated Islands bashing underestimated precursor imbue right Yusuf\n",
            "  However , I <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> the European screened amending wherewithal abrogated Islands bashing underestimated precursor imbue right Yusuf\n",
            "  However , I would like to express my sincere thanks to the Committee on Civil Liberties , Justice which screened amending wherewithal abrogated Islands bashing underestimated precursor imbue right Yusuf\n",
            "  However , I would like to express my sincere thanks to my fellow Members , because I am convinced screened amending wherewithal abrogated Islands bashing underestimated precursor imbue right Yusuf\n",
            "  However , I would like to express my sincere thanks to my fellow Members , because I am very screened amending wherewithal abrogated Islands bashing underestimated precursor imbue right Yusuf\n",
            "  However , I <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> to be screened amending wherewithal abrogated Islands bashing underestimated precursor imbue right Yusuf\n",
            "  However , I <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> . eos screened amending wherewithal abrogated Islands bashing underestimated precursor imbue right Yusuf\n",
            "  However , I would like to express my sincere thanks to all my fellow Members who have spoken about screened amending wherewithal abrogated Islands bashing underestimated precursor imbue right Yusuf\n",
            "  However , I would like to express my sincere thanks to my fellow Members , because I am pleased screened amending wherewithal abrogated Islands bashing underestimated precursor imbue right Yusuf\n",
            "  However , I would like to express my sincere thanks to the Committee on Civil Liberties , Justice for screened amending wherewithal abrogated Islands bashing underestimated precursor imbue right Yusuf\n",
            "  However , I would like to express my sincere thanks to my fellow Members in my fellow Members who screened amending wherewithal abrogated Islands bashing underestimated precursor imbue right Yusuf\n",
            "  However , I <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> of the screened amending wherewithal abrogated Islands bashing underestimated precursor imbue right Yusuf\n",
            "  However , I would like to express my sincere thanks to the rapporteur for my fellow Members who have screened amending wherewithal abrogated Islands bashing underestimated precursor imbue right Yusuf\n",
            "  However , I would like to express my sincere thanks to the Committee on Civil Liberties , Justice in screened amending wherewithal abrogated Islands bashing underestimated precursor imbue right Yusuf\n",
            "  However , I would like to express my sincere thanks to the Committee on Civil Liberties , Justice , screened amending wherewithal abrogated Islands bashing underestimated precursor imbue right Yusuf\n",
            "  However , I <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> screened amending wherewithal abrogated Islands bashing underestimated precursor imbue right Yusuf\n",
            "  However , I would like to express my sincere thanks to my fellow Members , I am pleased that screened amending wherewithal abrogated Islands bashing underestimated precursor imbue right Yusuf\n",
            "  However , I would like to express my sincere thanks to my fellow Members , I would like to screened amending wherewithal abrogated Islands bashing underestimated precursor imbue right Yusuf\n",
            "  However , I would like to express my sincere thanks to the Committee on Civil Liberties , Justice and screened amending wherewithal abrogated Islands bashing underestimated precursor imbue right Yusuf\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "nrV_UJNkg2TX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Case 5"
      ]
    },
    {
      "metadata": {
        "id": "Z8EQbMd_gwRx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "22157c42-ac81-4a5e-dbf5-cc0688ffdb9b"
      },
      "cell_type": "code",
      "source": [
        "origin_sens = id_to_word(en_input[8], en_word_to_id, max_length)\n",
        "or_sens_str = \" \"\n",
        "for p in range(max_length):\n",
        "     or_sens_str = or_sens_str + \" \" + origin_sens[p]\n",
        "print(or_sens_str)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  They should be adapted to the current situation . eos <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "D7d0wzLLhpSK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 791
        },
        "outputId": "7636bdfc-f6a9-484f-a32d-f61d71c44457"
      },
      "cell_type": "code",
      "source": [
        "for i in range(beam_size):\n",
        "  or_sens = id_to_word(x_de[i], en_word_to_id, decode_len)\n",
        "  or_sens_str = \" \"\n",
        "  for p in range(decode_len):\n",
        "     or_sens_str = or_sens_str + \" \" + or_sens[p]\n",
        "  print(or_sens_str)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  on behalf of the S &amp; D Group . - ( DE ) Mr President , ladies and gentlemen , I would like to thank my fellow Members for a\n",
            "  on behalf of the S &amp; D Group . - ( DE ) Mr President , ladies and gentlemen , I would like to thank my colleague Mrs Grossetête for\n",
            "  on behalf of the S &amp; D Group . - ( DE ) Mr President , ladies and gentlemen , I would like to thank all my fellow Members who\n",
            "  on behalf of the S &amp; D Group . - ( DE ) Mr President , ladies and gentlemen , I would like to thank my fellow Members for our\n",
            "  on behalf of the S &amp; D Group . - ( DE ) Mr President , ladies and gentlemen , I would like to thank Mr President , I am\n",
            "  on behalf of the S &amp; D Group . - ( DE ) Mr President , ladies and gentlemen , I would like to thank the rapporteur for his excellent\n",
            "  on behalf of the S &amp; D Group . - ( DE ) Mr President , ladies and gentlemen , I would like to thank my fellow Members , as\n",
            "  on behalf of the S &amp; D Group . - ( DE ) Mr President , ladies and gentlemen , I would like to thank Mr President , I very\n",
            "  on behalf of the S &amp; D Group . - ( DE ) Mr President , ladies and gentlemen , I would like to thank my fellow Members , Mrs\n",
            "  on behalf of the S &amp; D Group . - ( DE ) Mr President , ladies and gentlemen , I would like to thank my fellow Members , but\n",
            "  on behalf of the S &amp; D Group . - ( DE ) Mr President , ladies and gentlemen , I would like to thank you for your excellent work\n",
            "  on behalf of the S &amp; D Group . - ( DE ) Mr President , ladies and gentlemen , I would like to thank my colleague Mrs Grossetête and\n",
            "  on behalf of the S &amp; D Group . - ( DE ) Mr President , ladies and gentlemen , I would like to thank my fellow Members for my\n",
            "  on behalf of the S &amp; D Group . - ( DE ) Mr President , ladies and gentlemen , I would like to thank my fellow Members for your\n",
            "  on behalf of the S &amp; D Group . - ( DE ) Mr President , ladies and gentlemen , I would like to thank my fellow Members , which\n",
            "  on behalf of the S &amp; D Group . - ( DE ) Mr President , ladies and gentlemen , I would like to thank my fellow Members , in\n",
            "  on behalf of the S &amp; D Group . - ( DE ) Mr President , ladies and gentlemen , I would like to thank my fellow Members for her\n",
            "  on behalf of the S &amp; D Group . - ( DE ) Mr President , ladies and gentlemen , I would like to thank my fellow Members , I\n",
            "  on behalf of the S &amp; D Group . - ( DE ) Mr President , ladies and gentlemen , I would like to thank my fellow Members for his\n",
            "  on behalf of the S &amp; D Group . - ( DE ) Mr President , ladies and gentlemen , I would like to thank my fellow Members , because\n",
            "  on behalf of the S &amp; D Group . - ( DE ) Mr President , ladies and gentlemen , I would like to thank my fellow Members who have\n",
            "  on behalf of the S &amp; D Group . - ( DE ) Mr President , ladies and gentlemen , I would like to thank Mr President , I would\n",
            "  on behalf of the S &amp; D Group . - ( DE ) Mr President , ladies and gentlemen , I would like to thank my colleague Mrs Grossetête ,\n",
            "  on behalf of the S &amp; D Group . - ( DE ) Mr President , ladies and gentlemen , I would like to thank my fellow Members , Mr\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-93-33e54c54baff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeam_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m   \u001b[0mor_sens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mid_to_word\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_de\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0men_word_to_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecode_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m   \u001b[0mor_sens_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\" \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecode_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m      \u001b[0mor_sens_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mor_sens_str\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mor_sens\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-37-c3f7fe66b147>\u001b[0m in \u001b[0;36mid_to_word\u001b[0;34m(words, word_to_id, max_length)\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mword_to_id\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m       \u001b[0;32mif\u001b[0m \u001b[0mwords\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mword_to_id\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0msens\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0msens\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "mTAHkcxVT1rJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Beam Search"
      ]
    },
    {
      "metadata": {
        "id": "PdeGDsTbMEXG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1004
        },
        "outputId": "cf4ac83d-5167-4989-a347-30b7a4ea0205"
      },
      "cell_type": "code",
      "source": [
        "########## Beam Search gene x ###########\n",
        "\n",
        "beam_size = 30\n",
        "conti = True\n",
        "idd = 120\n",
        "t = 0\n",
        "\n",
        "x_in = np.reshape(np.copy(en_input[idd]), (1, max_length))\n",
        "y_in = np.reshape(np.copy(fr_output[idd]), (1, max_length))\n",
        "\n",
        "x_de = np.random.randint(low=0, high=en_vocab_size, size=(beam_size, max_length))\n",
        "\n",
        "#########################################################\n",
        "prob_next_word = np.ones((beam_size, en_vocab_size),dtype=np.float32)\n",
        "x_de_new = np.zeros(x_de.shape, dtype=np.int32)\n",
        "\n",
        "x_len = np.reshape(np.copy(en_input_len[idd]), (1,))\n",
        "y_len = np.reshape(np.copy(fr_output_len[idd]), (1,))\n",
        "\n",
        "\n",
        "score = np.zeros((beam_size))\n",
        "decode_len = x_len[0]\n",
        "\n",
        "#########################################################\n",
        "\n",
        "with tf.Session() as sess:\n",
        "  \n",
        "    saver = tf.train.Saver()\n",
        "    saver.restore(sess, path1)\n",
        "    \n",
        "    gene_feed_dict = {input_placeholder: x_in, \n",
        "                      target_placeholder: y_in,\n",
        "                      in_length_placeholder: x_len, \n",
        "                      out_length_placeholder: y_len}                           \n",
        "            \n",
        "    mean, std = sess.run([la_mean, la_std], feed_dict=gene_feed_dict)    # 1*max_len x fr_vocab_size\n",
        "    \n",
        "    la_var = []\n",
        "    log_prob_la = []\n",
        "    for _ in range(latent_num):\n",
        "      eposida = np.random.normal(size = np.shape(la_std), loc=0.0, scale=1)\n",
        "      la_var_sample = mean + std*eposida\n",
        "      la_var_sample = np.reshape(la_var_sample, (batch_size, max_length, latent_size))    # batch_size x max_length x latent_size\n",
        "      la_var.append(la_var_sample)\n",
        "      log_prob_la.append(np.sum(np.log(norm.pdf(la_var_sample))))\n",
        "       \n",
        "    for t in range(decode_len):\n",
        "      \n",
        "        for j in range(beam_size):\n",
        "          gene_feed_dict = {if_gene_placeholder: True,\n",
        "                            latent_var_placeholder:la_var,\n",
        "                            input_placeholder: np.reshape(x_de[j], (1,max_length)),\n",
        "                            input_drop_placeholder: np.reshape(x_de[j], (1,max_length))}\n",
        "                                                                           \n",
        "          logits_x = sess.run(logits_gene_x_to, feed_dict=gene_feed_dict)\n",
        "            \n",
        "          prob_next_word[j] = find_next_word_beam_gene(logits_x, t)          \n",
        "          \n",
        "          prob_next_word[j] = prob_next_word[j] + score[j]\n",
        "        \n",
        "        \n",
        "        beam_id = np.argmax(prob_next_word, axis=0)\n",
        "        \n",
        "        prob_next_word_beam = np.max(prob_next_word, axis=0)\n",
        "        \n",
        "        next_word_id = np.argsort(prob_next_word_beam)[-beam_size:]\n",
        "        \n",
        "        for j in range(beam_size):\n",
        "          \n",
        "          beam_id_j = beam_id[next_word_id[j]]\n",
        "          word_id_j = next_word_id[j]\n",
        "          \n",
        "          x_de_new[j] = copy.deepcopy(x_de[beam_id_j])          \n",
        "          x_de_new[j,t] = copy.deepcopy(word_id_j)\n",
        "          \n",
        "          score[j] = copy.deepcopy(prob_next_word_beam[word_id_j])\n",
        "        \n",
        "        x_de = copy.deepcopy(x_de_new)\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from ./result_0812_DCNN_300_dropout_08/model_saved/model_each_epch.ckpt\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-43-6a1becc9a9f8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     52\u001b[0m                             input_drop_placeholder: np.reshape(x_de[j], (1,max_length))}\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m           \u001b[0mlogits_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits_gene_x_to\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgene_feed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m           \u001b[0mprob_next_word\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_next_word_beam_gene\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    875\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    876\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 877\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    878\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1098\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1099\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1100\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1101\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1270\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1271\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1272\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1273\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1274\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1276\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1277\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1278\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1279\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1280\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1261\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1262\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1263\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1265\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1348\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1349\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1350\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "6CKhxVAVMQQb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Blue Score Functions"
      ]
    },
    {
      "metadata": {
        "id": "-flyQJg1YsX8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def count_ngram(candidate, references, n):\n",
        "    clipped_count = 0\n",
        "    count = 0\n",
        "    r = 0\n",
        "    c = 0\n",
        "    for si in range(len(candidate)):\n",
        "        # Calculate precision for each sentence\n",
        "        ref_counts = []\n",
        "        ref_lengths = []\n",
        "        # Build dictionary of ngram counts\n",
        "        for reference in references:\n",
        "            ref_sentence = reference[si]\n",
        "            ngram_d = {}\n",
        "            words = ref_sentence.strip().split()\n",
        "            ref_lengths.append(len(words))\n",
        "            limits = len(words) - n + 1\n",
        "            # loop through the sentance consider the ngram length\n",
        "            for i in range(limits):\n",
        "                ngram = ' '.join(words[i:i+n]).lower()\n",
        "                if ngram in ngram_d.keys():\n",
        "                    ngram_d[ngram] += 1\n",
        "                else:\n",
        "                    ngram_d[ngram] = 1\n",
        "            ref_counts.append(ngram_d)\n",
        "        # candidate\n",
        "        cand_sentence = candidate[si]\n",
        "        cand_dict = {}\n",
        "        words = cand_sentence.strip().split()\n",
        "        limits = len(words) - n + 1\n",
        "        for i in range(0, limits):\n",
        "            ngram = ' '.join(words[i:i + n]).lower()\n",
        "            if ngram in cand_dict:\n",
        "                cand_dict[ngram] += 1\n",
        "            else:\n",
        "                cand_dict[ngram] = 1\n",
        "        clipped_count += clip_count(cand_dict, ref_counts)\n",
        "        count += limits\n",
        "        r += best_length_match(ref_lengths, len(words))\n",
        "        c += len(words)\n",
        "    if clipped_count == 0:\n",
        "        pr = 0\n",
        "    else:\n",
        "        pr = float(clipped_count) / count\n",
        "    bp = brevity_penalty(c, r)\n",
        "    return pr, bp\n",
        "\n",
        "\n",
        "def clip_count(cand_d, ref_ds):\n",
        "    \"\"\"Count the clip count for each ngram considering all references\"\"\"\n",
        "    count = 0\n",
        "    for m in cand_d.keys():\n",
        "        m_w = cand_d[m]\n",
        "        m_max = 0\n",
        "        for ref in ref_ds:\n",
        "            if m in ref:\n",
        "                m_max = max(m_max, ref[m])\n",
        "        m_w = min(m_w, m_max)\n",
        "        count += m_w\n",
        "    return count\n",
        "\n",
        "\n",
        "def best_length_match(ref_l, cand_l):\n",
        "    \"\"\"Find the closest length of reference to that of candidate\"\"\"\n",
        "    least_diff = abs(cand_l-ref_l[0])\n",
        "    best = ref_l[0]\n",
        "    for ref in ref_l:\n",
        "        if abs(cand_l-ref) < least_diff:\n",
        "            least_diff = abs(cand_l-ref)\n",
        "            best = ref\n",
        "    return best\n",
        "\n",
        "\n",
        "def brevity_penalty(c, r):\n",
        "    if c > r:\n",
        "        bp = 1\n",
        "    else:\n",
        "        bp = math.exp(1-(float(r)/c))\n",
        "    return bp\n",
        "\n",
        "\n",
        "def geometric_mean(precisions):\n",
        "    return (reduce(operator.mul, precisions)) ** (1.0 / len(precisions))\n",
        "\n",
        "\n",
        "def sel_sentence_bleu(candidate, references):\n",
        "    precisions = []\n",
        "    for i in range(4):\n",
        "        pr, bp = count_ngram(candidate, references, i+1)\n",
        "        precisions.append(pr)\n",
        "    bleu = geometric_mean(precisions) * bp\n",
        "    return bleu"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CcCYvSrNMpDp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Translate Sentence"
      ]
    },
    {
      "metadata": {
        "id": "vQ36FC_AM1Mw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Define functions"
      ]
    },
    {
      "metadata": {
        "id": "OlZ6FVjzMrDr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def find_next_word_beam_tran(logits_y, latent_score, t):\n",
        "\n",
        "  lower_ob = []\n",
        "  for l in range(latent_num):           \n",
        "    #y_max = np.max(logits_y[l,t])\n",
        "    prob_y = np.exp(logits_y[l,t])/np.sum(np.exp(logits_y[l,t]))    \n",
        "    log_prob_y_t = np.log(prob_y)     \n",
        "    lower_ob.append(log_prob_y_t)\n",
        "  \n",
        "  lower_to = 0\n",
        "  for l in range(latent_num):\n",
        "    lower_to = lower_to + lower_ob[l]  + latent_score[l]\n",
        "  lower_ave = lower_to/latent_num\n",
        "  \n",
        "  return lower_ave,  lower_ob"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wZV6l0TCMxnO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "########## Beam Search translate ###########\n",
        "\n",
        "beam_size = 30\n",
        "\n",
        "x_in = np.reshape(np.copy(en_test[2]), (1, max_length))\n",
        "y_in = np.reshape(np.copy(fr_test[2]), (1, max_length))\n",
        "\n",
        "y_de = np.random.randint(low=0, high=fr_vocab_size, size=(beam_size, max_length))\n",
        "x_de = np.random.randint(low=0, high=en_vocab_size, size=(beam_size, max_length))\n",
        "\n",
        "#########################################################\n",
        "prob_next_word = np.ones((beam_size, en_vocab_size),dtype=np.float32)\n",
        "x_de_new = np.zeros(y_de.shape, dtype=np.int32)\n",
        "\n",
        "x_len = np.reshape(np.copy(en_test_len[2]), (1,))\n",
        "y_len = np.reshape(np.copy(fr_test_len[2]), (1,))\n",
        "\n",
        "score = np.zeros((beam_size))\n",
        "latent_score = np.zeros((latent_num))\n",
        "current_prob = np.zeros((beam_size, en_vocab_size))\n",
        "\n",
        "with tf.Session() as sess:\n",
        "  \n",
        "    saver = tf.train.Saver()\n",
        "    saver.restore(sess, path1)\n",
        "    \n",
        "    gene_feed_dict = {input_placeholder: x_in, \n",
        "                      target_placeholder: y_in,\n",
        "                      in_length_placeholder: x_len, \n",
        "                      out_length_placeholder: y_len}                           \n",
        "            \n",
        "    mean, std = sess.run([la_mean, la_std], feed_dict=gene_feed_dict)    # 1*max_len x fr_vocab_size\n",
        "    \n",
        "    la_var = []\n",
        "    log_prob_la = []\n",
        "    for _ in range(latent_num):\n",
        "      eposida = np.random.normal(size = np.shape(la_std), loc=0.0, scale=1)\n",
        "      la_var_sample = mean + std*eposida\n",
        "      la_var_sample = np.reshape(la_var_sample, (batch_size, max_length, latent_size))    # batch_size x max_length x latent_size\n",
        "      la_var.append(la_var_sample)\n",
        "      log_prob_la.append(np.sum(np.log(norm.pdf(la_var_sample))))\n",
        "    \n",
        "    gene_feed_dict = {latent_var_placeholder:la_var,\n",
        "                      target_placeholder: y_in,\n",
        "                      out_length_placeholder: y_len}                           \n",
        "            \n",
        "    log_y = sess.run(log_liki_y_to, feed_dict=gene_feed_dict)    # 1*max_len x fr_vocab_size\n",
        "    \n",
        "    \n",
        "    for i in range(latent_num):\n",
        "      latent_score[i] = log_prob_la[i] + log_y[i]\n",
        "    \n",
        "    for t in range(10):      \n",
        "        for j in range(beam_size):\n",
        "          gene_feed_dict = {if_gene_placeholder: True,\n",
        "                            latent_var_placeholder:la_var,\n",
        "                            input_placeholder: np.reshape(x_de[j], (1,max_length))}\n",
        "                                                                           \n",
        "          logits_x = sess.run(logits_gene_x_to, feed_dict=gene_feed_dict)    # 1*max_len x fr_vocab_size\n",
        "            \n",
        "          prob_next_word[j], current_prob[j]  = find_next_word_beam_first(logits_x, latent_score, t)          \n",
        "          \n",
        "        \n",
        "        beam_max_id = np.argmax(prob_next_word, axis=0)\n",
        "        beam_max = np.max(prob_next_word, axis=0)\n",
        "        \n",
        "        next_beam_id = np.argsort(beam_max)[-beam_size:]\n",
        "        \n",
        "        score_new = np.zeros((beam_size))\n",
        "        \n",
        "        for j in range(beam_size):\n",
        "          beam_id = beam_max_id[next_beam_id[j]]\n",
        "          x_de_new[j] = x_de[beam_id]\n",
        "          x_de_new[j,t] = next_beam_id[j]\n",
        "          score_new[j] =  latent_score[beam_id] + current_prob[beam_id, next_beam_id[j]]\n",
        "        \n",
        "        x_de = x_de_new\n",
        "        latent_score = score_new\n",
        "        \n",
        "    print(np.mean(latent_score))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}